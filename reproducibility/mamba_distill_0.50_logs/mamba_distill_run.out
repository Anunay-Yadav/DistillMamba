/iopsstor/scratch/cscs/anunay/my_repo/MambaInLlama
teacher_model: LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(128256, 4096)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaFlashAttention2(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)
)
number of total params:8030261248
number of total trainable params:0
student_model: MambaTransformerHybridModelWrapper(
  (model): LlamaForCausalLM(
    (model): LlamaModel(
      (embed_tokens): Embedding(128256, 4096)
      (layers): ModuleList(
        (0): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (1): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (2): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (3): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (4): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (5): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (6): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (7): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (8): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (9): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (10): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (11): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (12): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (13): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (14): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (15): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (16): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (17): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (18): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (19): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (20): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (21): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (22): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (23): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (24): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (25): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (26): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (27): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (28): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (29): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
        (30): MambaDecoderLayer(
          (mamba): Mamba(
            (in_proj_x): Linear(in_features=4096, out_features=1024, bias=False)
            (in_proj_z): Linear(in_features=4096, out_features=4096, bias=False)
            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)
            (act): SiLU()
            (B_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (C_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (dt_proj_down): Linear(in_features=4096, out_features=256, bias=False)
            (dt_proj): Linear(in_features=256, out_features=4096, bias=True)
            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          )
          (mlp): MLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): RMSNorm()
          (post_attention_layernorm): RMSNorm()
        )
        (31): LlamaDecoderLayer(
          (self_attn): LlamaFlashAttention2(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
      )
      (norm): LlamaRMSNorm()
      (rotary_emb): LlamaRotaryEmbedding()
    )
    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)
  )
)
number of total params:8333758464
number of total trainable params:974585856
length of dataset: 296784
length of dataset: 296784
length of dataset: 296784
length of dataset: 296784
length of dataloader:length of dataloader:length of dataloader:   741967419674196


length of dataloader: 74196
training loss: 849.55029
training loss: 861.80054
training loss: 616.29150
training loss: 758.98682
training loss: 785.02332
training loss: 820.71106
training loss: 632.15039
training loss: 534.39868
training loss: 813.47601
training loss: 781.09686
training loss: 550.11761
training loss: 681.84784
training loss: 580.50702
training loss: 489.61337
training loss: 674.06360
training loss: 506.98981
training loss: 468.98703
training loss: 479.42517
training loss: 391.46298
training loss: 523.20959
training loss: 355.47681
training loss: 315.63074
training loss: 408.00830
training loss: 352.70493
training loss: 350.60858
training loss: 307.78195
training loss: 247.13544
training loss: 280.68686
training loss: 202.92055
training loss: 224.91699
training loss: 181.61064
training loss: 212.76208
training loss: 200.97874
training loss: 156.47624
training loss: 194.84430
training loss: 214.78592
training loss: 189.83701
training loss: 147.61853
training loss: 124.29715
training loss: 141.90874
training loss: 123.22325
training loss: 128.34921
training loss: 108.48553
training loss: 127.26977
training loss: 99.61614
training loss: 102.55750
training loss: 106.72734
training loss: 98.02724
training loss: 118.32484
training loss: 102.87837
training loss: 104.81650
training loss: 91.22438
training loss: 94.31400
training loss: 92.54367
training loss: 88.68028
training loss: 65.33579
training loss: 68.08405
training loss: 102.18502
training loss: 74.53910
training loss: 91.70697
training loss: 80.72767
training loss: 64.25216
training loss: 69.60625
training loss: 54.92422
training loss: 78.62932
training loss: 68.64532
training loss: 68.72442
training loss: 66.21315
training loss: 71.67869
training loss: 77.26630
training loss: 62.90901
training loss: 72.82745
training loss: 64.51436
training loss: 44.19232
training loss: 68.98772
training loss: 65.35241
training loss: 65.46796
training loss: 57.42071
training loss: 39.31253
training loss: 66.65015
training loss: 52.95803
training loss: 54.05814
training loss: 55.91887
training loss: 60.74637
training loss: 48.07283
training loss: 41.06078
training loss: 41.54867
training loss: 55.77770
training loss: 57.09026
training loss: 43.88215
training loss: 54.41482
training loss: 49.41038
training loss: 59.88249
training loss: 54.14745
training loss: 50.72784
training loss: 50.21133
training loss: 54.01908
training loss: 50.61217
training loss: 55.68534
training loss: 49.22757
training loss: 41.47401
training loss: 61.53853
training loss: 45.08575
training loss: 43.73595
training loss: nan
training loss: 44.10474
training loss: 50.77930
training loss: 33.34211
training loss: 47.17740
training loss: 40.06600
training loss: 48.08508
training loss: 29.30327
training loss: 48.10627
training loss: 65.77502
training loss: 37.66712
training loss: 43.81643
training loss: 55.29807
training loss: 49.78732
training loss: 33.07476
training loss: 48.15619
training loss: 42.71238
training loss: 46.95020
training loss: 55.23036
training loss: 40.52777
training loss: 31.13439
training loss: 33.14124
training loss: 44.44578
training loss: 50.16938
training loss: 38.47610
training loss: 38.26493
training loss: 43.94156
training loss: 40.76077
training loss: 34.54188
training loss: 40.51346
training loss: 39.02083
training loss: 46.51435
training loss: 44.59427
training loss: 40.31268
training loss: 43.45121
training loss: 44.77882
training loss: 31.00234
training loss: 39.95709
training loss: 44.88830
training loss: 40.47780
training loss: 37.40944
training loss: 30.97867
training loss: 34.85123
training loss: 31.53533
training loss: 35.45528
training loss: 42.10559
training loss: 32.72472
training loss: 34.02411
training loss: 33.70613
training loss: 59.80116
training loss: 30.88346
training loss: 38.17208
training loss: 29.55048
training loss: 34.65464
training loss: 48.68232
training loss: 35.05901
training loss: 34.14980
training loss: 37.03681
training loss: 32.70483
training loss: 32.88011
training loss: 38.26027
training loss: 28.19048
training loss: 33.44942
training loss: 39.36794
training loss: 37.78453
training loss: 45.20877
training loss: 36.95180
training loss: 34.64838
training loss: 30.71074
training loss: 39.28736
training loss: 31.27716
training loss: 31.70860
training loss: 31.78059
training loss: 26.24701
training loss: 29.33639
training loss: 40.91250
training loss: 39.24773
training loss: 34.51646
training loss: 32.13945
training loss: 44.90304
training loss: 29.22362
training loss: 46.52132
training loss: 37.58650
training loss: 35.88079
training loss: 39.51077
training loss: 33.76416
training loss: 37.87896
training loss: 30.40253
training loss: 24.79876
training loss: 36.04397
training loss: 29.00110
training loss: 32.99020
training loss: 29.31881
training loss: 43.24800
training loss: 48.12485
training loss: 28.79853
training loss: 41.89377
training loss: 33.46502
training loss: 31.11927
training loss: 28.52377
training loss: 32.95835
training loss: 30.91965
training loss: 37.80807
training loss: 32.60044
training loss: 31.81629
training loss: 36.55774
training loss: 27.82081
training loss: 32.53551
training loss: 32.74746
training loss: 26.88491
training loss: 97.69016
training loss: 25.97254
training loss: 41.48015
training loss: 32.80635
training loss: 27.05008
training loss: 40.31237
training loss: 29.82657
training loss: 30.22111
training loss: 29.17457
training loss: 27.15275
training loss: 29.26495
training loss: 34.16575
training loss: 48.21857
training loss: 30.57129
training loss: 41.77448
training loss: 43.61069
training loss: 27.42789
training loss: 34.73768
training loss: 30.82382
training loss: 32.82898
training loss: 22.68410
training loss: 30.63804
training loss: 36.99335
training loss: 32.30008
training loss: 20.72689
training loss: 30.13262
training loss: 30.52518
training loss: 33.59635
training loss: 36.08256
training loss: 33.73479
training loss: 33.37282
training loss: 31.27101
training loss: 36.07567
training loss: 25.19911
training loss: 41.84600
training loss: 26.77583
training loss: 27.83290
training loss: 39.98915
training loss: 21.44639
training loss: 29.76628
training loss: 39.89682
training loss: 30.93458
training loss: 35.34262
training loss: 27.49290
training loss: 32.37348
training loss: 22.17655
training loss: 22.81936
training loss: 34.73503
training loss: 36.88677
training loss: 23.76105
training loss: 35.56133
training loss: 23.84708
training loss: 28.13474
training loss: 25.44282
training loss: 23.77349
training loss: 32.02599
training loss: 28.67164
training loss: 34.56981
training loss: 26.57577
training loss: 40.49200
training loss: 32.74116
training loss: 22.91729
training loss: 24.39706
training loss: 27.97593
training loss: 27.92584
training loss: 38.14303
training loss: 25.25208
training loss: 22.19621
training loss: 34.73228
training loss: 26.54257
training loss: 32.60476
training loss: 38.07902
training loss: 27.91144
training loss: 24.57202
training loss: 32.79379
training loss: 33.19489
training loss: 29.74864
training loss: 31.73827
training loss: 26.95917
training loss: 24.21119
training loss: 24.72310
training loss: 24.88505
training loss: 33.56095
training loss: 33.99938
training loss: 38.84583
training loss: 42.00139
training loss: 37.28131
training loss: 33.88153
training loss: 37.69067
training loss: 27.50887
training loss: 26.15925
training loss: 36.60392
training loss: 22.82007
training loss: 47.58474
training loss: 32.32832
training loss: 26.85706
training loss: 29.64497
training loss: 19.98350
training loss: 30.53981
training loss: 35.74687
training loss: 35.13282
training loss: 23.88046
training loss: 29.50558
training loss: 28.63202
training loss: 32.09298
training loss: 20.90935
training loss: 28.58934
training loss: 30.65686
training loss: 51.06933
training loss: 23.74297
training loss: 33.27613
training loss: 26.31402
training loss: 28.46631
training loss: 25.76727
training loss: 32.46521
training loss: 25.90141
training loss: 30.98025
training loss: 22.92433
training loss: 27.27922
training loss: 25.57619
training loss: 26.63046
training loss: 21.94279
training loss: 26.70627
training loss: 22.66062
training loss: 25.06658
training loss: 27.03193
training loss: 25.06647
training loss: 24.30415
training loss: 25.65131
training loss: 41.46526
training loss: 24.07075
training loss: 27.03292
training loss: 26.28936
training loss: 31.10235
training loss: 33.45087
training loss: 29.74969
training loss: 28.21568
training loss: 29.84828
training loss: 26.52541
training loss: 20.49617
training loss: 27.54202
training loss: 26.79406
training loss: 20.24000
training loss: 24.76916
training loss: 22.48024
training loss: 30.65855
training loss: 25.78895
training loss: 23.01754
training loss: 30.17432
training loss: 35.10562
training loss: 34.37004
training loss: 27.29516
training loss: 45.72059
training loss: 18.67801
training loss: 28.50664
training loss: 33.22759
training loss: 38.22676
training loss: 18.33678
training loss: 26.74380
training loss: 25.51097
training loss: 27.00634
training loss: 29.45526
training loss: 21.54650
training loss: 23.16879
training loss: 26.95362
training loss: 33.72766
training loss: 28.27624
training loss: 34.21904
training loss: 28.62469
training loss: 30.98185
training loss: 43.67006
training loss: 33.04825
training loss: 30.06955
training loss: 21.87081
training loss: 29.17805
training loss: 26.24164
training loss: 28.44818
training loss: 28.51512
training loss: 29.07888
training loss: 20.10653
training loss: 26.89987
training loss: 19.81568
training loss: 25.06818
training loss: 26.39227
training loss: 28.90265
training loss: 23.68623
training loss: 24.38105
training loss: 23.11062
training loss: 26.03687
training loss: 38.47805
training loss: 23.48185
training loss: 24.70249
training loss: 30.76109
training loss: 34.39016
training loss: 23.41643
training loss: 23.65578
training loss: 25.80231
training loss: 23.46577
training loss: 18.90924
training loss: 29.60314
training loss: 26.06028
training loss: 24.66688
training loss: 27.56322
training loss: 32.15874
training loss: 21.70524
training loss: 26.93680
training loss: 33.91973
training loss: 25.65313
training loss: 24.39053
training loss: 30.00133
training loss: 30.51251
training loss: 26.16458
training loss: 22.95645
training loss: 21.55705
training loss: 24.04438
training loss: 30.93281
training loss: 28.10702
training loss: 33.50345
training loss: 22.62615
training loss: 21.15049
training loss: 22.15300
training loss: 24.17997
training loss: 23.51583
training loss: 32.58407
training loss: 26.78608
training loss: 35.42959
training loss: 28.44139
training loss: 33.62123
training loss: 26.51334
training loss: 22.82878
training loss: 29.41117
training loss: 21.51924
training loss: 31.03720
training loss: 29.13626
training loss: 27.91187
training loss: 24.30511
training loss: 36.23801
training loss: 21.89160
training loss: 22.59498
training loss: 27.33474
training loss: 34.67812
training loss: 28.76578
training loss: 29.11725
training loss: 23.26649
training loss: 19.11732
training loss: 18.00361
training loss: 28.49961
training loss: 25.56616
training loss: 29.90552
training loss: 31.49845
training loss: 22.28613
training loss: 18.40417
training loss: 30.34723
training loss: 23.46283
training loss: 33.48397
training loss: 28.37072
training loss: 26.24962
training loss: 29.62070
training loss: 30.75107
training loss: 23.55375
training loss: 23.77780
training loss: 27.43033
training loss: 25.65325
training loss: 19.20870
training loss: 46.95226
training loss: 22.52932
training loss: 25.87119
training loss: 25.37528
training loss: 23.84309
training loss: 26.66675
training loss: 19.61858
training loss: 28.79251
training loss: 30.07140
training loss: 20.92797
training loss: 23.27989
training loss: 29.33675
training loss: 19.76792
training loss: 19.78799
training loss: 21.49898
training loss: 21.53712
training loss: 21.40319
training loss: 24.93394
training loss: 22.79007
training loss: 24.30565
training loss: 24.48916
training loss: 26.52554
training loss: 22.67498
training loss: 17.81510
training loss: 26.31133
training loss: 21.84577
training loss: 20.77065
training loss: 24.51592
training loss: 20.20734
training loss: 23.23447
training loss: 33.13002
training loss: 26.46799
training loss: 22.70268
training loss: 34.22604
training loss: 33.35344
training loss: 24.49265
training loss: 25.02658
training loss: 22.35020
training loss: 21.32250
training loss: 18.79816
training loss: 24.73027
training loss: 35.57359
training loss: 27.30571
training loss: 25.12768
training loss: 21.90503
training loss: 25.32385
training loss: 29.45968
training loss: 22.91048
training loss: 28.45889
training loss: 23.63605
training loss: 23.15385
training loss: 27.70762
training loss: 24.86094
training loss: 27.85207
training loss: 22.69256
training loss: 23.09286
training loss: 22.81483
training loss: 26.10346
training loss: 25.56345
training loss: 26.47945
training loss: 24.10376
training loss: 26.72668
training loss: 28.03734
training loss: 17.34815
training loss: 26.23588
training loss: 25.66041
training loss: 17.48811
training loss: 36.15278
training loss: 26.94427
training loss: 25.90178
training loss: 27.43161
training loss: 28.80676
training loss: 25.76023
training loss: 23.13882
training loss: 19.58365
training loss: 20.82808
training loss: 21.30936
training loss: 23.98514
training loss: 22.96654
training loss: 24.65534
training loss: 34.74743
training loss: 60.57489
training loss: 19.84712
training loss: 22.74412
training loss: 19.25071
training loss: 23.96677
training loss: 26.39330
training loss: 29.08865
training loss: 21.90899
training loss: 20.17174
training loss: 31.98053
training loss: 25.94268
training loss: 22.20840
training loss: 23.99652
training loss: 25.11996
training loss: 25.72394
training loss: 26.33569
training loss: 22.24354
training loss: 24.14957
training loss: 23.51366
training loss: 25.20349
training loss: 21.96018
training loss: 32.28511
training loss: 23.54291
training loss: 25.81133
training loss: 36.18687
training loss: 20.19683
training loss: 24.20027
training loss: 30.52652
training loss: 14.53984
training loss: 22.92151
training loss: 26.86796
training loss: 22.15462
training loss: 25.51217
training loss: 22.32998
training loss: 29.33511
training loss: 24.55052
training loss: 29.92412
training loss: 17.49175
training loss: 23.98590
training loss: 33.24903
training loss: 29.83187
training loss: 27.55455
training loss: 19.89446
training loss: 17.64481
training loss: 23.37383
training loss: 26.72147
training loss: 35.07541
training loss: 22.66956
training loss: 18.93945
training loss: 23.85237
training loss: 17.85047
training loss: 27.08269
training loss: 23.51393
training loss: 19.94293
training loss: 20.07208
training loss: 39.77714
training loss: 28.03123
training loss: 24.50946
training loss: 20.33159
training loss: 27.39374
training loss: 25.15055
training loss: 13.45034
training loss: 25.37997
training loss: 33.01698
training loss: 19.42228
training loss: 24.00900
training loss: 35.64049
training loss: 24.55786
training loss: 23.54965
training loss: 22.39769
training loss: 25.27065
training loss: 21.43776
training loss: 26.19234
training loss: 21.38405
training loss: 30.17991
training loss: 24.36565
training loss: 25.40945
training loss: 22.66609
training loss: 21.65112
training loss: 23.55653
training loss: 37.26344
training loss: 33.77232
training loss: 22.53109
training loss: 17.51237
training loss: 26.02177
training loss: 23.66125
training loss: 24.57013
training loss: 24.88005
training loss: 28.39493
training loss: 22.46097
training loss: 31.06605
training loss: 30.24446
training loss: 25.59413
training loss: 18.90304
training loss: 27.50695
training loss: 21.06160
training loss: 15.95676
training loss: 22.76158
training loss: 23.47202
training loss: 22.86832
training loss: 24.80588
training loss: 29.27475
training loss: 20.84949
training loss: 20.32959
training loss: 18.51263
training loss: 29.41448
training loss: 30.22409
training loss: 24.23928
training loss: 24.18814
training loss: 22.70405
training loss: 31.79953
training loss: 22.51095
training loss: 20.26806
training loss: 19.97765
training loss: 19.73192
training loss: 23.07967
training loss: 19.64837
training loss: 19.80269
training loss: 25.93430
training loss: 23.31647
training loss: 30.86368
training loss: 25.71142
training loss: 28.46035
training loss: 27.97876
training loss: 28.50058
training loss: 21.59389
training loss: 19.79052
training loss: 24.14062
training loss: 28.79354
training loss: 26.28817
training loss: 31.62096
training loss: 19.07885
training loss: 20.01321
training loss: 27.01510
training loss: 34.64248
training loss: 23.23532
training loss: 22.92301
training loss: 22.15383
training loss: 24.84514
training loss: 22.52237
training loss: 22.89808
training loss: 21.66641
training loss: 18.81559
training loss: 19.21567
training loss: 26.88310
training loss: 18.49007
training loss: 20.27542
training loss: 15.40705
training loss: 26.53903
training loss: 23.02183
training loss: 27.02282
training loss: 23.10715
training loss: 29.37218
training loss: 19.43475
training loss: 21.87743
training loss: 21.02352
training loss: 18.22596
training loss: 32.72506
training loss: 18.31555
training loss: 20.77378
training loss: 18.13216
training loss: 49.62888
training loss: 29.64117
training loss: 19.58499
training loss: 21.19058
training loss: 22.04676
training loss: 19.82141
training loss: 25.49694
training loss: 20.22103
training loss: 22.72446
training loss: 26.30433
training loss: 26.05265
training loss: 21.61094
training loss: 19.21588
training loss: 20.33031
training loss: 27.37398
training loss: 20.96048
training loss: 25.31466
training loss: 22.37224
training loss: 26.64518
training loss: 23.24048
training loss: 33.87771
training loss: 25.61007
training loss: 26.89021
training loss: 22.12359
training loss: 30.64800
training loss: 19.04508
training loss: 24.23444
training loss: 15.72172
training loss: 22.55352
training loss: 25.97905
training loss: 18.34313
training loss: 27.30413
training loss: 21.50833
training loss: 21.92498
training loss: 25.11350
training loss: 18.43391
training loss: 16.72194
training loss: 31.87103
training loss: 18.07201
training loss: 19.78843
training loss: 27.01840
training loss: 17.80219
training loss: 18.18609
training loss: 27.22071
training loss: 21.17308
training loss: 28.34567
training loss: 20.82688
training loss: 17.39495
training loss: 26.02532
training loss: 18.96767
training loss: 21.12139
training loss: 26.75090
training loss: 19.10245
training loss: 25.53835
training loss: 24.61474
training loss: 23.79327
training loss: 19.82837
training loss: 21.45250
training loss: 23.39806
training loss: 26.48265
training loss: 19.34199
training loss: 22.96789
training loss: 21.62193
training loss: 25.01593
training loss: 24.85685
training loss: 16.17962
training loss: 20.82142
training loss: 21.20162
training loss: 21.80508
training loss: 25.92702
training loss: 17.61093
training loss: 24.24974
training loss: 22.36397
training loss: 24.11428
training loss: 19.62782
training loss: 21.05542
training loss: 24.44609
training loss: 23.08594
training loss: 25.25826
training loss: 28.87840
training loss: 21.16669
training loss: 19.47272
training loss: 26.21406
training loss: 26.45811
training loss: 18.90796
training loss: 23.44975
training loss: 20.45823
training loss: 24.19640
training loss: 22.59262
training loss: 30.05301
training loss: 22.96276
training loss: 28.86423
training loss: 25.69877
training loss: 20.66529
training loss: 25.69524
training loss: 23.36849
training loss: 24.07161
training loss: 25.92505
training loss: 25.59620
training loss: 32.69300
training loss: 23.75822
training loss: 15.61125
training loss: 22.19084
training loss: 20.75715
training loss: 21.40747
training loss: 19.90657
training loss: 21.07606
training loss: 29.80605
training loss: 31.96434
training loss: 19.68230
training loss: 16.64675
training loss: 27.58274
training loss: 25.18401
training loss: 16.83364
training loss: 19.49432
training loss: 21.06693
training loss: 22.36472
training loss: 24.57453
training loss: 18.80071
training loss: 25.64822
training loss: 20.85789
training loss: 22.62159
training loss: 22.28106
training loss: 22.31838
training loss: 16.89854
training loss: 29.47233
training loss: 16.93573
training loss: 20.25837
training loss: 28.30728
training loss: 21.09805
training loss: 29.71660
training loss: 21.49822
training loss: 19.82487
training loss: 21.13041
training loss: 22.55373
training loss: 17.50597
training loss: 24.94362
training loss: 20.47395
training loss: 19.87927
training loss: 23.03449
training loss: 40.14872
training loss: 22.73034
training loss: 19.91899
training loss: 22.04967
training loss: 28.22986
training loss: 33.65688
training loss: 19.13020
training loss: 15.71993
training loss: 17.08974
training loss: 21.30665
training loss: 23.08509
training loss: 17.63935
training loss: 24.82664
training loss: 22.64273
training loss: 16.20862
training loss: 18.81086
training loss: 26.14558
training loss: 17.96910
training loss: 11.61967
training loss: 24.24239
training loss: 17.91751
training loss: 20.84593
training loss: 20.78324
training loss: 27.56011
training loss: 20.01317
training loss: 33.33547
training loss: 20.63976
training loss: 17.05697
training loss: 20.05494
training loss: 21.22545
training loss: 16.30865
training loss: 21.68246
training loss: 21.76436
training loss: 24.33117
training loss: 24.72320
training loss: 25.81763
training loss: 19.63653
training loss: 22.24141
training loss: 15.19525
training loss: 19.42702
training loss: 22.57422
training loss: 18.67896
training loss: 22.53819
training loss: 18.46871
training loss: 35.88822
training loss: 20.02196
training loss: 19.00991
training loss: 32.48151
training loss: 15.98218
training loss: 15.55773
training loss: 24.77092
training loss: 24.49536
training loss: 18.20364
training loss: 15.83390
training loss: 21.00900
training loss: 18.57475
training loss: 17.44610
training loss: 25.46807
training loss: 23.04668
training loss: 23.41521
training loss: 33.47282
training loss: 20.30811
training loss: 22.52208
training loss: 19.48421
training loss: 23.17326
training loss: 23.47121
training loss: 28.73276
training loss: 24.71365
training loss: 14.89695
training loss: 27.04985
training loss: 23.95295
training loss: 25.70141
training loss: 25.61833
training loss: 17.44805
training loss: 27.93982
training loss: 21.33368
training loss: 22.38363
training loss: 21.26424
training loss: 19.84537
training loss: 24.97301
training loss: 25.38978
training loss: 19.11453
training loss: 18.42000
training loss: 26.15231
training loss: 18.40404
training loss: 22.46282
training loss: 19.72545
training loss: 19.24160
training loss: 20.93669
training loss: 47.51387
training loss: 17.24462
training loss: 19.92940
training loss: 21.09973
training loss: 18.01961
training loss: 19.91472
training loss: 16.13187
training loss: 24.28453
training loss: 20.43276
training loss: 20.71307
training loss: 15.89647
training loss: 25.86232
training loss: 15.00464
training loss: 18.49316
training loss: 25.03379
training loss: 28.83592
training loss: 19.59250
training loss: 18.75031
training loss: 16.49756
training loss: 17.42164
training loss: 16.19839
training loss: 20.71449
training loss: 26.71712
training loss: 23.91886
training loss: 18.67785
training loss: 19.29328
training loss: 18.32817
training loss: 21.07018
training loss: 23.47885
training loss: 15.23903
training loss: 18.99372
training loss: 24.85024
training loss: 17.54134
training loss: 23.55522
training loss: 19.89212
training loss: 17.26134
training loss: 22.40245
training loss: 18.40801
training loss: 30.15854
training loss: 29.94949
training loss: 24.14620
training loss: 22.75849
training loss: 21.95815
training loss: 19.16194
training loss: 26.02015
training loss: 17.24521
training loss: 22.37433
training loss: 18.79356
training loss: 17.03146
training loss: 32.65156
training loss: 17.14228
training loss: 26.31337
training loss: 19.71727
training loss: 15.75235
training loss: 22.50204
training loss: 32.92427
training loss: 18.45140
training loss: 17.18552
training loss: 18.95878
training loss: 25.64903
training loss: 18.53006
training loss: 14.28847
training loss: nan
training loss: 18.37198
training loss: 20.15822
training loss: 29.17417
training loss: 18.62349
training loss: 14.84603
training loss: 26.11967
training loss: 22.97965
training loss: 21.72790
training loss: 17.76051
training loss: 21.40082
training loss: 22.19211
training loss: 21.08983
training loss: 20.83872
training loss: 16.96165
training loss: 20.86267
training loss: 21.83346
training loss: 22.20004
training loss: 26.09629
training loss: 23.53253
training loss: 24.14299
training loss: 22.73370
training loss: 17.64187
training loss: 17.91710
training loss: 19.32000
training loss: 21.69708
training loss: 25.62109
training loss: 20.52234
training loss: 25.99747
training loss: 23.72114
training loss: 26.80551
training loss: 22.19644
training loss: 13.55674
training loss: 19.48095
training loss: 25.81150
training loss: 20.45089
training loss: 20.09033
training loss: 25.74598
training loss: 27.58462
training loss: 22.11926
training loss: 20.51081
training loss: 18.04144
training loss: 21.04089
training loss: 15.70063
training loss: 16.73981
training loss: 17.18513
training loss: 15.72148
training loss: 23.15133
training loss: 19.29751
training loss: 25.57699
training loss: 18.35628
training loss: 20.87202
training loss: 18.95274
training loss: 21.31744
training loss: 20.12104
training loss: 19.25893
training loss: 22.55954
training loss: 16.49739
training loss: 18.07789
training loss: 18.10962
training loss: 26.93888
training loss: 20.12236
training loss: 15.39461
training loss: 23.69128
training loss: 17.06090
training loss: 14.78453
training loss: 19.10384
training loss: 21.73268
training loss: 27.57442
training loss: 20.98504
training loss: 16.95540
training loss: 22.90051
training loss: 15.80276
training loss: 21.38880
training loss: 14.68858
training loss: 20.40915
training loss: 17.22112
training loss: 23.44143
training loss: 14.62530
training loss: 16.48697
training loss: 19.07889
training loss: 18.40131
training loss: 26.36069
training loss: 19.61315
training loss: 22.28178
training loss: 15.63271
training loss: 21.77946
training loss: 19.25657
training loss: 20.96716
training loss: 18.85227
training loss: 15.32776
training loss: 22.66142
training loss: 25.15887
training loss: 26.94707
training loss: 16.86591
training loss: 19.43998
training loss: 25.47959
training loss: 18.38567
training loss: 14.91375
training loss: 27.71854
training loss: 20.05955
training loss: 21.45664
training loss: 26.73777
training loss: 21.88077
training loss: 22.84176
training loss: 23.44481
training loss: 17.90632
training loss: 21.60067
training loss: 19.11895
training loss: 22.91098
training loss: 18.11704
training loss: 26.12711
training loss: 24.17981
training loss: 17.70375
training loss: 22.05072
training loss: 14.82136
training loss: 21.01705
training loss: 17.51635
training loss: 36.00755
training loss: 25.28591
training loss: 21.47573
training loss: 18.25348
training loss: 22.32889
training loss: 27.89048
training loss: 27.68018
training loss: 19.53875
training loss: 22.03719
training loss: 20.05418
training loss: 18.26144
training loss: 21.17302
training loss: 21.71898
training loss: 22.44729
training loss: 19.47091
training loss: 21.03632
training loss: 22.27158
training loss: 26.59024
training loss: 20.42091
training loss: 24.26272
training loss: 16.96918
training loss: 16.77873
training loss: 24.19866
training loss: 13.29359
training loss: 18.97824
training loss: 18.52464
training loss: 19.28579
training loss: 33.40199
training loss: 14.52365
training loss: 25.22542
training loss: 23.59019
training loss: 20.38427
training loss: 18.43789
training loss: 16.94171
training loss: 24.87297
training loss: 21.43681
training loss: 20.90367
training loss: 18.25096
training loss: 20.60795
training loss: 20.93397
training loss: 23.29026
training loss: 14.72882
training loss: 15.01883
training loss: 23.58270
training loss: 18.59713
training loss: 18.81674
training loss: 14.15808
training loss: 24.24088
training loss: 21.88425
training loss: 20.18536
training loss: 24.22151
training loss: 22.05770
training loss: 18.32284
training loss: 25.61110
training loss: 19.22452
training loss: 24.42844
training loss: 20.45957
training loss: 23.98552
training loss: 15.35205
training loss: 21.50190
training loss: 20.93639
training loss: 18.67763
training loss: 20.34519
training loss: 18.98848
training loss: 19.60447
training loss: 23.16520
training loss: 20.10671
training loss: 24.26327
training loss: 20.81503
training loss: 19.79408
training loss: 16.24781
training loss: 26.97747
training loss: 20.12182
training loss: 23.96026
training loss: 22.36707
training loss: 14.08270
training loss: 17.51214
training loss: 20.75997
training loss: 17.47035
training loss: 14.64637
training loss: 19.85689
training loss: 20.57184
training loss: 19.92586
training loss: 17.69354
training loss: 21.58072
training loss: 26.93264
training loss: 19.95882
training loss: 22.41487
training loss: 17.13187
training loss: 19.78445
training loss: 19.60466
training loss: 15.67970
training loss: 12.25800
training loss: 30.50545
training loss: 19.56243
training loss: 19.65757
training loss: 14.20772
training loss: 16.61139
training loss: 22.30822
training loss: 19.60596
training loss: 20.83971
training loss: 19.19299
training loss: 18.80246
training loss: 24.33103
training loss: 18.06276
training loss: 20.65597
training loss: 26.14733
training loss: 23.37238
training loss: 21.41674
training loss: 20.19102
training loss: 18.92558
training loss: 21.21986
training loss: 18.73534
training loss: 19.47381
training loss: 18.62569
training loss: 21.69834
training loss: 18.51900
training loss: 23.23286
training loss: 24.33067
training loss: 25.30350
training loss: nan
training loss: 19.64652
training loss: 18.52620
training loss: 20.06146
training loss: 18.98590
training loss: 20.36347
training loss: 21.89978
training loss: 24.30790
training loss: 12.67462
training loss: 17.09720
training loss: 19.11344
training loss: 16.59483
training loss: 21.40306
training loss: 20.25121
training loss: 20.26727
training loss: 17.93750
training loss: 19.75793
training loss: 20.32896
training loss: 20.47052
training loss: 18.42948
training loss: 18.36528
training loss: 20.02042
training loss: 18.55315
training loss: 15.65144
training loss: 24.20959
training loss: 19.08386
training loss: 17.75342
training loss: 19.73041
training loss: 18.91382
training loss: 26.04606
training loss: 29.73009
training loss: 14.24132
training loss: 19.25144
training loss: 18.55321
training loss: 14.87342
training loss: 17.49349
training loss: 21.73206
training loss: 19.49270
training loss: 27.65973
training loss: 18.18813
training loss: 16.69311
training loss: 15.22509
training loss: 16.16294
training loss: 21.88409
training loss: 18.78106
training loss: 24.27933
training loss: 17.68609
training loss: 18.60313
training loss: 16.77343
training loss: 17.35485
training loss: 21.33592
training loss: 20.13147
training loss: 19.08173
training loss: 18.11603
training loss: 17.66302
training loss: 18.64999
training loss: 18.94718
training loss: 23.39571
training loss: 18.47095
training loss: 19.39395
training loss: 28.53133
training loss: 19.66201
training loss: 16.74264
training loss: 24.25005
training loss: 23.58335
training loss: 16.82561
training loss: 15.92259
training loss: 16.00996
training loss: 18.39713
training loss: 16.65446
training loss: 24.20860
training loss: 19.45308
training loss: 22.78635
training loss: 23.70163
training loss: 17.61732
training loss: 30.25563
training loss: 22.81434
training loss: 22.96002
training loss: 18.59539
training loss: 20.21731
training loss: 25.90578
training loss: 15.84630
training loss: 22.26983
training loss: 21.81844
training loss: 23.15131
training loss: 17.89085
training loss: 17.55579
training loss: 25.55882
training loss: 23.05205
training loss: 20.75594
training loss: 18.58486
training loss: 24.52216
training loss: 15.26745
training loss: 18.20849
training loss: 17.54812
training loss: 20.23345
training loss: 22.96446
training loss: 17.14505
training loss: 16.90324
training loss: 20.22493
training loss: 23.96536
training loss: 30.58165
training loss: 16.18944
training loss: 24.22668
training loss: 15.17577
training loss: 16.81172
training loss: 22.91292
training loss: 20.67876
training loss: 25.38425
training loss: 17.66839
training loss: 26.31238
training loss: 21.54803
training loss: 14.21687
training loss: 17.36604
training loss: 14.64288
training loss: 19.30693
training loss: 23.71858
training loss: 17.80892
training loss: 24.15743
training loss: 22.85630
training loss: 15.17310
training loss: 17.30437
training loss: 17.85880
training loss: 21.52328
training loss: 18.37144
training loss: 21.59666
training loss: 17.65554
training loss: 17.98828
training loss: 17.95471
training loss: 20.26077
training loss: 18.48023
training loss: 20.66912
training loss: 20.13762
training loss: 24.34615
training loss: 24.31744
training loss: 21.37119
training loss: 20.01533
training loss: 16.71339
training loss: 20.64044
training loss: 24.54091
training loss: 17.01912
training loss: 21.52283
training loss: 20.18881
training loss: 16.07662
training loss: 20.09836
training loss: 19.16122
training loss: 20.82663
training loss: 18.93286
training loss: 16.91300
training loss: 14.24957
training loss: 15.71892
training loss: 15.19881
training loss: 17.00147
training loss: 23.98471
training loss: 21.81976
training loss: 14.96044
training loss: 13.05543
training loss: 27.99335
training loss: 18.45450
training loss: 22.66179
training loss: 20.33081
training loss: 19.46447
training loss: 20.62683
training loss: 23.34575
training loss: 20.42054
training loss: 18.49487
training loss: 36.35138
training loss: 23.11191
training loss: 19.45698
training loss: 21.17845
training loss: 22.71527
training loss: 19.82567
training loss: 12.39580
training loss: 19.21748
training loss: 27.70665
training loss: 21.84037
training loss: 16.86953
training loss: 20.15759
training loss: 20.43580
training loss: 19.93657
training loss: 20.51238
training loss: 18.19543
training loss: 15.85518
training loss: 21.84858
training loss: 24.87418
training loss: 22.61219
training loss: 26.09968
training loss: 23.62037
training loss: 21.27359
training loss: 15.65722
training loss: 21.42531
training loss: 16.88733
training loss: 26.08110
training loss: 20.26085
training loss: 25.39574
training loss: nan
training loss: 22.28327
training loss: 20.31775
training loss: 23.31474
training loss: 20.20474
training loss: 12.82203
training loss: 17.55851
training loss: 23.81430
training loss: 19.94795
training loss: 16.36674
training loss: 14.23191
training loss: 21.82604
training loss: 23.58165
training loss: 21.63222
training loss: 26.28164
training loss: 17.45592
training loss: 26.06909
training loss: 21.47797
training loss: 25.02494
training loss: 16.83769
training loss: 19.59953
training loss: 23.51698
training loss: 14.27158
training loss: 22.33808
training loss: 20.83664
training loss: 19.76862
training loss: 24.14297
training loss: 20.44777
training loss: 24.18474
training loss: 16.90979
training loss: 22.62681
training loss: 18.13161
training loss: 23.23344
training loss: 23.50978
training loss: 19.13669
training loss: 22.21996
training loss: 22.78892
training loss: 20.92281
training loss: 19.97986
training loss: 19.97433
training loss: 19.55516
training loss: 27.07878
training loss: 15.03412
training loss: 19.30447
training loss: 17.40967
training loss: 18.74909
training loss: 18.76835
training loss: nan
training loss: 16.62849
training loss: 21.94327
training loss: 23.49495
training loss: 24.76825
training loss: 16.54012
training loss: 25.65875
training loss: 13.32550
training loss: 22.54046
training loss: 14.82161
training loss: 13.68956
training loss: 22.60502
training loss: 21.21401
training loss: 16.68874
training loss: 18.00746
training loss: 17.65854
training loss: 20.91819
training loss: 17.77575
training loss: 20.29528
training loss: 21.44428
training loss: 20.01194
training loss: 19.81560
training loss: 17.08470
training loss: 18.82600
training loss: 15.51462
training loss: 13.89116
training loss: 26.06721
training loss: 17.89305
training loss: 21.02719
training loss: 18.71479
training loss: 16.98396
training loss: 16.23151
training loss: 17.39337
training loss: 14.93600
training loss: 18.24119
training loss: 21.79402
training loss: 24.00498
training loss: 17.14081
training loss: 24.55059
training loss: 16.48126
training loss: 20.10703
training loss: 17.50108
training loss: 12.76688
training loss: 25.52874
training loss: 19.41699
training loss: 15.34155
training loss: 24.02179
training loss: 16.84764
training loss: 18.07385
training loss: 21.16005
training loss: 15.63826
training loss: 18.09831
training loss: 20.34448
training loss: 18.73919
training loss: 14.79075
training loss: 18.99411
training loss: 12.81592
training loss: 18.10303
training loss: 16.51137
training loss: 17.27036
training loss: 21.86826
training loss: 20.91560
training loss: 20.78349
training loss: 19.01219
training loss: 15.45761
training loss: 18.82200
training loss: 18.78101
training loss: 25.93554
training loss: 18.22646
training loss: 18.51375
training loss: 16.82869
training loss: 21.99314
training loss: 21.59112
training loss: 16.04876
training loss: 22.52564
training loss: 22.48108
training loss: 20.67883
training loss: 18.50503
training loss: 21.45195
training loss: 21.06728
training loss: 19.95181
training loss: 17.44425
training loss: 19.91052
training loss: 20.39987
training loss: 23.87387
training loss: 17.31712
training loss: 20.58848
training loss: 18.32785
training loss: 16.14983
training loss: 22.90402
training loss: 22.06504
training loss: 20.20036
training loss: 24.82284
training loss: 15.08505
training loss: 15.77627
training loss: 15.98028
training loss: 23.44515
training loss: 16.96215
training loss: 14.41673
training loss: 18.50843
training loss: 27.21161
training loss: 14.26066
training loss: 14.94538
training loss: 21.11661
training loss: 18.51495
training loss: 23.89893
training loss: 13.99289
training loss: 17.77622
training loss: 17.27796
training loss: 18.34229
training loss: 20.60966
training loss: 17.50350
training loss: 15.81745
training loss: 18.73766
training loss: 16.91801
training loss: 18.11995
training loss: 20.77631
training loss: 18.92425
training loss: 16.70416
training loss: 15.21056
training loss: 25.87929
training loss: 13.77305
training loss: 28.92835
training loss: 15.81598
training loss: 19.25100
training loss: 20.93017
training loss: 15.60406
training loss: 22.47465
training loss: 15.68785
training loss: 24.03571
training loss: 15.37761
training loss: 17.24744
training loss: 14.80768
training loss: 18.54284
training loss: 19.07285
training loss: 21.07155
training loss: 18.46756
training loss: 17.85135
training loss: 24.10846
training loss: 18.97611
training loss: 16.29582
training loss: 22.84461
training loss: 23.65738
training loss: 25.47761
training loss: 19.98057
training loss: 16.10490
training loss: 17.53165
training loss: 15.61717
training loss: 19.02203
training loss: 20.66209
training loss: 19.13810
training loss: 15.49184
training loss: 21.65520
training loss: 14.61793
training loss: 24.00546
training loss: 15.29441
training loss: 18.54031
training loss: 22.20323
training loss: 18.21631
training loss: 22.00574
training loss: nan
training loss: 18.50514
training loss: 23.04762
training loss: 22.62876
training loss: 24.28625
training loss: 20.94369
training loss: 25.94576
training loss: 16.41786
training loss: 22.05910
training loss: 19.42797
training loss: 15.30340
training loss: 22.71911
training loss: 27.50562
training loss: 18.25344
training loss: 20.80928
training loss: 22.71462
training loss: 20.30534
training loss: 18.57563
training loss: 22.93377
training loss: 12.70998
training loss: 23.02138
training loss: 18.32837
training loss: 18.47399
training loss: 15.13717
training loss: 19.30365
training loss: 18.20441
training loss: 14.04050
training loss: 14.52660
training loss: 15.04737
training loss: 18.23671
training loss: 18.24925
training loss: 15.99320
training loss: 18.54821
training loss: 17.37401
training loss: 18.45399
training loss: 18.19823
training loss: 21.15630
training loss: 18.11909
training loss: 21.15083
training loss: 13.59433
training loss: 23.60334
training loss: 20.36800
training loss: 17.30708
training loss: 14.22869
training loss: 18.34176
training loss: 17.93661
training loss: 17.46943
training loss: 19.24054
training loss: 20.80434
training loss: 20.20877
training loss: 13.59236
training loss: 21.88223
training loss: 18.24843
training loss: 25.05115
training loss: 21.46058
training loss: 19.17267
training loss: 25.20297
training loss: 17.00106
training loss: 16.37634
training loss: 23.43243
training loss: 23.30395
training loss: 16.26095
training loss: 19.62833
training loss: 15.65353
training loss: 19.12504
training loss: 20.36791
training loss: 22.55429
training loss: 16.87084
training loss: 19.59575
training loss: 16.51731
training loss: 20.26513
training loss: 16.69413
training loss: 19.44965
training loss: 16.98923
training loss: 15.13289
training loss: 20.29357
training loss: 16.80634
training loss: 22.53700
training loss: 12.64962
training loss: 22.52415
training loss: 22.16327
training loss: 19.28881
training loss: 14.82522
training loss: 26.03196
training loss: 21.35374
training loss: 23.59027
training loss: 16.63712
training loss: 26.51974
training loss: 18.87742
training loss: 22.63931
training loss: 17.38269
training loss: 20.66685
training loss: 17.16908
training loss: nan
training loss: 12.48219
training loss: 20.83651
training loss: 21.24483
training loss: 19.28085
training loss: 23.08710
training loss: 22.17350
training loss: 17.94035
training loss: 20.45205
training loss: 16.59434
training loss: 15.60365
training loss: 24.29142
training loss: 14.15603
training loss: 19.69075
training loss: 13.47637
training loss: 17.96319
training loss: 18.36317
training loss: 16.42192
training loss: 26.24726
training loss: 20.95778
training loss: 25.56338
training loss: 22.52739
training loss: 21.23499
training loss: 17.83820
training loss: 18.77864
training loss: 17.29430
training loss: 15.24165
training loss: 17.18580
training loss: 20.30353
training loss: 36.62978
training loss: 22.55724
training loss: 17.06845
training loss: 15.14506
training loss: 14.48407
training loss: 15.26960
training loss: 19.96680
training loss: 18.69877
training loss: 22.58398
training loss: 18.63709
training loss: 26.45966
training loss: 17.93767
training loss: 16.58182
training loss: 15.71430
training loss: 18.04056
training loss: 15.52433
training loss: 16.17353
training loss: 19.72565
training loss: 16.03013
training loss: 16.19492
training loss: 21.15333
training loss: 22.64517
training loss: 13.00927
training loss: 16.98490
training loss: 16.31151
training loss: 18.44932
training loss: 19.65568
training loss: 16.39814
training loss: 17.93267
training loss: 13.35535
training loss: 20.14339
training loss: 22.63651
training loss: 12.63682
training loss: 16.06656
training loss: 15.64735
training loss: 24.01766
training loss: 18.09854
training loss: 17.82178
training loss: 15.72382
training loss: 24.96294
training loss: 18.24228
training loss: 17.64924
training loss: 22.95154
training loss: 20.07954
training loss: 20.64320
training loss: 21.46649
training loss: 17.79468
training loss: 20.98296
training loss: 16.88284
training loss: 27.34062
training loss: 21.71753
training loss: 21.96372
training loss: 18.94516
training loss: 16.20464
training loss: 24.20882
training loss: 17.06409
training loss: 14.96005
training loss: 16.30340
training loss: 23.49365
training loss: 14.30540
training loss: 20.54872
training loss: 17.94531
training loss: 19.43770
training loss: 18.80026
training loss: 19.07552
training loss: 14.56896
training loss: 20.86429
training loss: 11.82657
training loss: 19.46593
training loss: 15.08064
training loss: 18.20337
training loss: 13.86062
training loss: 18.54274
training loss: 17.02886
training loss: 18.12916
training loss: 13.51547
training loss: 17.49537
training loss: 17.73285
training loss: 15.27002
training loss: 26.28458
training loss: 14.86671
training loss: 22.32328
training loss: 13.25032
training loss: 12.06344
training loss: 21.27864
training loss: 17.23478
training loss: 17.81898
training loss: 15.57007
training loss: 20.49898
training loss: 20.20020
training loss: 20.37583
training loss: 18.27477
training loss: 20.37249
training loss: 25.30043
training loss: 14.50166
training loss: 12.59184
training loss: 21.61243
training loss: 18.97416
training loss: 23.45589
training loss: 17.84157
training loss: 16.63525
training loss: 16.23861
training loss: 18.23463
training loss: 17.73740
training loss: 20.06763
training loss: 19.38531
training loss: 20.44172
training loss: 17.67377
training loss: 15.37378
training loss: 16.46234
training loss: 15.77569
training loss: 19.76148
training loss: 18.63152
training loss: 18.84954
training loss: 20.20944
training loss: 13.29725
training loss: 17.63200
training loss: 20.44834
training loss: 16.78284
training loss: 18.91940
training loss: 19.04050
training loss: 14.73439
training loss: 24.82923
training loss: 15.39600
training loss: 23.10176
training loss: 15.88023
training loss: 14.54149
training loss: 15.85917
training loss: 15.09415
training loss: 16.83836
training loss: 17.22884
training loss: 16.26381
training loss: 22.64165
training loss: 18.18456
training loss: 15.86358
training loss: 16.56463
training loss: 19.04316
training loss: 17.01863
training loss: 12.33686
training loss: 16.98421
training loss: 16.97807
training loss: 20.58636
training loss: 17.13772
training loss: 19.09209
training loss: 12.56442
training loss: 20.09345
training loss: 14.47073
training loss: 16.91227
training loss: 19.26426
training loss: 17.97678
training loss: 20.04270
training loss: 20.13841
training loss: 13.18134
training loss: 19.36994
training loss: 13.71302
training loss: 18.51139
training loss: 18.70611
training loss: 20.20536
training loss: 15.46964
training loss: 18.10951
training loss: 20.09758
training loss: 18.48802
training loss: 14.66050
training loss: 18.05873
training loss: 16.15926
training loss: 17.25441
training loss: 14.28413
training loss: 14.58186
training loss: 15.69784
training loss: 19.98858
training loss: 20.40887
training loss: 16.48151
training loss: 17.96205
training loss: 22.21462
training loss: 17.32129
training loss: 22.01622
training loss: 23.92885
training loss: 16.70450
training loss: 15.73027
training loss: 24.51796
training loss: 19.22037
training loss: 16.37268
training loss: 17.01106
training loss: 14.86149
training loss: 15.72481
training loss: 17.74084
training loss: 20.51385
training loss: 21.95871
training loss: 17.84483
training loss: 13.88815
training loss: 22.32198
training loss: 18.00757
training loss: 14.39015
training loss: 18.39954
training loss: 17.62211
training loss: 18.23565
training loss: 17.62206
training loss: 22.84260
training loss: 20.13991
training loss: 17.89277
training loss: 16.51597
training loss: 15.41167
training loss: 16.81623
training loss: 16.11759
training loss: 20.00588
training loss: 17.22608
training loss: 18.54933
training loss: 17.33406
training loss: 21.38889
training loss: 14.36626
training loss: 20.40645
training loss: 20.53656
training loss: 30.95462
training loss: 17.46866
training loss: 17.06258
training loss: 17.55144
training loss: 17.34494
training loss: 14.66126
training loss: 20.81858
training loss: 22.78382
training loss: 15.40724
training loss: 16.20322
training loss: 20.79673
training loss: 22.98176
training loss: 17.90531
training loss: 13.91036
training loss: 20.43443
training loss: 15.97912
training loss: 15.61739
training loss: 20.78269
training loss: 19.90993
training loss: 16.52516
training loss: 16.66976
training loss: 19.86903
training loss: 14.65217
training loss: 20.34137
training loss: 21.10354
training loss: 20.43840
training loss: 16.51062
training loss: 14.45292
training loss: 21.79381
training loss: 18.09765
training loss: 17.25473
training loss: 14.41406
training loss: 19.34998
training loss: 15.87001
training loss: 16.04597
training loss: 12.29738
training loss: 17.49128
training loss: 21.30458
training loss: 16.22766
training loss: 12.24286
training loss: 14.88749
training loss: 15.04958
training loss: 15.62623
training loss: 20.65505
training loss: 16.33568
training loss: 17.83594
training loss: 19.29072
training loss: 17.89177
training loss: 15.92130
training loss: 14.86190
training loss: 15.79629
training loss: 19.44436
training loss: 16.69166
training loss: 20.54770
training loss: 13.61865
training loss: 14.28246
training loss: 22.34643
training loss: 20.06708
training loss: 18.45796
training loss: 20.72386
training loss: 19.33754
training loss: 15.56436
training loss: 18.66142
training loss: 16.86388
training loss: 18.21794
training loss: 19.12389
training loss: 14.82417
training loss: 15.38086
training loss: 16.68462
training loss: 16.50012
training loss: 18.65243
training loss: 13.23634
training loss: 22.17543
training loss: 15.08566
training loss: 11.13938
training loss: 16.58075
training loss: 15.26773
training loss: 15.34833
training loss: 17.35302
training loss: 21.04964
training loss: 22.10215
training loss: 14.26267
training loss: 25.54079
training loss: 14.43142
training loss: 22.31284
training loss: 15.91512
training loss: 17.75265
training loss: 18.66778
training loss: 16.34224
training loss: 21.56810
training loss: 17.98080
training loss: 18.35317
training loss: 17.31841
training loss: 18.08479
training loss: 16.99836
training loss: 17.15501
training loss: 16.15326
training loss: 26.40464
training loss: 15.54066
training loss: 15.57081
training loss: 20.03131
training loss: 20.28097
training loss: 14.25925
training loss: 14.85567
training loss: 19.85785
training loss: 17.72197
training loss: 19.00566
training loss: 18.57747
training loss: 19.52747
training loss: 20.86214
training loss: 11.92333
training loss: 17.89413
training loss: 24.45330
training loss: 19.64644
training loss: 25.45594
training loss: 21.39713
training loss: 27.91133
training loss: 15.75006
training loss: 17.39596
training loss: 19.84715
training loss: 14.75492
training loss: 19.05778
training loss: 20.01862
training loss: 20.53222
training loss: 14.92879
training loss: 18.22419
training loss: 18.24524
training loss: 16.89291
training loss: 15.83860
training loss: 16.63601
training loss: 16.72724
training loss: 14.59445
training loss: 20.34102
training loss: 16.09817
training loss: 20.11197
training loss: 18.28679
training loss: 12.93224
training loss: 16.78238
training loss: 18.60810
training loss: 22.59259
training loss: 17.81020
training loss: 20.38637
training loss: 18.48842
training loss: 16.68993
training loss: 15.15617
training loss: 22.54776
training loss: 15.12552
training loss: 14.79301
training loss: 11.90610
training loss: 17.89710
training loss: 17.33657
training loss: 19.76573
training loss: 19.25475
training loss: 18.43131
training loss: 19.28179
training loss: 20.01324
training loss: 19.06572
training loss: 22.10739
training loss: 16.42147
training loss: 14.81402
training loss: 14.11138
training loss: 16.18794
training loss: 15.03327
training loss: 16.42388
training loss: 16.93980
training loss: 16.24268
training loss: 16.60696
training loss: 22.89435
training loss: 19.17336
training loss: 21.25212
training loss: 15.96968
training loss: 17.41624
training loss: 12.76994
training loss: 18.48545
training loss: 19.54723
training loss: 24.24124
training loss: 19.04607
training loss: 18.73889
training loss: 15.25940
training loss: 19.31187
training loss: 16.74235
training loss: 16.41542
training loss: 12.11799
training loss: 17.66504
training loss: 15.40739
training loss: 20.81027
training loss: 26.48605
training loss: 16.81818
training loss: 18.52850
training loss: 16.12574
training loss: 19.65583
training loss: 18.24782
training loss: 21.75491
training loss: 15.96601
training loss: 13.48162
training loss: 14.19978
training loss: 17.90587
training loss: 16.49475
training loss: 21.57921
training loss: 19.10045
training loss: 18.96242
training loss: 18.45796
training loss: 22.79991
training loss: 19.99908
training loss: 17.12085
training loss: 16.82281
training loss: 15.12800
training loss: 15.41939
training loss: 21.10243
training loss: 15.20821
training loss: 18.19749
training loss: 20.74074
training loss: 17.90539
training loss: 22.87822
training loss: 19.40787
training loss: 16.33405
training loss: 15.35978
training loss: 15.90252
training loss: 17.38546
training loss: 13.97060
training loss: 20.09232
training loss: 16.04452
training loss: 16.54797
training loss: 27.03100
training loss: 22.92191
training loss: 17.07248
training loss: 13.72223
training loss: 15.46172
training loss: 12.39255
training loss: 15.46756
training loss: 22.31734
training loss: 19.66364
training loss: 18.26668
training loss: 28.46849
training loss: 13.45143
training loss: 24.29906
training loss: 19.15186
training loss: 16.85270
training loss: 15.41219
training loss: 18.65880
training loss: 28.47624
training loss: 15.77698
training loss: 24.22068
training loss: 19.70406
training loss: 15.53290
training loss: 17.71139
training loss: 14.28321
training loss: 17.87956
training loss: 23.80987
training loss: 19.77362
training loss: 14.07654
training loss: 17.51896
training loss: 19.57649
training loss: 15.62655
training loss: 19.29927
training loss: 17.08133
training loss: 17.83869
training loss: 20.02444
training loss: 14.57117
training loss: 19.76828
training loss: 21.27205
training loss: 19.11041
training loss: 15.36902
training loss: 17.83460
training loss: 20.20889
training loss: 14.70760
training loss: 17.84837
training loss: 12.94121
training loss: 19.21219
training loss: 14.52471
training loss: 15.29305
training loss: 15.05314
training loss: 16.71803
training loss: 17.52480
training loss: 16.62686
training loss: 15.36397
training loss: 22.84723
training loss: 15.19109
training loss: 13.61689
training loss: 19.42649
training loss: 16.79562
training loss: 19.38066
training loss: 18.10627
training loss: 18.82796
training loss: 15.84919
training loss: 17.35939
training loss: 21.45618
training loss: 25.20809
training loss: 17.88186
training loss: 24.54142
training loss: 15.14434
training loss: 18.27641
training loss: 14.04335
training loss: 17.73914
training loss: 17.87644
training loss: 20.23246
training loss: 18.10338
training loss: 20.40796
training loss: 17.28349
training loss: 17.40296
training loss: 15.35926
training loss: 19.13400
training loss: 14.74578
training loss: 18.46737
training loss: 19.30273
training loss: 16.95239
training loss: 18.33532
training loss: 15.75132
training loss: 14.75691
training loss: 20.01069
training loss: 14.23995
training loss: 16.81680
training loss: 17.07408
training loss: 16.26772
training loss: 12.88659
training loss: 20.42782
training loss: 19.98430
training loss: 16.41936
training loss: 15.68446
training loss: 18.65511
training loss: 11.70801
training loss: 14.78266
training loss: 21.24671
training loss: 14.27729
training loss: 14.74073
training loss: 20.86158
training loss: 15.60273
training loss: 24.83478
training loss: 17.47254
training loss: 12.67709
training loss: 14.27583
training loss: 19.60502
training loss: 20.09718
training loss: 15.72638
training loss: 23.16772
training loss: 16.43344
training loss: 23.04137
training loss: 20.79064
training loss: 19.00232
training loss: 15.37483
training loss: 21.05793
training loss: 14.03910
training loss: 26.99271
training loss: 22.65826
training loss: 18.12942
training loss: 20.10093
training loss: 23.92042
training loss: 17.54609
training loss: 18.23387
training loss: 17.56953
training loss: 19.05526
training loss: 16.79803
training loss: 19.48701
training loss: 20.92382
training loss: 18.68937
training loss: 17.21474
training loss: 15.02558
training loss: 21.78805
training loss: 18.23400
training loss: 21.91976
training loss: 13.83404
training loss: 19.41810
training loss: 17.50048
training loss: 19.31472
training loss: 14.25742
training loss: 17.57503
training loss: 13.54547
training loss: 19.67129
training loss: 18.37326
training loss: 19.20820
training loss: 15.58502
training loss: 16.84492
training loss: 17.10765
training loss: 13.75386
training loss: 19.73721
training loss: 19.29146
training loss: 14.52703
training loss: 18.43850
training loss: 17.61434
training loss: 16.43465
training loss: 17.12504
training loss: 16.47100
training loss: 21.18524
training loss: 20.43771
training loss: 16.20628
training loss: 10.51025
training loss: 13.82443
training loss: 20.05633
training loss: 18.62696
training loss: 14.19682
training loss: 20.97699
training loss: 17.20116
training loss: 17.71811
training loss: 17.88465
training loss: 22.78081
training loss: 19.95934
training loss: 17.01258
training loss: 16.79029
training loss: 18.94156
training loss: 15.95167
training loss: 16.11736
training loss: 15.94132
training loss: 19.84015
training loss: 20.13500
training loss: 15.55721
training loss: 16.52720
training loss: 12.84122
training loss: 15.04101
training loss: 11.94167
training loss: 25.72132
training loss: 15.65975
training loss: 16.22909
training loss: 20.71359
training loss: 19.73868
training loss: 16.99434
training loss: 15.91918
training loss: 19.16761
training loss: 15.11384
training loss: 11.44428
training loss: 21.11283
training loss: 23.17292
training loss: 15.09185
training loss: 14.89499
training loss: 19.47472
training loss: 20.16285
training loss: 18.53782
training loss: 18.54518
training loss: 15.40428
training loss: 19.40026
training loss: 18.28204
training loss: 15.13914
training loss: 16.73776
training loss: 15.99927
training loss: 24.39272
training loss: 13.24061
training loss: 11.12837
training loss: 19.82722
training loss: 16.40048
training loss: 29.98431
training loss: 17.25369
training loss: 15.64409
training loss: 14.94305
training loss: 19.12229
training loss: 16.84424
training loss: 21.55416
training loss: 20.05339
training loss: 24.61215
training loss: 14.60304
training loss: 23.86908
training loss: 16.32551
training loss: 18.02781
training loss: 20.06501
training loss: 15.54348
training loss: 15.17356
training loss: 23.03538
training loss: 21.54496
training loss: 14.98452
training loss: 15.98950
training loss: 20.16493
training loss: 22.37585
training loss: 15.36084
training loss: 14.44644
training loss: 16.56871
training loss: 17.55125
training loss: 16.13487
training loss: 14.58692
training loss: 13.00014
training loss: 15.24586
training loss: 14.66348
training loss: 14.73727
training loss: 16.00848
training loss: 20.38465
training loss: 14.59772
training loss: 19.34515
training loss: 21.06064
training loss: 21.09516
training loss: 26.18524
training loss: 17.11576
training loss: 14.31153
training loss: 22.74993
training loss: 20.71049
training loss: 15.86103
training loss: 18.62576
training loss: 11.23830
training loss: 16.51679
training loss: 16.87460
training loss: 18.70896
training loss: 14.51848
training loss: 12.62688
training loss: 15.35455
training loss: 18.03011
training loss: 15.34276
training loss: 19.02028
training loss: 15.48766
training loss: 18.48417
training loss: 13.72191
training loss: 21.08733
training loss: 18.86070
training loss: 16.22907
training loss: 16.34674
training loss: 12.65078
training loss: 14.60035
training loss: 17.45433
training loss: 22.05001
training loss: 15.92178
training loss: 15.83483
training loss: 18.60782
training loss: 15.30147
training loss: 17.24340
training loss: 15.92601
training loss: 21.99744
training loss: 15.01062
training loss: 18.60920
training loss: 14.09722
training loss: 18.14684
training loss: 18.46809
training loss: 12.06407
training loss: 18.56795
training loss: 14.43194
training loss: 24.35855
training loss: 17.52212
training loss: 18.60274
training loss: 16.45149
training loss: 15.76061
training loss: 20.87531
training loss: 19.86247
training loss: 22.88321
training loss: 17.21914
training loss: 16.23378
training loss: 22.24627
training loss: 17.83151
training loss: 16.27956
training loss: 17.43043
training loss: 10.18857
training loss: 22.78951
training loss: 11.30387
training loss: 15.77250
training loss: 21.23037
training loss: 14.41414
training loss: 18.58852
training loss: 14.32677
training loss: 12.56904
training loss: 13.90542
training loss: 13.17340
training loss: 18.09870
training loss: 15.91603
training loss: 18.42473
training loss: 12.92979
training loss: 16.54437
training loss: 19.50749
training loss: 13.21210
training loss: 14.97855
training loss: 19.33901
training loss: 12.34302
training loss: 11.86807
training loss: 20.50992
training loss: 20.19480
training loss: 23.46397
training loss: 19.53998
training loss: 24.09743
training loss: 18.40632
training loss: 23.77354
training loss: 13.57868
training loss: 23.24580
training loss: 14.24123
training loss: 13.34263
training loss: 18.79413
training loss: 18.06316
training loss: 26.87274
training loss: 18.03778
training loss: 17.10843
training loss: 18.18276
training loss: 21.82712
training loss: 15.25561
training loss: 14.53614
training loss: 16.45763
training loss: 17.33076
training loss: 19.89072
training loss: 20.13542
training loss: 20.79980
training loss: 11.86641
training loss: 20.06050
training loss: 19.94404
training loss: 20.47835
training loss: 19.57021
training loss: 19.41568
training loss: 15.94021
training loss: 18.07401
training loss: 15.54296
training loss: 17.43901
training loss: 22.81999
training loss: 17.37897
training loss: 15.20879
training loss: 16.18354
training loss: 19.39928
training loss: 15.67795
training loss: 19.85423
training loss: 15.84499
training loss: 16.90299
training loss: 18.74756
training loss: 17.63267
training loss: 14.47973
training loss: 19.71922
training loss: 20.45206
training loss: 16.11200
training loss: 18.67373
training loss: 19.07554
training loss: 19.35090
training loss: 17.90083
training loss: 17.61362
training loss: 16.85740
training loss: 13.24963
training loss: 16.58205
training loss: 20.37727
training loss: 17.82234
training loss: 17.92630
training loss: 17.75006
training loss: 24.08184
training loss: 27.58965
training loss: 21.25992
training loss: 15.53641
training loss: 21.04075
training loss: 21.18475
training loss: 12.51154
training loss: 12.44178
training loss: 14.95192
training loss: 22.51522
training loss: 13.61562
training loss: 18.85029
training loss: 15.76782
training loss: 21.94735
training loss: 17.26338
training loss: 14.61537
training loss: 13.04906
training loss: 13.89345
training loss: 14.96316
training loss: 14.80628
training loss: 16.52271
training loss: 12.27508
training loss: 16.57214
training loss: 14.86919
training loss: 14.36048
training loss: 22.90020
training loss: 15.60655
training loss: 14.16667
training loss: 21.54601
training loss: 17.49250
training loss: 16.84306
training loss: 13.98604
training loss: 15.64108
training loss: 19.16474
training loss: 13.95030
training loss: 17.15653
training loss: 17.11184
training loss: 15.97261
training loss: 15.94992
training loss: 16.13731
training loss: 14.87471
training loss: 14.92775
training loss: 17.61593
training loss: 15.86447
training loss: 22.82128
training loss: 13.62512
training loss: 23.08941
training loss: 15.92311
training loss: 12.99347
training loss: 15.95807
training loss: 20.41263
training loss: 19.35663
training loss: 18.20934
training loss: 14.55273
training loss: 13.31051
training loss: 17.44311
training loss: 15.15462
training loss: 17.13910
training loss: 20.45246
training loss: 22.79198
training loss: 18.37957
training loss: 15.49038
training loss: 20.46092
training loss: 19.67757
training loss: 14.47743
training loss: 12.91738
training loss: 13.28132
training loss: 15.67068
training loss: 18.83629
training loss: 15.66527
training loss: 13.86788
training loss: 19.87449
training loss: 16.08359
training loss: 14.60318
training loss: 17.22975
training loss: 15.43434
training loss: 20.39695
training loss: 23.39142
training loss: 14.78168
training loss: 17.67514
training loss: 15.00251
training loss: 25.08557
training loss: 22.24005
training loss: 19.10641
training loss: 18.42267
training loss: 18.72409
training loss: 15.65557
training loss: 20.21841
training loss: 14.99388
training loss: 20.12169
training loss: 20.17226
training loss: 16.77535
training loss: 14.36786
training loss: 17.42239
training loss: 20.47559
training loss: 15.52687
training loss: 14.17371
training loss: 17.11304
training loss: 17.24604
training loss: 17.14687
training loss: 15.87382
training loss: 15.62748
training loss: 14.40248
training loss: 18.14052
training loss: 25.79889
training loss: 13.51371
training loss: 13.10795
training loss: 19.79350
training loss: 16.50405
training loss: 15.12132
training loss: 15.64846
training loss: 14.93878
training loss: 17.97922
training loss: 16.72539
training loss: 13.36727
training loss: 18.80924
training loss: 15.04365
training loss: 11.81987
training loss: 15.53771
training loss: 14.79989
training loss: 17.16472
training loss: 10.75758
training loss: 16.63656
training loss: 16.01570
training loss: 18.99731
training loss: 11.56436
training loss: 15.59937
training loss: 16.54912
training loss: 19.20349
training loss: 13.45095
training loss: 17.81028
training loss: 10.76966
training loss: 15.66637
training loss: 19.11969
training loss: 15.35802
training loss: 17.74329
training loss: 13.70839
training loss: 15.08618
training loss: 13.40121
training loss: 15.39028
training loss: 15.08180
training loss: 17.53261
training loss: 15.95219
training loss: 13.91828
training loss: 12.90203
training loss: 15.84013
training loss: 12.26668
training loss: 22.88418
training loss: 12.82165
training loss: 11.08491
training loss: 16.04462
training loss: 15.84241
training loss: 14.43222
training loss: 23.17971
training loss: 17.49402
training loss: 16.50286
training loss: 13.97360
training loss: 16.04939
training loss: 11.78326
training loss: 16.53949
training loss: 13.20601
training loss: 16.32467
training loss: 16.45140
training loss: 21.08883
training loss: 13.14951
training loss: 13.28684
training loss: 21.79811
training loss: 15.32074
training loss: 16.14592
training loss: 14.45268
training loss: 22.25811
training loss: 21.85738
training loss: 11.23472
training loss: 16.69176
training loss: 15.91789
training loss: 17.73138
training loss: 12.79631
training loss: 16.34575
training loss: 20.21953
training loss: 14.68960
training loss: 19.64688
training loss: 14.06405
training loss: 13.29659
training loss: 18.44497
training loss: 14.18380
training loss: 16.11984
training loss: 21.79810
training loss: 17.14348
training loss: 18.10499
training loss: 13.18737
training loss: 17.44863
training loss: 21.78930
training loss: 16.36733
training loss: 19.50430
training loss: 14.21383
training loss: 20.03840
training loss: 16.43417
training loss: 18.23937
training loss: 16.00099
training loss: 15.53346
training loss: 17.99679
training loss: 19.36076
training loss: 14.01535
training loss: 19.81612
training loss: 16.76863
training loss: 18.34136
training loss: 13.09624
training loss: 20.86134
training loss: 17.36973
training loss: 14.50802
training loss: 23.36914
training loss: 13.49316
training loss: 15.04502
training loss: 19.47184
training loss: 15.26726
training loss: 18.45238
training loss: 20.07068
training loss: 18.60156
training loss: 17.71860
training loss: 17.64646
training loss: 17.88946
training loss: 19.56741
training loss: 15.78024
training loss: 15.60032
training loss: 19.21949
training loss: 17.59615
training loss: 13.01837
training loss: 15.05326
training loss: 14.79423
training loss: 18.64282
training loss: 14.75327
training loss: 17.43328
training loss: 16.49569
training loss: 15.06623
training loss: 18.84453
training loss: 16.71513
training loss: 16.65544
training loss: 13.33789
training loss: 16.47334
training loss: 17.31417
training loss: 18.21402
training loss: 19.77145
training loss: 15.25060
training loss: 11.51954
training loss: 18.20326
training loss: 22.77021
training loss: 21.39947
training loss: 15.01309
training loss: 15.54039
training loss: 14.38022
training loss: 17.44224
training loss: 15.10553
training loss: 15.83404
training loss: 19.24242
training loss: 15.68037
training loss: 15.08969
training loss: 17.30231
training loss: 20.97614
training loss: 19.90593
training loss: 12.27413
training loss: 14.95479
training loss: 13.62345
training loss: 18.02105
training loss: 19.35807
training loss: 18.95845
training loss: 16.22866
training loss: 17.05707
training loss: 18.62531
training loss: 13.50568
training loss: 15.61386
training loss: 18.41786
training loss: 13.77610
training loss: 20.23684
training loss: 19.36783
training loss: 20.79830
training loss: 16.19066
training loss: 19.19378
training loss: 15.75556
training loss: 16.56781
training loss: 16.30871
training loss: 13.76662
training loss: 15.43318
training loss: 13.54502
training loss: 19.53364
training loss: 16.17410
training loss: 14.90523
training loss: 20.85611
training loss: 16.97976
training loss: 14.19536
training loss: 18.18866
training loss: 16.87889
training loss: 16.72307
training loss: 12.23775
training loss: 17.63650
training loss: 12.51698
training loss: 13.47679
training loss: 12.34207
training loss: 18.53441
training loss: 15.23467
training loss: 13.54898
training loss: 16.67442
training loss: 13.80782
training loss: 17.75123
training loss: 14.81925
training loss: 16.90909
training loss: 16.22494
training loss: 13.61835
training loss: 22.47462
training loss: 13.17924
training loss: 13.30970
training loss: 12.90350
training loss: 14.92001
training loss: 15.73320
training loss: 14.94554
training loss: 20.84295
training loss: 12.20112
training loss: 14.55428
training loss: 14.96719
training loss: 16.42446
training loss: 19.97769
training loss: 18.57915
training loss: 16.72064
training loss: 19.82673
training loss: 16.21838
training loss: 19.84960
training loss: 15.23078
training loss: 15.39155
training loss: 17.72521
training loss: 14.52227
training loss: 12.10650
training loss: 20.92064
training loss: 15.54164
training loss: 15.86714
training loss: 17.95020
training loss: 19.33928
training loss: 13.94654
training loss: 16.28601
training loss: 15.40578
training loss: 16.21553
training loss: 14.62115
training loss: 22.08172
training loss: 15.16527
training loss: 22.85930
training loss: 16.44541
training loss: 18.76889
training loss: 14.46208
training loss: 16.72676
training loss: 11.23505
training loss: 13.31076
training loss: 15.44670
training loss: 16.72834
training loss: 14.24363
training loss: 15.25619
training loss: 14.30260
training loss: 15.18146
training loss: 12.21047
training loss: 19.47476
training loss: 19.53065
training loss: 15.44370
training loss: 20.77592
training loss: 15.07434
training loss: 13.79722
training loss: 11.25009
training loss: 13.54051
training loss: 13.15179
training loss: 15.58823
training loss: 14.41528
training loss: 16.48668
training loss: nan
training loss: 21.75593
training loss: 11.04388
training loss: 21.03592
training loss: 16.44002
training loss: 18.54906
training loss: 15.64750
training loss: 21.89060
training loss: 13.14551
training loss: 16.55533
training loss: 17.80579
training loss: 19.19597
training loss: 16.39950
training loss: 11.16400
training loss: 14.23311
training loss: 12.95342
training loss: 17.70743
training loss: 16.50725
training loss: 20.13374
training loss: 16.55400
training loss: 22.89197
training loss: 11.87403
training loss: 16.36755
training loss: 11.55521
training loss: 17.94193
training loss: 17.32661
training loss: 15.11669
training loss: 21.26539
training loss: 19.79999
training loss: nan
training loss: 21.35948
training loss: 19.75955
training loss: 16.69340
training loss: 15.62775
training loss: 21.04632
training loss: 15.87858
training loss: 14.91571
training loss: 15.70161
training loss: 22.03361
training loss: 15.50107
training loss: 14.89435
training loss: 12.64056
training loss: 13.33067
training loss: 15.38635
training loss: 14.68663
training loss: 19.87594
training loss: 16.84527
training loss: 20.96990
training loss: 13.11412
training loss: 18.42302
training loss: 15.69696
training loss: 18.08558
training loss: 15.86642
training loss: 12.75544
training loss: 19.05322
training loss: 12.81717
training loss: 11.95733
training loss: 15.11112
training loss: 13.58445
training loss: 16.71019
training loss: 19.59455
training loss: 17.34954
training loss: 13.08093
training loss: 14.75472
training loss: 20.59972
training loss: 17.79577
training loss: 15.08657
training loss: 10.81722
training loss: 16.28094
training loss: 13.52276
training loss: 13.12564
training loss: 15.94538
training loss: 11.94598
training loss: 23.06917
training loss: 16.48566
training loss: 19.52415
training loss: 15.44551
training loss: 15.11218
training loss: 17.77416
training loss: 21.51179
training loss: 14.64236
training loss: 13.63625
training loss: 14.78545
training loss: 15.20952
training loss: 14.48806
training loss: 14.54637
training loss: 16.01694
training loss: 16.37545
training loss: 15.81720
training loss: 16.31682
training loss: 12.39363
training loss: 14.30183
training loss: 19.55181
training loss: 17.56739
training loss: 17.20974
training loss: 16.61519
training loss: 14.86535
training loss: 15.06922
training loss: 10.19333
training loss: 16.10039
training loss: nan
training loss: 18.79865
training loss: 18.63058
training loss: 18.48869
training loss: 15.56730
training loss: 16.23330
training loss: 14.77528
training loss: 16.11300
training loss: 15.93414
training loss: 16.93828
training loss: 19.78743
training loss: 11.11182
training loss: 22.61989
training loss: 17.15422
training loss: 22.19295
training loss: 14.00061
training loss: 19.95374
training loss: 18.60609
training loss: 19.68087
training loss: 14.38975
training loss: 16.82930
training loss: 17.51777
training loss: 12.64031
training loss: 16.54818
training loss: 16.24978
training loss: 9.57062
training loss: 15.35203
training loss: 15.98861
training loss: 18.90193
training loss: 14.73295
training loss: 24.88596
training loss: 15.23391
training loss: 18.54306
training loss: 18.64836
training loss: 20.72861
training loss: 25.10703
training loss: 13.21010
training loss: 16.65687
training loss: 14.43786
training loss: 18.17449
training loss: 17.24999
training loss: 13.94315
training loss: 13.42301
training loss: 14.84135
training loss: 18.33187
training loss: 17.37447
training loss: 12.05520
training loss: 19.04461
training loss: 15.01001
training loss: 15.73068
training loss: 12.04435
training loss: 14.19596
training loss: 14.90195
training loss: 24.46860
training loss: 13.09449
training loss: 18.17012
training loss: 19.38473
training loss: 16.57896
training loss: 16.54248
training loss: 17.73918
training loss: 15.36578
training loss: 13.80480
training loss: 15.01365
training loss: 15.08780
training loss: 13.57667
training loss: 16.70373
training loss: 15.97358
training loss: 20.46042
training loss: 16.67344
training loss: 14.82492
training loss: 14.68265
training loss: 12.39704
training loss: 19.35966
training loss: 20.88523
training loss: 15.47043
training loss: 13.30222
training loss: 11.11936
training loss: 16.82532
training loss: 14.24432
training loss: 24.31585
training loss: 16.46791
training loss: 15.05130
training loss: 16.06628
training loss: 12.93024
training loss: 15.84389
training loss: 16.59210
training loss: 14.21287
training loss: 20.14446
training loss: 19.10355
training loss: 13.95675
training loss: 16.65298
training loss: 17.92517
training loss: 19.69266
training loss: 15.76243
training loss: 17.68982
training loss: 13.53211
training loss: 14.68770
training loss: 14.58054
training loss: 14.43849
training loss: 15.77439
training loss: 17.25455
training loss: 17.58796
training loss: 16.57018
training loss: 13.72547
training loss: 13.98005
training loss: 19.43376
training loss: 18.13863
training loss: 17.89016
training loss: 16.35130
training loss: 11.98245
training loss: 16.57530
training loss: 16.97666
training loss: 17.87098
training loss: 20.99834
training loss: 11.40503
training loss: 18.04381
training loss: 10.09028
training loss: 19.24963
training loss: 14.66686
training loss: 13.84636
training loss: 16.15909
training loss: nan
training loss: 15.08487
training loss: 16.95873
training loss: 18.83069
training loss: 16.23089
training loss: 18.29678
training loss: 12.99325
training loss: 19.94092
training loss: 16.43208
training loss: 18.88016
training loss: 11.75757
training loss: 16.29872
training loss: 14.46568
training loss: 13.77132
training loss: 13.70940
training loss: 16.17236
training loss: 16.41755
training loss: 14.97924
training loss: 13.61075
training loss: 21.90580
training loss: 13.67286
training loss: 19.90190
training loss: 21.68686
training loss: 10.98548
training loss: 17.45236
training loss: 17.29154
training loss: 11.32941
training loss: 22.08631
training loss: 15.95258
training loss: 14.58457
training loss: 17.54911
training loss: 13.74467
training loss: 15.15033
training loss: 14.02411
training loss: 19.13051
training loss: 15.82469
training loss: 13.50856
training loss: 16.92342
training loss: 17.14902
training loss: 17.88059
training loss: 13.54536
training loss: 14.60873
training loss: 15.96373
training loss: 13.65979
training loss: 14.94056
training loss: 15.96979
training loss: 17.32832
training loss: 19.64102
training loss: 15.18216
training loss: 19.29052
training loss: 14.60238
training loss: 15.08924
training loss: 18.07063
training loss: 15.15631
training loss: 15.45539
training loss: 14.74297
training loss: 16.18313
training loss: 14.22166
training loss: 13.58260
training loss: 26.27860
training loss: 20.26033
training loss: 14.48191
training loss: 19.26267
training loss: 16.54381
training loss: 12.75825
training loss: 22.35127
training loss: 13.17713
training loss: 10.18618
training loss: 15.91426
training loss: 15.45859
training loss: 19.23710
training loss: 12.06184
training loss: 12.32448
training loss: 20.63865
training loss: 15.57153
training loss: 11.72810
training loss: 14.37275
training loss: 16.05694
training loss: 14.58372
training loss: 14.21585
training loss: 16.94123
training loss: 14.53735
training loss: 16.08169
training loss: 9.84825
training loss: 12.14024
training loss: 12.64523
training loss: 14.46156
training loss: 16.05643
training loss: 13.83197
training loss: 12.33187
training loss: 17.07353
training loss: 17.63541
training loss: 12.80788
training loss: 12.85867
training loss: 13.19112
training loss: 13.82448
training loss: 14.45352
training loss: 16.00574
training loss: 17.07929
training loss: 15.53347
training loss: 19.42853
training loss: 18.12506
training loss: 14.31784
training loss: 12.70857
training loss: 12.30025
training loss: 16.59806
training loss: 13.35059
training loss: 15.89602
training loss: 15.99644
training loss: 14.93018
training loss: 19.09979
training loss: 12.05495
training loss: 14.08782
training loss: 13.24658
training loss: 17.60436
training loss: 15.08077
training loss: 15.89352
training loss: 17.60785
training loss: 17.30378
training loss: 14.67884
training loss: 15.58464
training loss: 22.45562
training loss: 15.13992
training loss: 13.77838
training loss: 17.05641
training loss: 15.76970
training loss: 15.07577
training loss: 14.46641
training loss: 10.08293
training loss: 16.72884
training loss: 19.35307
training loss: 25.59534
training loss: 20.68797
training loss: 20.40235
training loss: 18.78619
training loss: 12.46583
training loss: 19.07424
training loss: 16.79376
training loss: 19.72579
training loss: 14.46147
training loss: 17.19782
training loss: 14.24629
training loss: 14.64655
training loss: 15.37890
training loss: 16.42573
training loss: 11.92514
training loss: 14.34826
training loss: 16.89506
training loss: 13.23515
training loss: 13.57090
training loss: 14.17458
training loss: 21.97930
training loss: 17.71055
training loss: 14.39788
training loss: 9.36740
training loss: 12.89040
training loss: 16.42466
training loss: 16.51282
training loss: 13.67278
training loss: 16.09571
training loss: 15.96619
training loss: 14.76054
training loss: 16.20125
training loss: 17.55411
training loss: 17.37355
training loss: nan
training loss: 13.93878
training loss: 19.38640
training loss: 14.83105
training loss: 17.87888
training loss: 14.57515
training loss: 23.57044
training loss: nan
training loss: 13.61316
training loss: 15.27306
training loss: 13.95995
training loss: 16.16693
training loss: 13.38909
training loss: 14.67266
training loss: 13.89143
training loss: 16.18447
training loss: 14.36431
training loss: 12.84045
training loss: 14.16180
training loss: 14.25594
training loss: 14.93955
training loss: 17.29299
training loss: 16.19304
training loss: 14.27411
training loss: 18.26859
training loss: 15.96636
training loss: 15.96455
training loss: 21.28862
training loss: 13.39255
training loss: 20.00186
training loss: 18.15067
training loss: 20.18633
training loss: 17.41117
training loss: 17.03807
training loss: 14.65486
training loss: 16.34833
training loss: 15.22065
training loss: 9.47496
training loss: 16.92094
training loss: 14.90659
training loss: 12.79167
training loss: 17.39682
training loss: 14.36812
training loss: 16.26087
training loss: 17.78496
training loss: 12.35751
training loss: 21.04752
training loss: 16.74628
training loss: 13.57756
training loss: 18.48932
training loss: 21.70678
training loss: 14.84818
training loss: 13.77956
training loss: 11.85307
training loss: 17.36035
training loss: 16.19867
training loss: 13.41139
training loss: 15.89949
training loss: 19.87421
training loss: 18.40307
training loss: 20.69639
training loss: 10.47391
training loss: 16.21184
training loss: 14.89951
training loss: 16.47444
training loss: 16.95789
training loss: 13.78805
training loss: 11.19655
training loss: 19.86356
training loss: 19.51089
training loss: 19.54880
training loss: 20.30982
training loss: 13.72134
training loss: 15.93852
training loss: 17.00699
training loss: 14.91459
training loss: 15.94529
training loss: 19.50247
training loss: 13.76671
training loss: 13.90597
training loss: 17.32006
training loss: 20.32149
training loss: 15.15394
training loss: 14.71773
training loss: 17.10439
training loss: 12.18772
training loss: 20.29425
training loss: 20.63826
training loss: 13.57338
training loss: 13.53010
training loss: 17.91933
training loss: 13.25693
training loss: 15.29904
training loss: 13.17457
training loss: 16.12120
training loss: 16.39264
training loss: 16.81503
training loss: 12.75360
training loss: 16.12834
training loss: 16.62976
training loss: 10.85344
training loss: 17.67852
training loss: 19.02495
training loss: 18.02995
training loss: 16.09323
training loss: 17.74376
training loss: 13.79602
training loss: 19.38987
training loss: 14.75413
training loss: 17.67196
training loss: 12.11867
training loss: 16.15093
training loss: 16.11473
training loss: 17.34391
training loss: 23.82335
training loss: 11.14914
training loss: 18.17882
training loss: 16.81776
training loss: 17.40651
training loss: 19.20247
training loss: 11.89871
training loss: 10.31869
training loss: 15.79871
training loss: 11.27392
training loss: 17.09392
training loss: 15.64754
training loss: 13.53784
training loss: 14.48046
training loss: 13.28969
training loss: 12.04403
training loss: 16.12362
training loss: 17.16607
training loss: 15.66599
training loss: 16.68787
training loss: 13.66980
training loss: 14.77004
training loss: 15.40368
training loss: 15.83709
training loss: 19.05349
training loss: 9.07246
training loss: 15.58273
training loss: 13.29051
training loss: 18.12985
training loss: 17.58346
training loss: 20.85028
training loss: 18.24978
training loss: 15.37143
training loss: 18.09672
training loss: 15.13595
training loss: 9.62358
training loss: 18.23592
training loss: 20.78479
training loss: 20.46732
training loss: 16.91484
training loss: 12.80297
training loss: 17.76416
training loss: 18.64599
training loss: 15.82387
training loss: 20.02608
training loss: 14.96182
training loss: 13.79752
training loss: 11.62836
training loss: 17.76632
training loss: 14.38550
training loss: 13.00757
training loss: 21.93644
training loss: 14.57620
training loss: 15.87908
training loss: 15.63663
training loss: 14.82267
training loss: 21.39515
training loss: 14.67119
training loss: 15.70671
training loss: 10.45020
training loss: 15.31629
training loss: 15.07268
training loss: 19.05819
training loss: 13.30785
training loss: 19.51722
training loss: 10.82077
training loss: 16.96539
training loss: 15.60905
training loss: 17.32156
training loss: 16.95277
training loss: 18.18847
training loss: 11.84330
training loss: 20.90404
training loss: 14.36827
training loss: 20.49709
training loss: 14.10508
training loss: 13.15767
training loss: 12.14479
training loss: 23.10333
training loss: 17.19449
training loss: 18.75352
training loss: 14.84685
training loss: 14.49962
training loss: 15.39908
training loss: 17.77481
training loss: 13.40534
training loss: 13.46746
training loss: 22.21199
training loss: 13.02273
training loss: 21.19725
training loss: 19.43026
training loss: 14.22757
training loss: 18.74198
training loss: 12.85597
training loss: 17.36021
training loss: 12.91586
training loss: 16.60227
training loss: 18.86600
training loss: 13.54378
training loss: 16.36736
training loss: 15.03798
training loss: 23.47993
training loss: 19.72101
training loss: 15.24016
training loss: 14.05926
training loss: 14.71113
training loss: 17.89723
training loss: 17.07021
training loss: 9.52442
training loss: 12.43453
training loss: 15.60381
training loss: 15.33470
training loss: 17.13647
training loss: 13.34682
training loss: 12.25399
training loss: 12.00224
training loss: 11.50049
training loss: 12.18363
training loss: 15.58322
training loss: 18.87737
training loss: 16.63654
training loss: 13.85010
training loss: 12.98069
training loss: 16.79061
training loss: 13.79556
training loss: 10.31068
training loss: 12.32485
training loss: 12.18392
training loss: 15.58681
training loss: 19.22979
training loss: 11.95285
training loss: 16.23021
training loss: 13.55744
training loss: 15.80248
training loss: 9.73316
training loss: 17.90174
training loss: 17.82297
training loss: 13.89194
training loss: 14.59132
training loss: 16.27687
training loss: 18.89750
training loss: 14.62061
training loss: 15.55063
training loss: 17.84008
training loss: 16.47084
training loss: 14.17122
training loss: 16.26080
training loss: 19.39622
training loss: 11.97789
training loss: 14.43079
training loss: 19.65273
training loss: 15.28076
training loss: 15.49314
training loss: 24.22275
training loss: 13.60370
training loss: 14.34166
training loss: 19.90615
training loss: 13.74715
training loss: 11.81704
training loss: 12.26642
training loss: 17.63994
training loss: 13.74119
training loss: 15.32486
training loss: 15.39493
training loss: 15.41214
training loss: 13.11953
training loss: 14.78161
training loss: 16.83697
training loss: 16.58410
training loss: 16.94195
training loss: 13.47753
training loss: 17.04091
training loss: 14.09777
training loss: 13.18608
training loss: 15.19779
training loss: 12.97407
training loss: 28.81229
training loss: 15.13526
training loss: 15.02940
training loss: 18.65039
training loss: 10.64981
training loss: 12.56156
training loss: 11.50939
training loss: 10.52948
training loss: 18.85445
training loss: 14.74888
training loss: 18.47888
training loss: 11.19821
training loss: 14.43687
training loss: 13.56336
training loss: 15.74211
training loss: 18.26095
training loss: 11.39316
training loss: 13.44139
training loss: 11.50265
training loss: 12.81434
training loss: 11.82352
training loss: 15.12917
training loss: 17.34195
training loss: 15.00775
training loss: 13.00849
training loss: 16.71194
training loss: 15.48996
training loss: 16.49090
training loss: 13.37010
training loss: 11.32467
training loss: 16.07386
training loss: 14.09290
training loss: 18.22677
training loss: 18.33199
training loss: 19.29263
training loss: 18.22762
training loss: 15.58647
training loss: 12.08180
training loss: 23.46030
training loss: 17.85176
training loss: 13.49694
training loss: 13.50018
training loss: 16.52463
training loss: 12.96377
training loss: 16.42637
training loss: 12.69806
training loss: 16.54922
training loss: 20.17488
training loss: 18.13628
training loss: 14.08458
training loss: 14.95210
training loss: 14.62404
training loss: 14.08722
training loss: 15.67421
training loss: 13.19600
training loss: 17.57680
training loss: 16.33917
training loss: 15.14007
training loss: 13.91571
training loss: 14.03132
training loss: 13.35696
training loss: 12.95395
training loss: 16.31889
training loss: 15.97574
training loss: 12.09710
training loss: 13.02769
training loss: 13.41003
training loss: 13.90845
training loss: 17.57273
training loss: 11.77516
training loss: 19.61442
training loss: 12.41915
training loss: 15.28492
training loss: 15.19496
training loss: 13.19567
training loss: 18.43966
training loss: 15.67132
training loss: 16.60464
training loss: 12.18896
training loss: 13.30753
training loss: 14.95539
training loss: 18.90674
training loss: 18.79734
training loss: 16.54329
training loss: 13.54444
training loss: 19.61669
training loss: 15.77460
training loss: 14.58139
training loss: 16.01242
training loss: 16.54720
training loss: 15.06476
training loss: 11.99124
training loss: 16.62414
training loss: 15.67293
training loss: 13.71206
training loss: 16.11027
training loss: 15.60474
training loss: 19.80167
training loss: 14.15437
training loss: 14.34720
training loss: 11.51929
training loss: 12.89807
training loss: 15.10620
training loss: 11.31719
training loss: 13.01871
training loss: 14.50140
training loss: 21.79235
training loss: 18.48650
training loss: 14.60927
training loss: 18.17819
training loss: 12.26100
training loss: 15.63573
training loss: 10.60464
training loss: 14.84191
training loss: 15.02603
training loss: 14.31763
training loss: 17.79363
training loss: 13.24148
training loss: 23.45021
training loss: 13.91404
training loss: 9.88282
training loss: 13.96493
training loss: 15.42338
training loss: 21.19607
training loss: 19.16590
training loss: 18.69855
training loss: 13.47421
training loss: 14.74647
training loss: 16.38217
training loss: 15.83315
training loss: 10.94413
training loss: 17.75515
training loss: 16.52978
training loss: 14.98474
training loss: 17.35043
training loss: 17.50291
training loss: 10.65809
training loss: 16.07297
training loss: 13.69126
training loss: 17.16659
training loss: 16.31529
training loss: 16.99446
training loss: 16.70494
training loss: 19.13446
training loss: 29.10160
training loss: 18.99448
training loss: 16.14291
training loss: 13.69661
training loss: 14.82454
training loss: 15.81170
training loss: 11.58899
training loss: 17.04689
training loss: 12.77250
training loss: 14.66125
training loss: 16.57010
training loss: 15.09717
training loss: 15.12172
training loss: 12.70776
training loss: 15.84195
training loss: 12.94873
training loss: 15.11487
training loss: 13.62191
training loss: 16.65428
training loss: 13.75091
training loss: 10.78273
training loss: 18.24577
training loss: 14.58270
training loss: 13.07017
training loss: 13.19354
training loss: 17.28003
training loss: 15.01597
training loss: 17.71897
training loss: 12.89002
training loss: 14.22792
training loss: 14.35355
training loss: 17.19932
training loss: 18.02725
training loss: 13.60344
training loss: 12.68128
training loss: 12.38951
training loss: 19.79773
training loss: 13.54677
training loss: 14.21364
training loss: 13.94519
training loss: 9.99748
training loss: 11.10314
training loss: 14.96953
training loss: 16.57853
training loss: 18.75240
training loss: 18.25311
training loss: 12.41467
training loss: 15.52674
training loss: 11.98267
training loss: 14.00872
training loss: 15.70665
training loss: 17.09071
training loss: 13.45481
training loss: 15.49625
training loss: 17.16403
training loss: 13.70720
training loss: 12.23148
training loss: 11.44837
training loss: 11.47706
training loss: 16.10059
training loss: 20.27939
training loss: 10.46671
training loss: 19.78011
training loss: 13.15572
training loss: 17.06334
training loss: 10.68839
training loss: 13.55947
training loss: 14.34947
training loss: 19.91287
training loss: 14.78247
training loss: 14.44416
training loss: 15.29726
training loss: 15.19931
training loss: 13.22594
training loss: 14.87091
training loss: 13.31289
training loss: 16.33071
training loss: 16.40040
training loss: 19.90927
training loss: 16.45967
training loss: 14.25730
training loss: 17.01544
training loss: 18.23761
training loss: 16.89730
training loss: 19.05687
training loss: 11.63309
training loss: 15.72602
training loss: 17.27107
training loss: 16.98642
training loss: 15.74568
training loss: 8.72306
training loss: 12.67755
training loss: 10.63231
training loss: 17.67123
training loss: 13.83105
training loss: 16.25811
training loss: 14.42882
training loss: 15.90066
training loss: 16.84682
training loss: 14.85781
training loss: 14.61368
training loss: 20.29070
training loss: 16.86147
training loss: 20.13745
training loss: 15.44649
training loss: 22.79517
training loss: 11.39250
training loss: 15.54161
training loss: 13.86649
training loss: 14.16963
training loss: 16.41760
training loss: 17.78153
training loss: 11.52674
training loss: 13.33318
training loss: 14.76937
training loss: 12.23352
training loss: 13.54650
training loss: 17.21362
training loss: 20.04573
training loss: 13.58444
training loss: 18.93492
training loss: 17.31454
training loss: 15.98795
training loss: 14.84733
training loss: 17.23947
training loss: 20.34137
training loss: 15.22016
training loss: 12.33789
training loss: 17.38659
training loss: 19.15073
training loss: 13.86145
training loss: 17.90199
training loss: 17.64594
training loss: 13.14025
training loss: 12.37362
training loss: 13.03835
training loss: 13.73410
training loss: 11.01558
training loss: 11.88671
training loss: 18.83943
training loss: 15.08832
training loss: 16.89007
training loss: 15.77923
training loss: 11.25403
training loss: 19.39528
training loss: 11.04383
training loss: 12.46656
training loss: 12.61536
training loss: 15.12859
training loss: 11.17076
training loss: 14.60621
training loss: 17.16422
training loss: 19.83256
training loss: 15.76048
training loss: 13.09799
training loss: 23.08194
training loss: 15.51322
training loss: 16.93620
training loss: 14.75829
training loss: 11.67934
training loss: 15.93231
training loss: 13.70194
training loss: 16.59762
training loss: 14.79873
training loss: 12.16522
training loss: 14.97908
training loss: 18.25869
training loss: 18.51961
training loss: 20.28249
training loss: 18.27589
training loss: 13.38385
training loss: 18.10176
training loss: 15.62764
training loss: 18.62956
training loss: 24.35105
training loss: 19.52158
training loss: 15.65729
training loss: 13.68606
training loss: 14.76683
training loss: 10.57080
training loss: 12.02320
training loss: 13.00713
training loss: 16.16194
training loss: 14.68055
training loss: 16.86179
training loss: 15.22876
training loss: 14.35656
training loss: 15.97704
training loss: 13.31116
training loss: 17.27265
training loss: 11.86805
training loss: 22.38244
training loss: 14.93600
training loss: 16.59195
training loss: 12.39771
training loss: 15.03516
training loss: 14.95426
training loss: 14.40127
training loss: 15.27493
training loss: 20.61298
training loss: 32.45943
training loss: 12.24570
training loss: 17.05937
training loss: 21.47047
training loss: 13.11315
training loss: 16.24944
training loss: 15.76434
training loss: 16.66186
training loss: 11.53332
training loss: 15.18775
training loss: 21.56190
training loss: 15.24405
training loss: 13.01043
training loss: 13.13199
training loss: nan
training loss: 15.34150
training loss: 8.77959
training loss: 12.54555
training loss: 15.57808
training loss: 16.36694
training loss: 17.11938
training loss: 14.36654
training loss: 18.42363
training loss: 16.31711
training loss: 20.20240
training loss: 17.32472
training loss: 16.00669
training loss: 13.74759
training loss: 16.10493
training loss: 16.40719
training loss: 9.69265
training loss: 16.80093
training loss: 15.46027
training loss: 14.68955
training loss: 16.70060
training loss: 9.26168
training loss: 11.47215
training loss: 15.81065
training loss: 14.41380
training loss: 15.43527
training loss: 16.24591
training loss: 15.64963
training loss: 12.67662
training loss: 12.53028
training loss: 19.00355
training loss: 14.20259
training loss: 13.15808
training loss: 14.87839
training loss: 16.02756
training loss: 14.30368
training loss: 18.33001
training loss: 16.83039
training loss: 17.34998
training loss: 15.39408
training loss: 15.08411
training loss: 13.72704
training loss: 17.56810
training loss: 18.66240
training loss: 17.71991
training loss: 11.07446
training loss: 13.57018
training loss: 14.60255
training loss: 11.66486
training loss: 18.37077
training loss: 15.58331
training loss: 11.95313
training loss: 11.71081
training loss: nan
training loss: 22.32624
training loss: 15.37028
training loss: 10.37982
training loss: 12.54079
training loss: 16.79649
training loss: 12.91260
training loss: 17.98546
training loss: 19.62871
training loss: 14.31425
training loss: 14.25128
training loss: 11.62339
training loss: 10.84178
training loss: 13.52804
training loss: 13.02044
training loss: 13.51081
training loss: 10.75814
training loss: 11.53032
training loss: 15.57020
training loss: 15.76321
training loss: 13.66612
training loss: 14.18013
training loss: 14.28827
training loss: 15.21795
training loss: 16.15276
training loss: 14.66127
training loss: 14.73308
training loss: 15.49641
training loss: 13.61985
training loss: 18.15110
training loss: 13.49767
training loss: 17.84401
training loss: 12.94701
training loss: 19.33511
training loss: 16.19459
training loss: 14.76883
training loss: 17.38710
training loss: 13.37656
training loss: 13.53154
training loss: 14.46096
training loss: 18.18648
training loss: 12.08967
training loss: 13.34981
training loss: 14.54165
training loss: 15.12567
training loss: 15.57958
training loss: 13.21050
training loss: 11.73996
training loss: 14.80635
training loss: 14.49697
training loss: 22.53003
training loss: 12.50908
training loss: 16.67737
training loss: 14.11151
training loss: 12.99392
training loss: 15.18962
training loss: 14.98667
training loss: 19.62638
training loss: 14.65967
training loss: 20.37872
training loss: 12.01170
training loss: 18.97917
training loss: 15.37008
training loss: 15.72124
training loss: 15.20191
training loss: 17.39840
training loss: 33.14590
training loss: 9.62346
training loss: 16.06656
training loss: 19.51359
training loss: 13.61661
training loss: 12.50328
training loss: 14.21757
training loss: 18.05335
training loss: 19.08981
training loss: 12.35640
training loss: 15.30499
training loss: 18.86386
training loss: 15.06026
training loss: 12.63350
training loss: 14.07870
training loss: 17.39393
training loss: 18.40737
training loss: 15.52379
training loss: 12.60721
training loss: 10.59603
training loss: 9.21497
training loss: 16.55130
training loss: 11.77480
training loss: 13.03925
training loss: 14.93582
training loss: 17.35337
training loss: 12.60910
training loss: 13.12623
training loss: 13.13410
training loss: 15.18520
training loss: 15.66140
training loss: 18.62612
training loss: 16.86010
training loss: 16.62171
training loss: 14.94373
training loss: 15.87555
training loss: 22.63736
training loss: 13.95438
training loss: 17.85257
training loss: 14.66273
training loss: 13.23851
training loss: 15.78971
training loss: 21.32829
training loss: 14.13332
training loss: 14.06033
training loss: 13.96196
training loss: 12.84600
training loss: 14.66403
training loss: 15.39243
training loss: 12.87251
training loss: 15.93926
training loss: 16.32624
training loss: 15.81649
training loss: 11.25729
training loss: 14.29157
training loss: 15.59051
training loss: 18.15233
training loss: 19.91218
training loss: 13.75922
training loss: 15.97927
training loss: 13.55646
training loss: 15.78438
training loss: 13.04351
training loss: 14.39098
training loss: 13.86650
training loss: 16.99776
training loss: 14.69626
training loss: 13.86287
training loss: 17.37081
training loss: 14.80476
training loss: 14.54636
training loss: 13.50830
training loss: 12.98096
training loss: 18.14326
training loss: 14.84334
training loss: 15.41397
training loss: 11.57765
training loss: 17.97919
training loss: 15.73313
training loss: 18.18678
training loss: 15.76736
training loss: 10.99139
training loss: 9.85589
training loss: 12.37091
training loss: 11.32703
training loss: 19.00000
training loss: 12.85032
training loss: 15.73883
training loss: 14.23463
training loss: 15.18738
training loss: 20.65587
training loss: 18.66142
training loss: 12.67038
training loss: 13.74454
training loss: 17.49380
training loss: 14.49293
training loss: 13.12050
training loss: 19.38284
training loss: 13.14920
training loss: 14.44591
training loss: 12.93483
training loss: 14.51714
training loss: 16.60571
training loss: 17.06522
training loss: 13.77766
training loss: 11.51832
training loss: 15.12855
training loss: 11.73042
training loss: 17.64244
training loss: 14.21833
training loss: 16.70098
training loss: 13.74494
training loss: 13.10118
training loss: 15.07021
training loss: 13.78900
training loss: 17.32619
training loss: 12.32412
training loss: 16.15004
training loss: 12.78037
training loss: 17.56778
training loss: 16.60014
training loss: 12.57046
training loss: 15.63198
training loss: 12.25297
training loss: 14.74938
training loss: 18.12220
training loss: 14.09830
training loss: 10.37170
training loss: 13.52637
training loss: 15.15648
training loss: 13.19064
training loss: 17.57982
training loss: 17.64493
training loss: 14.58391
training loss: 17.50751
training loss: 16.63083
training loss: 17.23816
training loss: 14.66269
training loss: 17.82989
training loss: 25.93540
training loss: 14.70713
training loss: 18.60532
training loss: 15.28830
training loss: 13.62443
training loss: 19.94738
training loss: 13.32695
training loss: 12.36518
training loss: 15.80606
training loss: 12.60097
training loss: 17.54520
training loss: 13.88900
training loss: 21.45321
training loss: 12.37490
training loss: 14.16281
training loss: 14.27333
training loss: 13.37218
training loss: 13.95156
training loss: 15.36164
training loss: 18.37021
training loss: 12.88732
training loss: 16.86629
training loss: 16.16603
training loss: 16.64132
training loss: 14.84675
training loss: 22.04441
training loss: 13.63562
training loss: 15.87210
training loss: 11.37103
training loss: 15.46136
training loss: 15.79103
training loss: 11.00227
training loss: 15.20206
training loss: 14.57766
training loss: 11.07592
training loss: 16.86405
training loss: 14.80707
training loss: 16.31796
training loss: 12.93343
training loss: 12.79301
training loss: 10.58101
training loss: 11.69081
training loss: 13.12972
training loss: 12.36668
training loss: 14.36520
training loss: 12.12004
training loss: 13.00724
training loss: 12.31123
training loss: 14.51415
training loss: 15.06317
training loss: 15.63953
training loss: 15.98516
training loss: 15.14095
training loss: 14.42981
training loss: 13.31815
training loss: 14.18409
training loss: 12.70304
training loss: 17.19176
training loss: 16.98499
training loss: 12.69894
training loss: 13.30607
training loss: 13.51757
training loss: 18.13709
training loss: 15.06146
training loss: 18.85770
training loss: 14.84136
training loss: 14.01845
training loss: 12.51763
training loss: 19.74905
training loss: 16.95126
training loss: 17.62480
training loss: 12.07799
training loss: 14.93320
training loss: 17.75561
training loss: 15.61380
training loss: 13.45241
training loss: 15.08942
training loss: 15.55742
training loss: 16.54194
training loss: 12.21264
training loss: 12.37330
training loss: 17.00220
training loss: 15.42466
training loss: 11.45238
training loss: 12.09748
training loss: 13.08202
training loss: 17.68349
training loss: 14.77532
training loss: 14.20504
training loss: 18.35823
training loss: 13.40862
training loss: 12.51787
training loss: 17.45358
training loss: 13.46179
training loss: 15.20329
training loss: 12.38110
training loss: 10.82676
training loss: 13.16015
training loss: 13.33939
training loss: 14.68947
training loss: 13.02180
training loss: 11.82800
training loss: 15.02583
training loss: 19.31318
training loss: 16.99990
training loss: 15.85425
training loss: 19.59160
training loss: 13.29998
training loss: 17.43964
training loss: 15.50334
training loss: 15.10096
training loss: 17.93691
training loss: 10.18388
training loss: 15.61097
training loss: 15.44092
training loss: 15.93161
training loss: 17.97827
training loss: 11.02268
training loss: 10.45676
training loss: 14.47998
training loss: 11.12800
training loss: 12.54168
training loss: 15.54376
training loss: 11.10154
training loss: 22.05003
training loss: 12.28774
training loss: 16.89724
training loss: 18.83877
training loss: 10.97434
training loss: 16.99005
training loss: 12.30601
training loss: 12.43761
training loss: 12.42938
training loss: 15.35510
training loss: 14.43727
training loss: 14.51330
training loss: 13.47160
training loss: 13.61941
training loss: 15.29491
training loss: 12.67592
training loss: 17.98110
training loss: 13.74182
training loss: 17.28779
training loss: 17.98969
training loss: 15.88962
training loss: 13.49055
training loss: 17.99154
training loss: 11.76305
training loss: 18.94055
training loss: 16.22604
training loss: 11.40415
training loss: 17.05590
training loss: 14.65217
training loss: 13.30935
training loss: 13.81405
training loss: 14.43894
training loss: 13.74939
training loss: 16.66425
training loss: 12.69053
training loss: 12.18136
training loss: 12.91831
training loss: 14.56489
training loss: 11.57906
training loss: 11.82986
training loss: 12.56042
training loss: 12.76814
training loss: 13.63696
training loss: 11.15203
training loss: 19.09582
training loss: 10.94331
training loss: 11.00296
training loss: 12.08082
training loss: 13.47553
training loss: 15.90782
training loss: 15.42533
training loss: 7.24609
training loss: 16.48561
training loss: 11.34222
training loss: 18.45718
training loss: 15.90256
training loss: 11.93915
training loss: 12.87033
training loss: 19.61763
training loss: 16.25844
training loss: 15.26779
training loss: nan
training loss: 16.81556
training loss: 21.61858
training loss: 14.89575
training loss: 22.10319
training loss: 14.82167
training loss: 16.11697
training loss: 16.46740
training loss: 15.96653
training loss: 11.38706
training loss: 14.11434
training loss: 22.64465
training loss: 19.90459
training loss: 18.03140
training loss: 18.57887
training loss: 15.35028
training loss: 14.94509
training loss: 17.19139
training loss: 15.51445
training loss: 12.99975
training loss: 15.84437
training loss: 12.81887
training loss: 17.40178
training loss: 14.85050
training loss: 15.90146
training loss: 12.17791
training loss: 13.06017
training loss: 14.81011
training loss: 11.92066
training loss: 16.57366
training loss: 14.64395
training loss: 11.42270
training loss: 17.20851
training loss: 15.48059
training loss: 10.20792
training loss: 12.79802
training loss: nan
training loss: 15.17202
training loss: nan
training loss: 16.88116
training loss: 13.34301
training loss: 15.80205
training loss: 13.25133
training loss: 16.97361
training loss: 13.30849
training loss: 14.89958
training loss: 13.59153
training loss: 18.47929
training loss: 18.37911
training loss: 15.11110
training loss: 20.53129
training loss: 10.52338
training loss: 17.57642
training loss: 12.31010
training loss: 20.42005
training loss: 16.87854
training loss: 15.34579
training loss: 13.76140
training loss: 14.10116
training loss: 13.63543
training loss: 12.66149
training loss: 12.21361
training loss: 13.78024
training loss: 15.65253
training loss: 15.97521
training loss: 14.53887
training loss: 15.56168
training loss: 17.00757
training loss: 12.55503
training loss: 16.86808
training loss: 13.33864
training loss: 17.84417
training loss: 13.80127
training loss: 16.95842
training loss: 12.40106
training loss: 15.72343
training loss: 13.90098
training loss: 15.52623
training loss: 14.00489
training loss: 15.00502
training loss: 12.05676
training loss: 10.52128
training loss: 19.08325
training loss: 15.97136
training loss: 14.50388
training loss: 15.59794
training loss: 14.71169
training loss: 15.16038
training loss: 11.17205
training loss: 14.91378
training loss: 9.05535
training loss: 12.36606
training loss: 16.27610
training loss: 13.47126
training loss: 18.86655
training loss: 19.68410
training loss: 15.01778
training loss: 16.08148
training loss: 13.76889
training loss: 14.43904
training loss: 15.32148
training loss: 15.99462
training loss: 13.60060
training loss: 14.50296
training loss: 15.71590
training loss: 12.89819
training loss: 15.39932
training loss: 16.54745
training loss: 16.01390
training loss: 19.02405
training loss: 15.39346
training loss: 13.64580
training loss: 12.60525
training loss: 15.08712
training loss: 13.22744
training loss: 17.01779
training loss: 14.71777
training loss: 14.72567
training loss: 15.70732
training loss: 14.66168
training loss: 14.08134
training loss: 18.93707
training loss: 14.54346
training loss: 13.14636
training loss: 18.04761
training loss: 11.59907
training loss: 13.59381
training loss: 10.88411
training loss: 12.36802
training loss: 13.61541
training loss: 13.12430
training loss: 17.04401
training loss: 16.74696
training loss: 17.05363
training loss: 12.13917
training loss: 16.00532
training loss: 9.42274
training loss: 13.91433
training loss: 10.60395
training loss: 23.17574
training loss: 14.20760
training loss: 14.22172
training loss: 15.12600
training loss: 16.28984
training loss: 21.61848
training loss: 13.32080
training loss: 12.97338
training loss: 16.72724
training loss: 14.33780
training loss: 14.34738
training loss: 12.55439
training loss: 12.08263
training loss: 16.67282
training loss: 10.18106
training loss: 14.11105
training loss: 13.05777
training loss: 14.22013
training loss: 12.47992
training loss: 15.70068
training loss: 12.89537
training loss: 14.77552
training loss: 15.53554
training loss: 14.52106
training loss: 16.47646
training loss: 15.26611
training loss: 14.10180
training loss: 17.02654
training loss: 16.56976
training loss: 15.59417
training loss: 19.52456
training loss: 14.26233
training loss: 12.82874
training loss: 11.92278
training loss: 17.48302
training loss: 12.89039
training loss: 10.68813
training loss: 12.48068
training loss: 13.35539
training loss: 14.42774
training loss: 14.56723
training loss: 15.30088
training loss: 11.68431
training loss: 11.92251
training loss: 10.92721
training loss: 17.10800
training loss: 17.46642
training loss: 9.36169
training loss: 15.74231
training loss: 41.29929
training loss: 12.98464
training loss: 12.01456
training loss: 13.00426
training loss: 13.36675
training loss: 12.85705
training loss: 10.68665
training loss: 11.93116
training loss: 11.22604
training loss: 14.09067
training loss: 13.94783
training loss: 19.79249
training loss: 14.07442
training loss: 12.57979
training loss: 14.23460
training loss: 11.11230
training loss: 18.24018
training loss: 13.21261
training loss: 14.04973
training loss: 14.93300
training loss: 15.75680
training loss: 16.61889
training loss: 16.80156
training loss: 15.72304
training loss: 10.92640
training loss: 19.34168
training loss: 13.33442
training loss: 18.18631
training loss: 12.41020
training loss: 18.02468
training loss: 14.76128
training loss: 13.24433
training loss: 14.46482
training loss: 14.19671
training loss: 14.03889
training loss: 20.38165
training loss: 13.55577
training loss: 14.47391
training loss: 12.67320
training loss: 12.28112
training loss: 11.52650
training loss: 21.71292
training loss: 13.33420
training loss: 12.96716
training loss: 16.11415
training loss: 19.38665
training loss: 10.67089
training loss: 16.47468
training loss: 14.75968
training loss: 12.62912
training loss: 12.70779
training loss: 13.22285
training loss: 9.67947
training loss: 14.67369
training loss: 13.21896
training loss: 14.70289
training loss: 11.83695
training loss: 11.17787
training loss: 20.12052
training loss: 16.55714
training loss: 17.85447
training loss: 13.09219
training loss: 13.29441
training loss: 10.84702
training loss: 13.21832
training loss: 21.54625
training loss: 13.79091
training loss: 12.65722
training loss: 13.89594
training loss: 19.65946
training loss: 16.60168
training loss: 16.54495
training loss: 15.37654
training loss: 14.35560
training loss: 10.67522
training loss: 18.49310
training loss: 16.59136
training loss: 12.88344
training loss: 13.02422
training loss: 13.31674
training loss: 18.29855
training loss: 12.30307
training loss: 13.71086
training loss: 14.44349
training loss: 11.79667
training loss: 13.04455
training loss: 14.58748
training loss: 17.15518
training loss: 14.25914
training loss: 14.72166
training loss: 18.53387
training loss: 11.20216
training loss: 16.37291
training loss: 12.76245
training loss: 18.84534
training loss: 13.07410
training loss: 13.92569
training loss: 19.01923
training loss: 15.74969
training loss: 14.59820
training loss: 12.64787
training loss: 18.99041
training loss: 18.34042
training loss: 13.76653
training loss: 12.31621
training loss: 14.56093
training loss: 16.02265
training loss: 18.87902
training loss: 13.47023
training loss: 16.49190
training loss: 15.77985
training loss: 14.85345
training loss: 15.62239
training loss: 16.07070
training loss: 12.82698
training loss: 17.28707
training loss: 14.63592
training loss: 15.44941
training loss: 17.09980
training loss: 14.67637
training loss: 15.12426
training loss: 18.54529
training loss: 11.96529
training loss: 13.98618
training loss: 16.54770
training loss: 15.11240
training loss: 16.28394
training loss: 14.55427
training loss: 13.60318
training loss: 16.47222
training loss: 13.93517
training loss: 12.35956
training loss: 9.49574
training loss: 16.20607
training loss: 11.53426
training loss: 11.29558
training loss: 10.76781
training loss: 13.00760
training loss: 18.01821
training loss: 14.71089
training loss: 13.95183
training loss: 17.68630
training loss: 13.84566
training loss: 15.19357
training loss: 14.18140
training loss: 12.17800
training loss: 23.73191
training loss: 16.37554
training loss: 15.42369
training loss: 13.66496
training loss: 15.89162
training loss: 13.83919
training loss: 10.74000
training loss: 15.87656
training loss: 14.41561
training loss: 11.92607
training loss: 13.15991
training loss: 14.79695
training loss: 15.98289
training loss: 12.33091
training loss: 13.66783
training loss: 15.79881
training loss: 16.02767
training loss: 17.54314
training loss: 14.62580
training loss: 12.54981
training loss: 15.08861
training loss: 13.63038
training loss: 15.73928
training loss: 17.89972
training loss: 16.69334
training loss: 12.78648
training loss: 12.05936
training loss: 16.67875
training loss: 14.23436
training loss: 17.14676
training loss: 25.07215
training loss: 12.93839
training loss: 15.80129
training loss: 12.72707
training loss: 14.65035
training loss: 18.37826
training loss: 13.98296
training loss: 12.96674
training loss: 12.14207
training loss: 15.58294
training loss: 15.95055
training loss: 11.85138
training loss: 14.49806
training loss: 14.13189
training loss: 19.65899
training loss: 14.02042
training loss: 11.95552
training loss: 16.20563
training loss: 15.21498
training loss: 14.01760
training loss: 10.73252
training loss: 13.42872
training loss: 13.09558
training loss: 14.57200
training loss: 15.75148
training loss: 12.65913
training loss: 11.10479
training loss: 17.21622
training loss: 17.20009
training loss: 15.33737
training loss: 15.10137
training loss: 14.59288
training loss: 18.45850
training loss: 17.03306
training loss: 14.76288
training loss: 12.60989
training loss: 11.84151
training loss: 16.62508
training loss: 9.24397
training loss: 15.78578
training loss: 14.48904
training loss: 16.79537
training loss: 13.09095
training loss: 12.60708
training loss: 15.55487
training loss: 10.08738
training loss: 15.02813
training loss: 13.14126
training loss: 20.83872
training loss: 16.11192
training loss: 14.71592
training loss: 17.32829
training loss: 17.36685
training loss: 19.62445
training loss: 13.36673
training loss: 14.04202
training loss: 13.81270
training loss: 14.98443
training loss: 13.37888
training loss: 15.14381
training loss: 12.01498
training loss: 15.35903
training loss: 10.82061
training loss: 12.80710
training loss: 13.31550
training loss: 11.70618
training loss: 12.90997
training loss: 13.30362
training loss: 12.15996
training loss: 16.78664
training loss: 19.95422
training loss: 10.58721
training loss: 19.51470
training loss: 14.73962
training loss: 12.05411
training loss: 8.17754
training loss: 14.93436
training loss: 13.29337
training loss: 16.51381
training loss: 12.55094
training loss: 12.67483
training loss: 12.83459
training loss: 17.06376
training loss: 13.92192
training loss: 13.54967
training loss: 11.16869
training loss: 18.59246
training loss: 13.10506
training loss: 18.47753
training loss: 16.83798
training loss: 10.80436
training loss: 12.72306
training loss: 12.70293
training loss: 12.13246
training loss: 12.03434
training loss: 9.28648
training loss: 16.94163
training loss: 13.69595
training loss: 15.87301
training loss: 22.04301
training loss: 12.87741
training loss: 14.92225
training loss: 17.75973
training loss: 14.57262
training loss: 12.88552
training loss: 12.11427
training loss: 11.60461
training loss: 13.73605
training loss: 14.42566
training loss: 10.70785
training loss: 15.86626
training loss: 17.75373
training loss: 15.47410
training loss: 10.32369
training loss: 15.45728
training loss: 13.21453
training loss: 20.28385
training loss: 16.14320
training loss: 13.96628
training loss: 11.62439
training loss: 12.57796
training loss: 13.53441
training loss: 10.02702
training loss: 13.26872
training loss: 12.70185
training loss: 16.50124
training loss: 10.18525
training loss: 13.28493
training loss: 15.40407
training loss: 13.66672
training loss: 16.05461
training loss: 13.13608
training loss: 15.16543
training loss: 16.44106
training loss: 13.48147
training loss: 16.14011
training loss: 11.91086
training loss: 19.68306
training loss: 16.85546
training loss: 14.65345
training loss: 12.90948
training loss: 13.83731
training loss: 13.93151
training loss: 14.35096
training loss: 12.42896
training loss: 13.57195
training loss: 16.48449
training loss: 15.99256
training loss: 15.65304
training loss: 19.62319
training loss: 15.15046
training loss: 11.30273
training loss: 9.35759
training loss: 14.00321
training loss: 12.64570
training loss: 14.91439
training loss: 15.93829
training loss: 17.30337
training loss: 17.91395
training loss: 12.80525
training loss: 14.44177
training loss: 16.87278
training loss: 13.04230
training loss: 15.43736
training loss: 17.82212
training loss: 11.79341
training loss: 10.86631
training loss: 12.93557
training loss: 14.78513
training loss: 15.12327
training loss: 13.97712
training loss: 11.90216
training loss: 16.14374
training loss: 17.01241
training loss: 15.01693
training loss: 13.67502
training loss: 17.38733
training loss: 13.23714
training loss: 17.69749
training loss: 14.57637
training loss: 14.09867
training loss: 12.81306
training loss: 14.70813
training loss: 14.64179
training loss: 10.77217
training loss: 11.63586
training loss: 15.06316
training loss: 13.43502
training loss: 11.98907
[2025-03-12 19:28:15,738] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 19:28:15,748] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 19:28:15,748] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 19:28:15,755] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
training loss: 12.42006
training loss: 15.86675
training loss: 11.88698
training loss: 12.36786
training loss: 16.00180
training loss: 13.80670
training loss: 15.38747
training loss: 20.68777
training loss: 12.05666
training loss: 12.31236
training loss: 14.51035
training loss: 14.24082
training loss: 18.26959
training loss: 15.41800
training loss: 15.07160
training loss: 15.10764
training loss: 14.04840
training loss: 12.35919
training loss: 13.60806
training loss: 16.49658
training loss: 12.56274
training loss: 14.60700
training loss: 9.68773
training loss: 11.50275
training loss: 18.13736
training loss: 17.32131
training loss: 16.44694
training loss: 13.69343
training loss: 12.27938
training loss: 10.35775
training loss: 16.22853
training loss: 12.68486
training loss: 14.43128
training loss: 14.65941
training loss: 14.01312
training loss: 12.84619
training loss: 13.80171
training loss: 13.67337
training loss: 14.19868
training loss: 14.94287
training loss: 8.70589
training loss: 14.02521
training loss: 17.02220
training loss: 12.53040
training loss: 11.67613
training loss: 12.96272
training loss: 14.03947
training loss: 16.79652
training loss: 16.12670
training loss: 15.88549
training loss: 14.44920
training loss: 14.91724
training loss: 13.62876
training loss: 15.61565
training loss: 12.49183
training loss: 22.24749
training loss: 12.95929
training loss: 10.28267
training loss: 15.34485
training loss: 11.93016
training loss: 15.87726
training loss: 17.39322
training loss: 15.94382
training loss: 12.82332
training loss: 18.43914
training loss: 14.53211
training loss: 10.20651
training loss: 12.74391
training loss: 15.13175
training loss: 12.27314
training loss: 21.16740
training loss: 17.03242
training loss: 20.07701
training loss: 14.26582
training loss: 17.91407
training loss: 15.11685
training loss: 15.39164
training loss: 12.86323
training loss: 9.16526
training loss: 12.85523
training loss: 14.20571
training loss: 15.95726
training loss: 11.62959
training loss: 18.62270
training loss: 19.42616
training loss: 18.16100
training loss: 12.16534
training loss: 15.92447
training loss: 15.13107
training loss: 15.61310
training loss: 10.04967
training loss: 20.51300
training loss: 13.75790
training loss: 14.67215
training loss: 14.48154
training loss: 14.38745
training loss: 15.88525
training loss: 11.56281
training loss: 14.60523
training loss: 15.20769
training loss: 14.96768
training loss: 11.73629
training loss: nan
training loss: 19.11574
training loss: 13.98506
training loss: 11.46706
training loss: 13.92264
training loss: 14.61936
training loss: 13.41751
training loss: 15.02085
training loss: 15.02002
training loss: 17.11618
training loss: 10.32596
training loss: 15.99238
training loss: 18.24413
training loss: 15.44995
training loss: 13.60533
training loss: nan
training loss: 15.79115
training loss: 12.15740
training loss: 13.95033
training loss: 15.90447
training loss: 13.82991
training loss: 11.91841
training loss: 12.09981
training loss: 16.58821
training loss: 13.09863
training loss: 15.86917
training loss: 11.91021
training loss: 13.49740
training loss: 16.24991
training loss: 15.93843
training loss: 14.09562
training loss: 17.55130
training loss: 11.65222
training loss: 16.81263
training loss: 16.87972
training loss: 11.82014
training loss: 17.33226
training loss: 17.31872
training loss: 13.79899
training loss: 10.93698
training loss: 11.55391
training loss: 14.09973
training loss: 15.31171
training loss: 12.00677
training loss: 14.44540
training loss: 10.91331
training loss: 19.83623
training loss: 13.01692
training loss: 15.49190
training loss: 16.37429
training loss: 13.84718
training loss: 15.50403
training loss: 13.52658
training loss: 19.80181
training loss: 16.26705
training loss: 13.06662
training loss: 15.25215
training loss: 17.21061
training loss: 11.17928
training loss: 15.93371
training loss: 12.35559
training loss: 11.70713
training loss: 15.14093
training loss: nan
training loss: 19.76807
training loss: 11.55544
training loss: 12.25391
training loss: 12.63796
training loss: 12.84060
training loss: 7.83925
training loss: 11.22058
training loss: 13.89475
training loss: 14.81100
training loss: 12.67849
training loss: 11.01072
training loss: 8.88444
training loss: 16.68307
training loss: 12.05697
training loss: 12.37070
training loss: 14.62454
training loss: 23.14096
training loss: 12.21685
training loss: 11.70131
training loss: 16.09699
training loss: 11.98477
training loss: 14.71731
training loss: 13.65184
training loss: 14.55319
training loss: 11.30879
training loss: 12.63742
training loss: 16.77326
training loss: 14.14828
training loss: 13.62041
training loss: 17.05544
training loss: 13.82143
training loss: 14.89783
training loss: 11.46051
training loss: 16.03802
training loss: 11.04451
training loss: 16.45813
training loss: 15.31565
training loss: 13.45426
training loss: 18.78918
training loss: 9.59927
training loss: 15.66313
training loss: 13.26643
training loss: 12.26447
training loss: 13.82316
training loss: 10.63452
training loss: 15.70935
training loss: 14.28873
training loss: 13.78346
training loss: 13.14546
training loss: 15.32549
training loss: 12.04098
training loss: 13.12118
training loss: 18.72082
training loss: 17.24772
training loss: 15.46604
training loss: 12.47366
training loss: 11.92660
training loss: 15.41814
training loss: 16.33174
training loss: 11.94117
training loss: 17.18466
training loss: 14.00256
training loss: 13.85703
training loss: 13.40160
training loss: 17.16891
training loss: 14.39176
training loss: 13.87041
training loss: 12.46816
training loss: 9.97577
training loss: 11.57931
training loss: 16.53547
training loss: 11.44613
training loss: 12.48668
training loss: 16.33783
training loss: 16.17611
training loss: 15.08088
training loss: 13.32526
training loss: 14.06119
training loss: 16.39591
training loss: 13.94109
training loss: 11.43438
training loss: 16.87886
training loss: 17.67624
training loss: 14.52521
training loss: 14.53482
training loss: 10.75576
training loss: 12.92799
training loss: 14.82787
training loss: 17.78306
training loss: 14.00163
training loss: 16.38169
training loss: 18.36764
training loss: 13.62083
training loss: 12.75957
training loss: 17.02475
training loss: 13.51048
training loss: 16.31030
training loss: 14.52471
training loss: 15.27288
training loss: 16.80075
training loss: 16.80054
training loss: 15.38989
training loss: 13.00250
training loss: 9.85296
training loss: 14.99657
training loss: 11.93358
training loss: 13.93911
training loss: 14.62590
training loss: 15.36523
training loss: 13.95183
training loss: 13.78071
training loss: 13.44279
training loss: 14.77932
training loss: 15.81568
training loss: 14.04114
training loss: 11.39235
training loss: 13.17222
training loss: 11.78546
training loss: 14.86989
training loss: 13.22226
training loss: 12.22628
training loss: 13.20705
training loss: 13.38163
training loss: 17.42122
training loss: 14.70674
training loss: 15.58134
training loss: 14.26305
training loss: 9.78153
training loss: 21.11056
training loss: 16.98033
training loss: 15.37152
training loss: 15.86364
training loss: 21.24918
training loss: 13.55746
training loss: 17.59100
training loss: 12.15183
training loss: 12.16777
training loss: 14.09159
training loss: 11.82626
training loss: 22.54688
training loss: 17.79881
training loss: 15.60366
training loss: 13.10710
training loss: 18.55862
training loss: 19.47569
training loss: 13.91717
training loss: 15.90623
training loss: 14.98154
training loss: 9.69192
training loss: 19.84390
training loss: 13.41858
training loss: 10.86205
training loss: 14.64288
training loss: 14.20883
training loss: 7.32965
training loss: 15.41447
training loss: 11.64520
training loss: 17.80525
training loss: 13.76677
training loss: 11.06081
training loss: 19.95071
training loss: 17.99414
training loss: 16.70473
training loss: 12.05911
training loss: 14.93218
training loss: 13.22564
training loss: 15.81130
training loss: 17.46581
training loss: 10.70963
training loss: 14.13389
training loss: 15.03941
training loss: 17.75550
training loss: 19.99389
training loss: 9.91555
training loss: 13.74988
training loss: 19.68560
training loss: 12.01789
training loss: 8.85122
training loss: 12.13666
training loss: 16.69035
training loss: nan
training loss: 12.88371
training loss: 18.09061
training loss: 13.16863
training loss: 15.65817
training loss: 12.76554
training loss: 10.93163
training loss: 12.59919
training loss: 10.08811
training loss: 13.75725
training loss: 20.42580
training loss: 17.52287
training loss: 12.95480
training loss: 14.83636
training loss: 11.94877
training loss: 18.02587
training loss: 13.05862
training loss: 14.03027
training loss: 16.93291
training loss: 12.20184
training loss: 13.44299
training loss: 13.96366
training loss: 14.20279
training loss: 11.02627
training loss: 12.30509
training loss: 16.96756
training loss: 14.42625
training loss: 10.80145
training loss: 11.07746
training loss: 12.67613
training loss: 14.66675
training loss: 11.84232
training loss: 13.71675
training loss: 14.29762
training loss: 12.86748
training loss: 12.18422
training loss: 15.25122
training loss: 14.94906
training loss: 9.04695
training loss: 13.01603
training loss: 17.52241
training loss: 18.79422
training loss: 11.68287
training loss: 11.14785
training loss: 9.98411
training loss: 17.11505
training loss: 14.54420
training loss: 13.16111
training loss: 15.50527
training loss: 13.78180
training loss: 13.04589
training loss: 13.38784
training loss: 17.39107
training loss: 12.11717
training loss: 19.05498
training loss: 15.54276
training loss: 13.89923
training loss: 11.94735
training loss: 9.91992
training loss: 14.13296
training loss: 11.73504
training loss: 14.24345
training loss: 16.25319
training loss: 11.36435
training loss: 15.49810
training loss: 14.39660
training loss: 12.34046
training loss: 12.86337
training loss: 14.27180
training loss: 13.46222
training loss: 11.02944
training loss: 13.39044
training loss: 15.48535
training loss: 14.16514
training loss: 13.02250
training loss: 18.91129
training loss: 16.05553
training loss: 16.00376
training loss: 9.95187
training loss: 12.43800
training loss: 13.35509
training loss: 14.37593
training loss: 11.05614
training loss: 14.63793
training loss: 15.95026
training loss: 16.61232
training loss: 15.21227
training loss: 10.98822
training loss: 11.84834
training loss: 14.08980
training loss: 15.69454
training loss: 10.70504
training loss: 16.13865
training loss: 16.45650
training loss: 10.33093
training loss: 10.03435
training loss: 15.37969
training loss: 14.12723
training loss: 13.52151
training loss: 13.14930
training loss: 14.56265
training loss: 16.00373
training loss: 12.49188
training loss: 17.94105
training loss: 11.96123
training loss: 16.62232
training loss: 16.22245
training loss: 12.20571
training loss: 13.10015
training loss: 16.74148
training loss: 12.09398
training loss: 15.88811
training loss: 22.33653
training loss: 25.70689
training loss: 11.51873
training loss: 9.63684
training loss: 11.73249
training loss: 15.06250
training loss: 8.66880
training loss: 12.27590
training loss: 18.11042
training loss: 13.12080
training loss: 14.99196
training loss: 17.82477
training loss: 13.48082
training loss: 17.42664
training loss: 13.26933
training loss: 16.01402
training loss: 14.05906
training loss: 11.76118
training loss: 13.99353
training loss: 16.24619
training loss: 10.36433
training loss: 14.65521
training loss: 14.31058
training loss: 17.81497
training loss: 13.61128
training loss: 14.69944
training loss: 13.20025
training loss: 10.88786
training loss: 14.75402
training loss: 12.43125
training loss: 16.95626
training loss: 13.68711
training loss: 12.72316
training loss: 12.06557
training loss: 17.88860
training loss: 16.95505
training loss: 12.36789
training loss: 10.53669
training loss: 13.32754
training loss: 18.62502
training loss: 17.26231
training loss: 12.13896
training loss: 13.47987
training loss: 15.23880
training loss: 13.31321
training loss: 17.14418
training loss: 9.51220
training loss: 12.94691
training loss: 16.46087
training loss: 13.87332
training loss: 11.15124
training loss: 11.58643
training loss: 12.29341
training loss: 11.10284
training loss: 14.76635
training loss: 12.89664
training loss: 14.89553
training loss: 14.56912
training loss: 12.54724
training loss: 13.51792
training loss: 13.87427
training loss: 11.11208
training loss: 14.06824
training loss: 14.23316
training loss: 14.86425
training loss: 15.92543
training loss: 15.02670
training loss: 11.28056
training loss: 12.95226
training loss: 10.11720
training loss: 11.10057
training loss: 12.43190
training loss: 17.64690
training loss: 15.31274
training loss: 14.03285
training loss: 11.84273
training loss: 12.39397
training loss: 14.24557
training loss: 11.98140
training loss: 17.27938
training loss: 13.46038
training loss: 13.39077
training loss: 10.90272
training loss: 14.85065
training loss: 17.48812
training loss: 12.43799
training loss: 13.89246
training loss: 14.03208
training loss: 12.69674
training loss: 15.73681
training loss: 16.68161
training loss: 12.12871
training loss: 14.37040
training loss: 8.88354
training loss: 18.93312
training loss: 11.59737
training loss: 13.17785
training loss: 15.27077
training loss: 17.60625
training loss: 11.88715
training loss: 13.92554
training loss: 13.53958
training loss: 12.22515
training loss: 12.82776
training loss: 13.82366
training loss: 15.04878
training loss: 13.83594
training loss: 14.42979
training loss: 15.07355
training loss: 11.27300
training loss: 17.74712
training loss: 16.27949
training loss: 17.86504
training loss: 14.45345
training loss: 13.65372
training loss: 14.67715
training loss: 11.15593
training loss: 11.87389
training loss: 12.25192
training loss: 14.16509
training loss: 13.98861
training loss: 17.87627
training loss: 14.09086
training loss: 12.86260
training loss: 15.83256
training loss: 13.85758
training loss: 10.41327
training loss: 12.68151
training loss: 15.66107
training loss: 13.44533
training loss: 9.64181
training loss: 12.17394
training loss: 14.07086
training loss: 13.86043
training loss: 11.63689
training loss: 11.89424
training loss: 11.55733
training loss: 18.99525
training loss: 12.77144
training loss: 18.41388
training loss: 16.99198
training loss: 19.26454
training loss: 16.20440
training loss: 11.73018
training loss: 13.64633
training loss: 12.49209
training loss: 14.55039
training loss: 13.08264
training loss: 11.32889
training loss: 14.32701
training loss: 12.21084
training loss: 13.71372
training loss: 15.19305
training loss: 12.63513
training loss: 10.70644
training loss: 26.39858
training loss: 14.78241
training loss: 12.63906
training loss: 18.19239
training loss: 25.75273
training loss: 17.06894
training loss: 9.43661
training loss: 16.18633
training loss: 16.04786
training loss: 11.45955
training loss: 13.89370
training loss: 16.74323
training loss: 13.18208
training loss: 10.82562
training loss: 12.24764
training loss: 13.23369
training loss: 12.20623
training loss: 22.63287
training loss: 18.48904
training loss: 11.50229
training loss: 16.09125
training loss: 14.05558
training loss: 16.67434
training loss: 11.93371
training loss: 15.90940
training loss: 12.86326
training loss: 13.14359
training loss: 14.68017
training loss: 16.96699
training loss: nan
training loss: 13.83008
training loss: 13.00617
training loss: 11.25331
training loss: 12.79321
training loss: 15.50947
training loss: 18.56974
training loss: 11.62041
training loss: 17.50555
training loss: 13.01983
training loss: 13.95420
training loss: 19.06646
training loss: 12.60165
training loss: 14.54153
training loss: 13.37895
training loss: 14.80917
training loss: 14.98263
training loss: 11.30207
training loss: 10.99611
training loss: 13.41107
training loss: 10.77493
training loss: 12.67212
training loss: 15.71818
training loss: 15.68919
training loss: 12.45303
training loss: 15.77811
training loss: 18.50941
training loss: 19.16422
training loss: 15.35931
training loss: 14.06112
training loss: 9.03510
training loss: 14.75344
training loss: 13.52574
training loss: 12.57355
training loss: 11.59089
training loss: 15.29506
training loss: 14.66025
training loss: 18.29236
training loss: 13.22516
training loss: 14.84354
training loss: 17.24080
training loss: 11.63298
training loss: 19.05333
training loss: 17.12083
training loss: 12.96729
training loss: 9.68123
training loss: 15.55295
training loss: 16.46451
training loss: 14.99253
training loss: 13.91205
training loss: 11.84837
training loss: 15.50907
training loss: 12.58211
training loss: 16.60332
training loss: 21.70764
training loss: 14.69942
training loss: 17.34480
training loss: 13.19928
training loss: 13.65585
training loss: 14.33493
training loss: 13.04261
training loss: 17.94771
training loss: 13.97126
training loss: 14.44793
training loss: 14.90330
training loss: 15.40588
training loss: 10.92593
training loss: 9.82597
training loss: 14.43112
training loss: 17.65018
training loss: 18.45687
training loss: 14.61402
training loss: 12.31318
training loss: 14.92406
training loss: 12.58879
training loss: 16.89549
training loss: 12.67266
training loss: 15.81736
training loss: 15.18113
training loss: 14.17967
training loss: 14.54375
training loss: 17.92448
training loss: 27.00441
training loss: 12.35542
training loss: 14.56348
training loss: 13.11990
training loss: 13.30033
training loss: 15.75328
training loss: 17.72001
training loss: 7.83394
training loss: 14.34623
training loss: 13.63536
training loss: 11.58035
training loss: 9.70966
training loss: 9.61276
training loss: 14.14743
training loss: 15.96482
training loss: 15.52784
training loss: 14.79547
training loss: 18.01521
training loss: 11.88429
training loss: 12.31285
training loss: 7.61226
training loss: 13.32815
training loss: 15.72837
training loss: 11.13415
training loss: 15.43727
training loss: 16.54293
training loss: 15.03590
training loss: 13.66159
training loss: 13.59608
training loss: 20.84738
training loss: 15.08076
training loss: 12.65548
training loss: 12.99246
training loss: 12.11338
training loss: 13.70387
training loss: 14.50830
training loss: 14.29733
training loss: 17.37259
training loss: 14.95936
training loss: 12.65858
training loss: 14.06792
training loss: 21.34089
training loss: 13.06228
training loss: 17.88161
training loss: 14.67822
training loss: 12.12966
training loss: 12.83981
training loss: 13.60577
training loss: 12.14510
training loss: 15.00563
training loss: 13.50767
training loss: 14.89727
training loss: 15.57082
training loss: 14.63940
training loss: 11.11505
training loss: 15.88102
training loss: 11.93593
training loss: 13.53446
training loss: 14.01515
training loss: 13.40713
training loss: 12.02948
training loss: 13.75396
training loss: 10.96341
training loss: 13.62191
training loss: 17.09633
training loss: 10.68634
training loss: 19.25317
training loss: 18.98847
training loss: 9.26546
training loss: 14.65970
training loss: 12.96317
training loss: 13.38245
training loss: 9.55346
training loss: 17.56181
training loss: 9.62661
training loss: 16.40420
training loss: 12.53009
training loss: 14.37354
training loss: 10.58105
training loss: 18.13464
training loss: 19.68996
training loss: 14.77278
training loss: 14.46127
training loss: 14.21344
training loss: 17.39806
training loss: 16.75500
training loss: 16.85781
training loss: 8.52675
training loss: 15.05025
training loss: 18.99821
training loss: 14.42103
training loss: 10.89496
training loss: 12.89193
training loss: 13.46104
training loss: 13.56348
training loss: 15.61227
training loss: 14.80192
training loss: 17.33256
training loss: 13.19652
training loss: 14.84879
training loss: 13.93624
training loss: 14.24327
training loss: 14.01732
training loss: 10.38770
training loss: 10.78648
training loss: 14.71644
training loss: 13.56903
training loss: 10.45901
training loss: 19.85343
training loss: 13.77725
training loss: 11.83516
training loss: 9.81430
training loss: 16.19784
training loss: 14.99481
training loss: 16.48351
training loss: 16.28200
training loss: 11.63459
training loss: 10.74340
training loss: 12.10009
training loss: 15.78169
training loss: 12.37099
training loss: 14.49091
training loss: 13.25173
training loss: 10.33798
training loss: 15.28064
training loss: 11.82110
training loss: 19.26288
training loss: 11.28188
training loss: 11.29818
training loss: 12.97279
training loss: 9.23608
training loss: 17.02727
training loss: 9.82005
training loss: 14.85969
training loss: 17.77306
training loss: 14.68449
training loss: 14.42192
training loss: 20.13853
training loss: 13.77624
training loss: 10.92006
training loss: 14.02235
training loss: 12.63592
training loss: 20.55334
training loss: 16.21561
training loss: nan
training loss: 15.97548
training loss: 18.42574
training loss: 13.19818
training loss: 14.01404
training loss: 15.13853
training loss: 15.07451
training loss: 15.30984
training loss: 13.88208
training loss: 10.16696
training loss: 9.25513
training loss: 10.76382
training loss: 17.10007
training loss: 15.00244
training loss: 12.34592
training loss: 12.22730
training loss: 11.00307
training loss: 12.92000
training loss: 14.53625
training loss: 15.25284
training loss: 14.80396
training loss: 16.52600
training loss: 13.27887
training loss: 16.70967
training loss: 13.22631
training loss: 10.56813
training loss: 17.70929
training loss: 15.83722
training loss: 13.23148
training loss: 16.51116
training loss: 16.25134
training loss: 12.05443
training loss: 13.70543
training loss: 12.94552
training loss: 15.03537
training loss: 14.09336
training loss: 14.80390
training loss: 11.28002
training loss: 14.09967
training loss: 15.00091
training loss: 11.15869
training loss: 11.03183
training loss: 14.22065
training loss: 12.56976
training loss: 14.38572
training loss: 13.62577
training loss: 14.81200
training loss: 11.79081
training loss: 14.24378
training loss: 10.83913
training loss: 10.30579
training loss: 15.25553
training loss: 20.24282
training loss: 16.08851
training loss: 15.28708
training loss: 10.02816
training loss: 14.46239
training loss: 10.08930
training loss: 13.33798
training loss: 15.42570
training loss: 17.06829
training loss: 14.89905
training loss: 16.21381
training loss: 14.88880
training loss: 17.35639
training loss: 13.37087
training loss: 14.07189
training loss: 14.98197
training loss: 14.43020
training loss: 17.33726
training loss: 13.97962
training loss: 13.11750
training loss: 14.01397
training loss: 10.74485
training loss: 16.80570
training loss: 15.85880
training loss: 13.36341
training loss: 11.81471
training loss: 12.09566
training loss: 17.46411
training loss: 10.42852
training loss: 14.91285
training loss: 15.57733
training loss: 13.95875
training loss: 17.68447
training loss: 18.39404
training loss: 14.61644
training loss: 12.72969
training loss: 15.02296
training loss: 8.77036
training loss: 13.48471
training loss: 21.57715
training loss: 17.34937
training loss: 12.03340
training loss: 19.63940
training loss: 17.86592
training loss: 10.19424
training loss: 18.45389
training loss: 16.15263
training loss: 12.98808
training loss: 19.63515
training loss: 12.37060
training loss: 12.94961
training loss: 15.04455
training loss: 12.61105
training loss: 14.90669
training loss: 14.40416
training loss: 11.75251
training loss: 13.33261
training loss: 13.96508
training loss: 16.29153
training loss: 10.09456
training loss: 17.14258
training loss: 13.39796
training loss: 11.12147
training loss: 15.74605
training loss: 14.16285
training loss: 18.76579
training loss: 16.75888
training loss: 11.92754
training loss: 10.88545
training loss: 19.07395
training loss: 9.95871
training loss: 11.35742
training loss: 13.26149
training loss: 12.09419
training loss: 12.96607
training loss: 14.57656
training loss: 17.23750
training loss: 12.01180
training loss: 12.13996
training loss: 13.61737
training loss: 13.27147
training loss: 14.07956
training loss: 19.20824
training loss: 20.49808
training loss: 14.46371
training loss: 16.30810
training loss: 14.60510
training loss: 14.30922
training loss: 13.84711
training loss: 18.83503
training loss: 13.48112
training loss: 13.10758
training loss: 12.86058
training loss: 13.77274
training loss: 13.88499
training loss: 19.02476
training loss: 12.31561
training loss: 14.39944
training loss: 13.32246
training loss: 13.93239
training loss: 15.39859
training loss: 10.65070
training loss: 13.52317
training loss: 9.78964
training loss: 14.53181
training loss: 15.81045
training loss: 11.67699
training loss: 15.23116
training loss: 14.76401
training loss: 15.68068
training loss: 19.02649
training loss: 15.81977
training loss: 15.66116
training loss: 12.24773
training loss: 16.73045
training loss: 13.81810
training loss: 12.78523
training loss: 10.23967
training loss: 22.44283
training loss: 13.33082
training loss: 14.28548
training loss: 12.51378
training loss: 12.49205
training loss: 18.36684
training loss: 16.78907
training loss: 14.79019
training loss: 13.95701
training loss: 12.63596
training loss: 14.03780
training loss: 14.25361
training loss: 12.75572
training loss: 15.23268
training loss: 10.73569
training loss: 13.81422
training loss: 12.68900
training loss: 16.88853
training loss: 13.33522
training loss: 12.40272
training loss: 15.16413
training loss: 13.79952
training loss: 9.02220
training loss: 14.80604
training loss: 14.67656
training loss: 12.69856
training loss: 13.22168
training loss: 14.68949
training loss: 14.20397
training loss: 13.81791
training loss: 13.48095
training loss: 13.29889
training loss: 11.66271
training loss: 12.04922
training loss: 13.10355
training loss: 15.11877
training loss: 17.91324
training loss: 11.32448
training loss: 13.75826
training loss: 9.05386
training loss: 17.03489
training loss: 14.64848
training loss: 16.51552
training loss: 12.63977
training loss: 13.82027
training loss: 12.39929
training loss: 16.78902
training loss: 15.02619
training loss: 17.82132
training loss: 13.26901
training loss: 20.05259
training loss: 17.84138
training loss: 16.89056
training loss: 15.55231
training loss: 15.18231
training loss: 13.87277
training loss: 19.01709
training loss: 12.73472
training loss: 15.02016
training loss: 12.75895
training loss: 13.05426
training loss: 12.95049
training loss: 11.77835
training loss: 14.26418
training loss: 16.92996
training loss: 12.92100
training loss: 14.51440
training loss: 16.79466
training loss: 11.33246
training loss: 13.78250
training loss: 14.82537
training loss: 13.88655
training loss: 14.25367
training loss: 13.80237
training loss: 13.54800
training loss: 11.88315
training loss: 13.41399
training loss: 15.09850
training loss: 14.34167
training loss: 15.34948
training loss: 10.57333
training loss: 13.85384
training loss: 14.81009
training loss: 11.17171
training loss: 16.87579
training loss: nan
training loss: 9.09721
training loss: 11.66010
training loss: 14.40080
training loss: 13.20337
training loss: 14.67882
training loss: 15.39128
training loss: 13.80184
training loss: 13.38887
training loss: 16.09441
training loss: 19.23003
training loss: 15.30636
training loss: 13.20730
training loss: 15.10927
training loss: 18.23015
training loss: 16.16039
training loss: 12.94526
training loss: 13.97172
training loss: 10.54838
training loss: 18.21782
training loss: 11.28233
training loss: 12.99535
training loss: 15.14145
training loss: 13.93628
training loss: 10.75726
training loss: 14.29811
training loss: 12.34550
training loss: 16.37358
training loss: 11.13961
training loss: 14.26273
training loss: 17.22686
training loss: 14.32001
training loss: 15.92306
training loss: 10.84306
training loss: 13.74533
training loss: 20.96766
training loss: 19.06906
training loss: 12.25157
training loss: 11.45228
training loss: 13.50278
training loss: 15.51467
training loss: 17.59631
training loss: 10.20714
training loss: 14.08140
training loss: 13.04534
training loss: 15.58043
training loss: 11.11407
training loss: 16.64649
training loss: 20.02515
training loss: 14.29563
training loss: 14.76892
training loss: 13.19578
training loss: 14.50534
training loss: 13.68903
training loss: 15.47682
training loss: 9.87809
training loss: 12.09925
training loss: 15.41873
training loss: 14.10007
training loss: 11.89736
training loss: 16.04865
training loss: 16.51357
training loss: 14.16543
training loss: 12.97274
training loss: 15.62746
training loss: 11.68181
training loss: 14.61837
training loss: 14.89694
training loss: 12.90538
training loss: 14.76155
training loss: 10.19917
training loss: 14.94821
training loss: 13.25170
training loss: 13.51616
training loss: 13.59496
training loss: 12.55731
training loss: 12.11265
training loss: 11.26310
training loss: 16.42384
training loss: 11.35459
training loss: 11.61285
training loss: 10.81950
training loss: 13.22127
training loss: 11.73955
training loss: 22.44620
training loss: 13.95514
training loss: 14.70751
training loss: 13.55731
training loss: 13.10929
training loss: 16.43856
training loss: 12.95693
training loss: 13.89486
training loss: 15.31381
training loss: 18.06421
training loss: 13.84765
training loss: 13.98921
training loss: 16.15019
training loss: 20.84139
training loss: 18.70869
training loss: 19.22462
training loss: nan
training loss: 14.12775
training loss: 13.28117
training loss: 14.95257
training loss: 11.43094
training loss: 10.79149
training loss: 12.76427
training loss: 16.11525
training loss: 15.29096
training loss: 12.27018
training loss: 13.89168
training loss: 18.26444
training loss: 15.41385
training loss: 13.38464
training loss: 16.16555
training loss: 14.58978
training loss: 11.62634
training loss: 16.84789
training loss: 14.10815
training loss: 12.80481
training loss: 12.73916
training loss: 14.00284
training loss: 15.84849
training loss: 17.72292
training loss: 16.23498
training loss: 12.61254
training loss: 15.93332
training loss: 12.22421
training loss: 14.32317
training loss: 16.39319
training loss: 12.68814
training loss: 11.08686
training loss: 11.52995
training loss: 19.35400
training loss: 12.76040
training loss: 11.05010
training loss: 11.66129
training loss: 12.95310
training loss: 13.48967
training loss: 15.13914
training loss: 12.71435
training loss: 11.43791
training loss: 15.31652
training loss: 16.91275
training loss: 14.84557
training loss: 11.42239
training loss: 13.35429
training loss: 19.29009
training loss: 16.88347
training loss: 13.04481
training loss: 19.86843
training loss: 14.94776
training loss: 13.43041
training loss: 12.31907
training loss: 13.35424
training loss: 11.27363
training loss: 16.50022
training loss: 14.66495
training loss: 16.13956
training loss: 12.97895
training loss: 13.01827
training loss: 12.28629
training loss: 11.75298
training loss: 18.48228
training loss: 13.21979
training loss: 18.50275
training loss: 16.62580
training loss: 14.38381
training loss: 12.36110
training loss: 13.85248
training loss: 11.87449
training loss: 12.54739
training loss: 8.67204
training loss: 11.69187
training loss: 16.53304
training loss: 11.10097
training loss: 11.63028
training loss: 11.47279
training loss: 11.78366
training loss: 16.16452
training loss: 16.93388
training loss: 17.89895
training loss: 12.80960
training loss: 12.93979
training loss: 11.87498
training loss: 10.47884
training loss: 12.27201
training loss: 11.31818
training loss: 12.96640
training loss: 14.09179
training loss: 18.16755
training loss: 16.83390
training loss: 18.18846
training loss: 14.18688
training loss: 13.55307
training loss: 11.28180
training loss: 13.61991
training loss: 12.98151
training loss: 14.69658
training loss: 11.14288
training loss: nan
training loss: 16.01600
training loss: 17.70363
training loss: 11.65778
training loss: 17.61103
training loss: 10.46839
training loss: 15.54605
training loss: 17.86299
training loss: 16.84826
training loss: 12.90389
training loss: 13.80175
training loss: 11.57460
training loss: 18.00811
training loss: 11.20391
training loss: 12.81087
training loss: 16.54306
training loss: 24.61195
training loss: 19.03746
training loss: 12.83712
training loss: 12.22408
training loss: 18.92274
training loss: 14.36875
training loss: 11.82526
training loss: 15.43232
training loss: 14.33531
training loss: 12.85200
training loss: 12.54008
training loss: 18.94650
training loss: 15.72797
training loss: 12.66676
training loss: 13.75368
training loss: 14.08534
training loss: 18.55871
training loss: 14.19634
training loss: 11.94219
training loss: 17.37187
training loss: 16.69434
training loss: 13.30155
training loss: 13.58298
training loss: 15.53670
training loss: 11.22645
training loss: 14.58697
training loss: 15.51563
training loss: 13.02658
training loss: 10.67087
training loss: 11.72934
training loss: 19.93814
training loss: 11.04357
training loss: 11.59258
training loss: 15.54637
training loss: 14.10442
training loss: 17.73863
training loss: 14.73902
training loss: 13.57515
training loss: 13.13972
training loss: 15.06641
training loss: 13.25648
training loss: 13.97701
training loss: 15.67302
training loss: 13.10486
training loss: 16.81755
training loss: 18.97127
training loss: 12.98017
training loss: 11.92273
training loss: 18.16016
training loss: 12.06596
training loss: 14.42810
training loss: 10.82810
training loss: 15.42993
training loss: 13.60579
training loss: 17.26660
training loss: 12.47332
training loss: 14.22549
training loss: 12.68594
training loss: 18.17856
training loss: 12.31705
training loss: 13.63435
training loss: 10.88348
training loss: 10.24273
training loss: 11.60052
training loss: 19.23433
training loss: 14.47361
training loss: 12.24245
training loss: 18.46497
training loss: 10.97224
training loss: 11.96819
training loss: 19.75222
training loss: 18.92248
training loss: 12.11562
training loss: 19.25526
training loss: 13.24062
training loss: 14.15528
training loss: 14.43134
training loss: 13.09740
training loss: 12.69497
training loss: 15.80741
training loss: 10.42003
training loss: 18.28882
training loss: 16.06602
training loss: 10.40488
training loss: 14.84416
training loss: 16.99670
training loss: 14.60673
training loss: 11.43044
training loss: 13.22688
training loss: 11.52192
training loss: 11.24684
training loss: 15.64005
training loss: 12.61412
training loss: 12.76904
training loss: 11.97345
training loss: 12.37148
training loss: 17.28334
training loss: 15.14359
training loss: 11.87403
training loss: 15.83684
training loss: 11.89394
training loss: 13.85243
training loss: 17.08515
training loss: 15.60325
training loss: 11.10234
training loss: 14.31563
training loss: 10.51526
training loss: 17.14864
training loss: 12.67427
training loss: 15.66974
training loss: 14.95828
training loss: 15.06523
training loss: 13.37510
training loss: 14.78681
training loss: 12.18059
training loss: 10.04554
training loss: 11.68869
training loss: 11.27793
training loss: 13.96885
training loss: 17.81220
training loss: 15.39659
training loss: 15.08522
training loss: 11.64970
training loss: 13.58996
training loss: 16.66902
training loss: 17.13037
training loss: 13.21848
training loss: 12.54115
training loss: 11.87897
training loss: 15.22648
training loss: 17.95615
training loss: 14.70506
training loss: 15.17078
training loss: 14.09377
training loss: 12.58537
training loss: 12.60372
training loss: 18.83670
training loss: 9.74317
training loss: 18.87613
training loss: 14.30063
training loss: 12.53687
training loss: 11.44719
training loss: 20.46237
training loss: 15.92360
training loss: 15.00850
training loss: 12.40503
training loss: 16.40393
training loss: 10.47377
training loss: 10.50954
training loss: 12.99824
training loss: 16.89401
training loss: 15.26860
training loss: 14.30183
training loss: 10.37104
training loss: 13.60725
training loss: 13.21066
training loss: 16.81838
training loss: 13.55736
training loss: 18.51834
training loss: 17.48616
training loss: 12.24099
training loss: 11.33640
training loss: 13.05030
training loss: 14.80189
training loss: 14.30800
training loss: 14.40608
training loss: 13.79686
training loss: 17.07077
training loss: 17.03049
training loss: 11.60423
training loss: 10.96591
training loss: 10.94997
training loss: 8.72410
training loss: 14.39466
training loss: 9.65200
training loss: 10.79778
training loss: 15.52405
training loss: 15.17398
training loss: 14.94533
training loss: 11.01047
training loss: 19.29537
training loss: 13.56109
training loss: 11.13651
training loss: 13.93786
training loss: 15.67759
training loss: 13.07506
training loss: 14.61701
training loss: 19.15244
training loss: 10.41094
training loss: 12.24905
training loss: 19.63757
training loss: 8.79688
training loss: 15.50772
training loss: 12.43456
training loss: 7.64714
training loss: 18.11883
training loss: 11.42469
training loss: 11.67201
training loss: 11.85986
training loss: 16.22634
training loss: 14.13246
training loss: 13.25808
training loss: 19.88115
training loss: 14.16458
training loss: 17.63490
training loss: 10.95061
training loss: 15.27308
training loss: 14.26527
training loss: 12.08646
training loss: 14.83171
training loss: 13.72750
training loss: 13.29440
training loss: 13.53920
training loss: 16.37096
training loss: 11.49262
training loss: 13.00297
training loss: 15.45084
training loss: 15.80493
training loss: 13.88411
training loss: 13.19018
training loss: 12.66403
training loss: 14.87955
training loss: 12.20747
training loss: 7.18034
training loss: 14.46911
training loss: 13.73827
training loss: 17.53704
training loss: 19.63973
training loss: 16.77016
training loss: 13.38453
training loss: 12.31683
training loss: 15.71001
training loss: 14.99324
training loss: 13.26817
training loss: 17.62497
training loss: 11.39983
training loss: 11.70423
training loss: 12.66642
training loss: 13.63698
training loss: 13.34714
training loss: 18.85758
training loss: 11.74257
training loss: 8.13424
training loss: 15.75069
training loss: 14.17915
training loss: 12.22842
training loss: 15.28331
training loss: 12.47374
training loss: 16.97079
training loss: 11.63859
training loss: 14.22292
training loss: 14.74768
training loss: 12.51455
training loss: 10.17823
training loss: 11.41232
training loss: 16.82007
training loss: 11.79575
training loss: nan
training loss: 16.87906
training loss: 12.65374
training loss: 13.88599
training loss: 11.50486
training loss: 21.50312
training loss: 11.77662
training loss: 14.91838
training loss: 11.62157
training loss: 15.44313
training loss: 16.21204
training loss: 12.89331
training loss: 15.64529
training loss: 11.13092
training loss: 9.05675
training loss: 15.27623
training loss: 11.76458
training loss: 9.42963
training loss: 14.90806
training loss: 17.56979
training loss: 15.20864
training loss: 12.54244
training loss: 11.04781
training loss: 10.92633
training loss: 12.78157
training loss: 17.67646
training loss: 15.48840
training loss: 13.79972
training loss: 17.69182
training loss: 14.03331
training loss: 12.38715
training loss: 12.52388
training loss: 14.28354
training loss: 17.20963
training loss: 10.66769
training loss: 18.52967
training loss: 15.29841
training loss: 11.03715
training loss: 19.97231
training loss: 12.19443
training loss: 19.98115
training loss: 13.38499
training loss: 14.74427
training loss: 20.48153
training loss: 17.63694
training loss: 17.34232
training loss: 9.37044
training loss: 13.31770
training loss: 17.93363
training loss: 12.39474
training loss: 16.92835
training loss: 13.44958
training loss: 11.04546
training loss: 10.35662
training loss: 11.89779
training loss: 12.11595
training loss: 14.77578
training loss: 17.28185
training loss: 13.36776
training loss: 11.29841
training loss: 15.99843
training loss: 13.12503
training loss: 17.31209
training loss: 19.03844
training loss: 12.61785
training loss: 13.94618
training loss: 18.73392
training loss: 15.01571
training loss: 12.69967
training loss: 18.07465
training loss: 16.35778
training loss: 16.19431
training loss: 11.54173
training loss: 18.34857
training loss: 12.20299
training loss: 12.73951
training loss: 14.27894
training loss: 12.76511
training loss: 16.23384
training loss: 13.48728
training loss: 14.18090
training loss: 14.06957
training loss: 15.60740
training loss: 11.37519
training loss: 13.59892
training loss: 14.23869
training loss: 14.28408
training loss: 16.89410
training loss: 13.53071
training loss: 16.17461
training loss: 8.48461
training loss: 13.29300
training loss: 12.02979
training loss: 14.69714
training loss: 14.35989
training loss: 19.25690
training loss: 15.44204
training loss: 14.57448
training loss: 13.19757
training loss: 12.80295
training loss: 11.84917
training loss: 13.47915
training loss: 13.61528
training loss: 13.65688
training loss: nan
training loss: 18.02741
training loss: 15.57218
training loss: 13.11553
training loss: 16.19753
training loss: 14.29876
training loss: 12.73672
training loss: 16.90772
training loss: 13.66465
training loss: 15.79991
training loss: 12.26673
training loss: 22.27232
training loss: 17.51927
training loss: 13.79325
training loss: 14.86256
training loss: 14.15786
training loss: 14.27954
training loss: 18.23875
training loss: 14.22118
training loss: 14.51913
training loss: 11.42124
training loss: 9.41672
training loss: 14.02310
training loss: 16.31619
training loss: 12.93452
training loss: 14.24995
training loss: 14.41963
training loss: 13.17587
training loss: 8.77193
training loss: 13.25939
training loss: 16.71712
training loss: 14.91109
training loss: 14.98147
training loss: 15.96722
training loss: 16.75450
training loss: 15.22578
training loss: 10.54703
training loss: 11.96571
training loss: 10.19086
training loss: 13.79695
training loss: 11.77600
training loss: 13.02201
training loss: 13.88034
training loss: 12.13411
training loss: 14.76033
training loss: 14.69539
training loss: 14.98814
training loss: 12.86722
training loss: 9.90806
training loss: 13.03172
training loss: 10.35948
training loss: 10.47669
training loss: 12.81583
training loss: 15.04992
training loss: 14.33328
training loss: 11.11294
training loss: 15.53534
training loss: 12.32203
training loss: 11.16012
training loss: 16.72124
training loss: 10.89497
training loss: 10.14381
training loss: 15.06732
training loss: 9.42819
training loss: 15.88987
training loss: 14.65876
training loss: 10.36453
training loss: 12.03433
training loss: 14.77248
training loss: 17.29989
training loss: 13.48959
training loss: 12.06088
training loss: 12.80791
training loss: 12.05262
training loss: 13.84456
training loss: 12.83570
training loss: 13.94582
training loss: 16.50659
training loss: 9.65104
training loss: 13.32005
training loss: 11.04690
training loss: 13.33319
training loss: 10.73845
training loss: 11.83749
training loss: 15.12639
training loss: 14.35318
training loss: 13.29962
training loss: 13.15510
training loss: 14.45609
training loss: 14.33827
training loss: 10.10157
training loss: 19.09837
training loss: 12.51846
training loss: 13.21074
training loss: 11.12163
training loss: 17.72612
training loss: 15.43755
training loss: 17.35184
training loss: 17.08699
training loss: 17.70437
training loss: 13.41841
training loss: 12.05416
training loss: 17.31720
training loss: 15.88322
training loss: 13.74077
training loss: 10.90352
training loss: 14.07370
training loss: 10.82207
training loss: 11.28829
training loss: 13.58913
training loss: 8.89654
training loss: 19.21203
training loss: 15.21390
training loss: 13.46784
training loss: 13.82811
training loss: 12.30649
training loss: 13.39526
training loss: 9.58190
training loss: 14.84377
training loss: 14.25332
training loss: 16.06549
training loss: 10.96515
training loss: 11.27365
training loss: 18.25681
training loss: 18.34011
training loss: 14.94379
training loss: 17.95937
training loss: 11.61313
training loss: 11.42039
training loss: 10.89744
training loss: 14.32953
training loss: 14.29146
training loss: 21.08200
training loss: 17.95087
training loss: 10.13769
training loss: 11.59904
training loss: 16.60878
training loss: 10.45272
training loss: 11.62902
training loss: 18.32655
training loss: 13.41109
training loss: 13.64835
training loss: 14.57237
training loss: 17.83113
training loss: 12.51074
training loss: 15.24392
training loss: 18.06409
training loss: 13.37187
training loss: 13.00568
training loss: 16.09052
training loss: 17.59143
training loss: 20.48309
training loss: 12.05357
training loss: 16.16007
training loss: 13.47052
training loss: 12.45501
training loss: 14.62155
training loss: 11.41376
training loss: 12.41950
training loss: 10.93908
training loss: 16.22732
training loss: 12.26692
training loss: 13.33046
training loss: 12.60522
training loss: 11.06994
training loss: 15.99683
training loss: 17.28199
training loss: 10.85355
training loss: 11.50863
training loss: 16.40682
training loss: 12.05872
training loss: 12.81610
training loss: 15.96221
training loss: 15.92787
training loss: 11.24703
training loss: 14.92473
training loss: 15.80279
training loss: 11.44198
training loss: 14.07052
training loss: 13.34720
training loss: 15.03531
training loss: 15.72511
training loss: 18.12597
training loss: 16.18833
training loss: 17.18093
training loss: 15.22403
training loss: 13.63659
training loss: 14.87467
training loss: 13.73057
training loss: 13.86110
training loss: 12.83241
training loss: 16.17404
training loss: 12.01932
training loss: 12.84322
training loss: 15.32006
training loss: 11.21907
training loss: 13.68403
training loss: 16.47569
training loss: 16.31946
training loss: 11.23196
training loss: 12.92605
training loss: 15.71740
training loss: 15.58316
training loss: 12.43433
training loss: 11.50227
training loss: 13.24818
training loss: 13.03980
training loss: 9.75647
training loss: 15.18710
training loss: 12.22344
training loss: 11.82420
training loss: 10.51108
training loss: 14.09903
training loss: 9.40351
training loss: 11.17196
training loss: 14.32251
training loss: 16.01587
training loss: 13.05870
training loss: 16.35149
training loss: 16.23177
training loss: 16.71899
training loss: 13.40739
training loss: 15.71061
training loss: 18.79846
training loss: 11.89128
training loss: 12.88033
training loss: 12.19545
training loss: 11.38610
training loss: 10.78551
training loss: 17.06080
training loss: 13.87700
training loss: 16.14557
training loss: 10.74495
training loss: 9.85934
training loss: 34.12298
training loss: 15.28392
training loss: 13.01317
training loss: 12.13422
training loss: 13.49192
training loss: 13.97922
training loss: 10.09447
training loss: 18.08881
training loss: 9.91369
training loss: 13.86784
training loss: 10.96078
training loss: 11.15642
training loss: 10.53937
training loss: 14.89724
training loss: 12.01017
training loss: 14.35733
training loss: 13.95827
training loss: 10.67771
training loss: 16.55117
training loss: 17.29998
training loss: 14.38221
training loss: 16.00930
training loss: 13.36098
training loss: nan
training loss: 17.18641
training loss: 19.26666
training loss: 10.28323
training loss: 19.57092
training loss: 15.10834
training loss: 13.46265
training loss: 9.69495
training loss: 15.46925
training loss: 10.32225
training loss: 15.36644
training loss: 15.37003
training loss: 10.78516
training loss: 11.90490
training loss: 16.09151
training loss: 14.73722
training loss: 15.74204
training loss: 13.89858
training loss: 14.13167
training loss: 14.08710
training loss: 15.80587
training loss: 12.63499
training loss: 11.99837
training loss: 13.66886
training loss: 12.80496
training loss: 13.32531
training loss: 12.42489
training loss: 18.31781
training loss: 11.82704
training loss: 13.69112
training loss: 15.29594
training loss: 11.75102
training loss: 14.04197
training loss: 18.00962
training loss: 12.95530
training loss: 13.36460
training loss: 12.93738
training loss: 10.01838
training loss: 13.85481
training loss: 15.90528
training loss: 13.17792
training loss: 9.78231
training loss: 14.07558
training loss: 13.06754
training loss: 11.90758
training loss: 14.95183
training loss: 21.03723
training loss: 14.89907
training loss: 12.77198
training loss: 10.91418
training loss: 16.59491
training loss: 10.57023
training loss: 11.16937
training loss: 16.43595
training loss: 13.15116
training loss: 11.30125
training loss: 18.95738
training loss: 20.41114
training loss: 10.33541
training loss: 15.40738
training loss: 14.40271
training loss: 12.18348
training loss: 16.30797
training loss: 15.88466
training loss: 12.22925
training loss: 11.80211
training loss: 13.40461
training loss: nan
training loss: 16.08468
training loss: 9.02899
training loss: 11.30714
training loss: 14.34950
training loss: 14.53795
training loss: 14.36997
training loss: 12.11586
training loss: 16.92197
training loss: 14.38996
training loss: 15.31948
training loss: 15.74784
training loss: 14.58951
training loss: 17.71379
training loss: 15.42211
training loss: 18.31628
training loss: 13.61365
training loss: 15.67422
training loss: 14.06455
training loss: 13.37222
training loss: 18.93272
training loss: 14.21344
training loss: 13.16056
training loss: 14.18805
training loss: 18.88968
training loss: 15.37776
training loss: 13.85044
training loss: 10.01786
training loss: 10.35873
training loss: 17.51225
training loss: 12.83785
training loss: 13.58108
training loss: 15.87158
training loss: 11.66390
training loss: 12.02901
training loss: 14.07854
training loss: 14.51242
training loss: 12.79618
training loss: 13.07273
training loss: 14.94424
training loss: 10.44399
training loss: 12.88254
training loss: 13.40249
training loss: 18.82848
training loss: 13.02730
training loss: 18.24467
training loss: 18.96541
training loss: 8.71270
training loss: 11.61960
training loss: 9.92900
training loss: 12.44818
training loss: 18.07548
training loss: 15.85725
training loss: 13.06345
training loss: 15.34481
training loss: 15.61043
training loss: 15.18810
training loss: 15.80069
training loss: 17.09173
training loss: 13.10767
training loss: 11.96451
training loss: 12.25075
training loss: 12.77809
training loss: 14.79929
training loss: 12.20200
training loss: 18.35959
training loss: 19.79486
training loss: 14.50770
training loss: 13.62611
training loss: 11.74404
training loss: nan
training loss: 10.69111
training loss: 11.23262
training loss: 15.78845
training loss: 13.44800
training loss: 12.97421
training loss: 15.77140
training loss: 13.18015
training loss: 13.86324
training loss: 19.08150
training loss: 10.52796
training loss: 18.18756
training loss: 16.96848
training loss: 14.96533
training loss: 10.74998
training loss: 14.11813
training loss: 10.15725
training loss: 12.91245
training loss: 9.52931
training loss: 15.15683
training loss: 15.05647
training loss: 14.31852
training loss: 15.59095
training loss: 11.96679
training loss: 14.92983
training loss: 11.69659
training loss: 15.89518
training loss: 10.54573
training loss: 12.88795
training loss: 14.49976
training loss: 18.57236
training loss: 15.11803
training loss: 10.60501
training loss: 12.18233
training loss: 14.54947
training loss: 14.66919
training loss: 13.20863
training loss: 17.31344
training loss: 12.76473
training loss: 19.21789
training loss: 13.69431
training loss: 16.17455
training loss: 14.37460
training loss: 14.52641
training loss: 13.03945
training loss: 11.24172
training loss: 12.26709
training loss: 15.15908
training loss: 15.15233
training loss: 11.91469
training loss: 14.36401
training loss: 14.29093
training loss: 10.91416
training loss: 17.72671
training loss: 10.23580
training loss: 13.86992
training loss: 8.76530
training loss: 16.51813
training loss: 18.30586
training loss: 16.51244
training loss: 11.48307
training loss: 16.52874
training loss: 12.95784
training loss: 13.39585
training loss: 11.96342
training loss: 16.35264
training loss: 12.82815
training loss: 10.21722
training loss: 9.66957
training loss: 14.51714
training loss: 16.90100
training loss: 8.85300
training loss: 15.08409
training loss: 15.22385
training loss: 15.60903
training loss: 11.43956
training loss: 13.44694
training loss: 12.95293
training loss: 17.17703
training loss: 14.73869
training loss: 14.72661
training loss: 10.06767
training loss: 19.88525
training loss: 12.85181
training loss: 20.26259
training loss: 14.36714
training loss: 13.18692
training loss: 19.67408
training loss: 13.39271
training loss: 14.77936
training loss: 10.89859
training loss: 11.18712
training loss: 12.55224
training loss: 15.15802
training loss: 13.16402
training loss: 12.95450
training loss: 12.59865
training loss: 15.86984
training loss: 16.94073
training loss: 14.79936
training loss: 13.18682
training loss: 9.78615
training loss: 14.43489
training loss: 13.78974
training loss: 13.10784
training loss: 14.71635
training loss: 14.22668
training loss: 14.72569
training loss: 12.53464
training loss: 12.43789
training loss: 10.08697
training loss: 14.56460
training loss: 13.27483
training loss: 14.76581
training loss: 10.82673
training loss: 12.21897
training loss: 14.97587
training loss: 20.78463
training loss: 15.30087
training loss: 15.69970
training loss: 12.78856
training loss: 11.71857
training loss: 14.29555
training loss: 15.38652
training loss: 15.75264
training loss: 14.60640
training loss: 14.94933
training loss: 15.93250
training loss: 13.73553
training loss: 11.00197
training loss: 13.20924
training loss: 18.38782
training loss: 15.25677
training loss: 11.47888
training loss: 12.56118
training loss: 13.70397
training loss: 16.00926
training loss: 9.65677
training loss: 17.19860
training loss: 14.47431
training loss: 10.93531
training loss: 13.04114
training loss: 27.31596
training loss: 11.37970
training loss: 9.53861
training loss: 14.51062
training loss: 13.47704
training loss: 8.90181
training loss: 14.83337
training loss: 10.43100
training loss: 13.48263
training loss: 8.69928
training loss: 9.11561
training loss: 13.95901
training loss: 12.08892
training loss: 14.50562
training loss: 11.02317
training loss: 12.66068
training loss: 12.47805
training loss: 10.28619
training loss: 17.46788
training loss: 17.58074
training loss: 10.44088
training loss: 16.38316
training loss: 12.82369
training loss: 11.13799
training loss: 15.32784
training loss: 11.98649
training loss: 11.74406
training loss: 16.83335
training loss: 13.66923
training loss: 15.72330
training loss: 15.17524
training loss: 16.08528
training loss: 13.61850
training loss: 14.20260
training loss: 15.65465
training loss: 9.60510
training loss: 13.88785
training loss: 10.56258
training loss: 18.73601
training loss: 10.63256
training loss: 12.71919
training loss: 10.54901
training loss: 12.47605
training loss: 15.59743
training loss: 13.56863
training loss: 18.93318
training loss: 13.70819
training loss: 17.07749
training loss: 11.80443
training loss: 12.66836
training loss: 11.66314
training loss: 10.62337
training loss: 13.66701
training loss: 14.06968
training loss: 12.20033
training loss: 12.06512
training loss: 10.48330
training loss: 13.30519
training loss: 15.92554
training loss: 23.74047
training loss: 13.18913
training loss: 19.00323
training loss: 13.11657
training loss: 16.42239
training loss: 10.11794
training loss: 14.33291
training loss: 9.06184
training loss: 17.19630
training loss: 15.21183
training loss: 18.19126
training loss: 16.35470
training loss: 17.84694
training loss: 17.87969
training loss: 12.28569
training loss: 13.41138
training loss: 13.09046
training loss: 21.10871
training loss: 16.61732
training loss: 12.57150
training loss: 15.16060
training loss: 12.09689
training loss: 9.63751
training loss: 12.47060
training loss: 12.13088
training loss: 12.45975
training loss: 15.01055
training loss: 13.40163
training loss: 8.75147
training loss: 12.35299
training loss: 11.45212
training loss: 12.19200
training loss: 12.66054
training loss: 17.37798
training loss: 10.49049
training loss: 11.14235
training loss: nan
training loss: 13.95889
training loss: 10.48565
training loss: 15.91952
training loss: 16.67072
training loss: 11.93677
training loss: 16.92981
training loss: 12.55522
training loss: 12.99378
training loss: 14.10641
training loss: 12.86386
training loss: 16.07617
training loss: 13.90172
training loss: 13.36876
training loss: 11.46765
training loss: 11.23679
training loss: 18.67345
training loss: 11.96591
training loss: 11.03809
training loss: 12.03934
training loss: 15.55640
training loss: 12.69010
training loss: 15.46222
training loss: 16.46882
training loss: 16.97025
training loss: 15.21048
training loss: 12.61161
training loss: 14.19084
training loss: 15.44458
training loss: 13.15498
training loss: 15.96452
training loss: 13.63752
training loss: 15.24695
training loss: 11.36149
training loss: 15.71891
training loss: 13.35294
training loss: 12.32064
training loss: 15.78136
training loss: 15.99885
training loss: 14.32519
training loss: 16.21302
training loss: 14.59321
training loss: 12.40495
training loss: 12.71449
training loss: 11.38710
training loss: 10.77186
training loss: 15.58188
training loss: 11.35677
training loss: 13.52270
training loss: 11.60517
training loss: 13.31504
training loss: 15.84820
training loss: 13.57044
training loss: 10.85002
training loss: 12.11618
training loss: 12.16041
training loss: 12.23517
training loss: 18.57451
training loss: 14.19103
training loss: 12.65126
training loss: 13.68014
training loss: 16.51590
training loss: 10.92121
training loss: 8.33334
training loss: 15.06741
training loss: 14.47167
training loss: 16.57217
training loss: 11.30800
training loss: 9.44030
training loss: 13.97452
training loss: 12.72809
training loss: 16.64605
training loss: 13.23818
training loss: 18.02955
training loss: 14.41356
training loss: 14.69002
training loss: 14.73352
training loss: 19.99411
training loss: 15.43544
training loss: 12.83892
training loss: 13.23653
training loss: 13.39986
training loss: 14.48784
training loss: 15.20984
training loss: 18.99019
training loss: 11.69138
training loss: 14.15164
training loss: 13.20205
training loss: 17.04252
training loss: 16.21192
training loss: 14.23895
training loss: 17.01351
training loss: 13.98463
training loss: 16.58245
training loss: 17.45889
training loss: nan
training loss: 10.04702
training loss: 11.81225
training loss: 14.45134
training loss: 13.92287
training loss: 11.36265
training loss: 12.00213
training loss: 12.01880
training loss: nan
training loss: 17.21480
training loss: 12.65229
training loss: 12.90562
training loss: 11.63222
training loss: 13.75484
training loss: 13.69046
training loss: 11.14709
training loss: 13.23614
training loss: 17.83998
training loss: 13.80788
training loss: 14.50716
training loss: 11.41834
training loss: 14.53842
training loss: 11.11667
training loss: 10.81601
training loss: 13.93319
training loss: 11.36109
training loss: 10.57129
training loss: 10.66201
training loss: 16.79616
training loss: 13.88989
training loss: 15.15804
training loss: 14.22260
training loss: 9.04040
training loss: 14.93390
training loss: 14.09923
training loss: 11.38024
training loss: 12.03221
training loss: 16.81808
training loss: 13.56739
training loss: 14.60723
training loss: 14.32606
training loss: 16.87422
training loss: 12.67428
training loss: 14.06161
training loss: 14.80359
training loss: 13.06533
training loss: 14.07204
training loss: 14.86011
training loss: 15.29733
training loss: 15.07510
training loss: 13.62971
training loss: 12.18728
training loss: 14.60137
training loss: 13.84849
training loss: 15.48983
training loss: 12.91090
training loss: 14.54329
training loss: 14.23000
training loss: 12.13134
training loss: 12.55826
training loss: 12.91448
training loss: 19.45891
training loss: 17.41262
training loss: 12.78538
training loss: 16.12310
training loss: 13.76267
training loss: 14.69145
training loss: 12.88262
training loss: 11.45960
training loss: 12.74651
training loss: 13.77078
training loss: 13.85506
training loss: 15.14295
training loss: 12.68523
training loss: 12.97136
training loss: 12.36755
training loss: 15.06404
training loss: 12.66433
training loss: nan
training loss: 15.54642
training loss: 13.57832
training loss: 9.77037
training loss: 16.67793
training loss: 14.01906
training loss: 13.93023
training loss: 13.40919
training loss: 18.81681
training loss: 16.82338
training loss: 11.09314
training loss: 15.86581
training loss: 14.45540
training loss: 15.90375
training loss: 11.99580
training loss: 13.38613
training loss: 16.17728
training loss: 14.66537
training loss: 12.75252
training loss: 12.49604
training loss: 12.54488
training loss: 13.64465
training loss: 15.93226
training loss: 14.25998
training loss: 9.47684
training loss: 16.59012
training loss: 14.62816
training loss: 13.89731
training loss: 13.36339
training loss: 10.40530
training loss: 9.76084
training loss: 15.74849
training loss: 14.82513
training loss: 14.55230
training loss: 14.03659
training loss: 11.90562
training loss: 13.36361
training loss: 11.75288
training loss: 16.12937
training loss: 9.67753
training loss: 10.66942
training loss: 14.13235
training loss: 13.05914
training loss: 10.35147
training loss: 16.21523
training loss: 17.77278
training loss: 14.13681
training loss: 12.68664
training loss: 11.81819
training loss: 14.02860
training loss: 11.96885
training loss: 23.22682
training loss: 11.79699
training loss: 13.39670
training loss: 14.92536
training loss: 11.65688
training loss: 15.91742
training loss: 12.45003
training loss: 12.88711
training loss: 15.29688
training loss: 11.70573
training loss: 16.30829
training loss: 13.73518
training loss: 11.38215
training loss: 14.04854
training loss: 13.46764
training loss: 12.27533
training loss: 12.90104
training loss: 16.16514
training loss: 14.63816
training loss: 10.58798
training loss: 11.32793
training loss: 12.62504
training loss: 11.93213
training loss: 12.63036
training loss: 12.05148
training loss: 12.69079
training loss: 14.97237
training loss: 13.04592
training loss: 14.92222
training loss: 13.70498
training loss: 17.35068
training loss: 12.25107
training loss: 16.49803
training loss: 11.19356
training loss: 16.20506
training loss: 14.92175
training loss: 15.01877
training loss: 11.50720
training loss: nan
training loss: 12.27195
training loss: 12.76168
training loss: 14.03900
training loss: 11.79421
training loss: 12.30893
training loss: 12.69002
training loss: 18.55706
training loss: 11.57346
training loss: 17.30868
training loss: 12.08473
training loss: 15.51410
training loss: 13.29164
training loss: 15.87323
training loss: 9.98572
training loss: 15.18422
training loss: 10.51786
training loss: 14.65590
training loss: 9.82335
training loss: 13.15970
training loss: 14.67037
training loss: 18.92198
training loss: 15.00925
training loss: 13.88624
training loss: 16.06563
training loss: 12.61944
training loss: 11.93979
training loss: 15.04049
training loss: 12.64653
training loss: 13.32936
training loss: 15.02803
training loss: 11.98724
training loss: 13.35993
training loss: 10.22732
training loss: 14.15827
training loss: 15.06564
training loss: 13.81595
training loss: 10.11218
training loss: 11.88097
training loss: 15.34481
training loss: 12.71226
training loss: 13.56929
training loss: 16.88304
training loss: 12.25404
training loss: 13.39538
training loss: 14.21130
training loss: 9.84431
training loss: 13.18379
training loss: 20.08967
training loss: 13.04596
training loss: 14.87847
training loss: 11.69867
training loss: 13.93031
training loss: 12.12414
training loss: 16.38766
training loss: 11.23222
training loss: 14.17818
training loss: 13.57762
training loss: 17.46824
training loss: 16.00241
training loss: 16.20863
training loss: 11.93145
training loss: 9.92234
training loss: 13.82062
training loss: 13.04703
training loss: 11.67101
training loss: 10.35325
training loss: 11.92368
training loss: 14.14194
training loss: 13.43615
training loss: 15.46805
training loss: 13.00909
training loss: 14.64464
training loss: 13.06076
training loss: 13.62281
training loss: 10.99135
training loss: 15.88810
training loss: 22.70236
training loss: 13.12950
training loss: 15.18159
training loss: 13.18675
training loss: 14.11491
training loss: 14.47075
training loss: 10.01640
training loss: 10.69980
training loss: 11.89722
training loss: 9.44780
training loss: 17.02272
training loss: 13.38057
training loss: 13.67464
training loss: 10.76500
training loss: 12.11003
training loss: 10.62444
training loss: 14.63930
training loss: 18.82864
training loss: 10.23591
training loss: 16.06036
training loss: 12.67047
training loss: 8.94036
training loss: 15.70469
training loss: 10.25287
training loss: 14.34601
training loss: 12.54418
training loss: 11.59738
training loss: 14.50725
training loss: 13.75586
training loss: 13.93730
training loss: 14.30235
training loss: 11.01591
training loss: 13.58583
training loss: 14.94161
training loss: 18.99033
training loss: 13.67705
training loss: 13.27985
training loss: 17.77537
training loss: 19.02713
training loss: 15.94105
training loss: 15.86736
training loss: 12.01785
training loss: 11.61146
training loss: 15.21057
training loss: 15.50542
training loss: 16.90324
training loss: 13.32293
training loss: 15.79243
training loss: 11.14038
training loss: 12.88965
training loss: 15.71355
training loss: 12.63200
training loss: 13.39319
training loss: 10.00648
training loss: 14.79478
training loss: 16.50985
training loss: 14.11947
training loss: 13.37068
training loss: 20.37673
training loss: 19.98614
training loss: 15.67548
training loss: 13.23689
training loss: 23.45070
training loss: 11.68024
training loss: 15.02183
training loss: 14.36412
training loss: 16.70839
training loss: 11.66484
training loss: 12.63190
training loss: 11.35342
training loss: 11.67093
training loss: 16.03417
training loss: 12.19717
training loss: 13.13829
training loss: 12.70871
training loss: 19.36907
training loss: 13.27158
training loss: 14.85047
training loss: 14.92068
training loss: 12.68082
training loss: 11.90350
training loss: 14.00187
training loss: 13.82787
training loss: 13.10519
training loss: 13.97272
training loss: 17.78291
training loss: 14.20265
training loss: 19.72244
training loss: 11.06333
training loss: 17.95890
training loss: 12.17776
training loss: 15.99320
training loss: 15.34415
training loss: 13.81206
training loss: 16.14783
training loss: 12.78874
training loss: 11.02428
training loss: 15.55583
training loss: 13.95285
training loss: 11.99533
training loss: 14.00424
training loss: 13.69800
training loss: 14.51393
training loss: 13.30608
training loss: 15.39788
training loss: 15.06327
training loss: 15.44490
training loss: 16.56268
training loss: 14.47671
training loss: 13.51808
training loss: 15.38812
training loss: 13.96087
training loss: 13.82092
training loss: 15.00867
training loss: 15.63628
training loss: 13.14014
training loss: 13.23939
training loss: 10.33135
training loss: 13.14011
training loss: 13.68789
training loss: 15.39126
training loss: 13.43170
training loss: 20.32985
training loss: 14.56424
training loss: 12.05590
training loss: 12.35629
training loss: 13.81142
training loss: 16.30000
training loss: 15.17406
training loss: 13.18959
training loss: 13.14493
training loss: 13.91769
training loss: 13.77825
training loss: 17.35446
training loss: 15.75124
training loss: 14.58565
training loss: 10.83292
training loss: 13.60401
training loss: 13.57627
training loss: 12.85893
training loss: 9.41557
training loss: 17.36280
training loss: 12.87207
training loss: 14.37319
training loss: 13.69432
training loss: 15.37690
training loss: 17.00688
training loss: 12.32967
training loss: 14.95318
training loss: 11.38431
training loss: 15.38763
training loss: 16.75361
training loss: 9.95088
training loss: 13.09696
training loss: 11.72407
training loss: 12.74467
training loss: 14.53541
training loss: 11.86611
training loss: 14.43675
training loss: 19.11383
training loss: 13.94586
training loss: 16.12414
training loss: 16.45551
training loss: 17.01316
training loss: 13.58782
training loss: 15.74931
training loss: 13.72265
training loss: 14.89730
training loss: 14.08069
training loss: 11.34218
training loss: 16.78843
training loss: 18.01924
training loss: 14.39820
training loss: 18.77558
training loss: 16.29214
training loss: 12.54058
training loss: 11.71340
training loss: 15.52742
training loss: 10.89109
training loss: 12.39946
training loss: 17.67987
training loss: 13.63639
training loss: 10.94053
training loss: 10.70141
training loss: 14.71919
training loss: 10.41928
training loss: 11.54878
training loss: 13.37306
training loss: 20.45503
training loss: 12.13306
training loss: 16.05456
training loss: 11.92997
training loss: 14.61860
training loss: 15.15561
training loss: 16.16413
training loss: 10.97600
training loss: 13.43407
training loss: 13.81064
training loss: 12.14459
training loss: 14.83568
training loss: 10.40423
training loss: 16.96178
training loss: 13.79122
training loss: 17.54509
training loss: 16.15862
training loss: 11.32086
training loss: 17.80843
training loss: 16.67801
training loss: 14.61757
training loss: 9.96243
training loss: 10.82886
training loss: 16.48092
training loss: 15.71611
training loss: 11.42304
training loss: 14.55698
training loss: 16.47132
training loss: 15.75259
training loss: 12.90270
training loss: 12.43909
training loss: 14.28285
training loss: 15.97287
training loss: 17.64566
training loss: 15.96414
training loss: 12.43826
training loss: 16.68621
training loss: 12.56945
training loss: 12.06215
training loss: 10.48205
training loss: 12.08402
training loss: 16.36677
training loss: 13.84057
training loss: 17.21048
training loss: 14.65362
training loss: 10.44253
training loss: 14.63040
training loss: 14.08331
training loss: 12.42354
training loss: 17.61579
training loss: 11.83521
training loss: 15.07746
training loss: 12.68673
training loss: 11.01837
training loss: 14.90973
training loss: 20.10124
training loss: 19.19101
training loss: 16.97107
training loss: 12.06146
training loss: 16.89551
training loss: 14.01244
training loss: 11.63894
training loss: 12.37835
training loss: 11.16283
training loss: 14.60325
training loss: 13.77785
training loss: 12.25655
training loss: 12.98377
training loss: 15.91235
training loss: 13.16573
training loss: 14.87457
training loss: 15.55452
training loss: 10.49265
training loss: 14.88222
training loss: 13.78739
training loss: 11.36764
training loss: 13.82102
training loss: 15.80687
training loss: 15.62191
training loss: 12.06777
training loss: 13.58351
training loss: 11.43453
training loss: 15.21379
training loss: 12.74688
training loss: 18.69167
training loss: 16.93694
training loss: 14.56456
training loss: 9.57068
training loss: 11.67824
training loss: nan
training loss: 10.58531
training loss: 16.66410
training loss: 12.26508
training loss: 10.20354
training loss: 15.93457
training loss: 14.72029
training loss: 13.86151
training loss: 13.03864
training loss: nan
training loss: 15.91777
training loss: 9.61885
training loss: 11.87989
training loss: 15.52623
training loss: 15.53011
training loss: 13.26542
training loss: 10.35357
training loss: 12.65196
training loss: 12.99637
training loss: 11.10548
training loss: 15.65428
training loss: 14.52299
training loss: 11.40726
training loss: 12.35331
training loss: 15.25540
training loss: 13.91004
training loss: 16.20349
training loss: 16.82720
training loss: 14.26419
training loss: 12.55513
training loss: 11.92441
training loss: 16.75152
training loss: 10.70114
training loss: 18.07978
training loss: 16.19512
training loss: 15.52586
training loss: 17.91809
training loss: 14.99851
training loss: 13.55729
training loss: 18.49211
training loss: 11.83920
training loss: 11.47050
training loss: 16.22519
training loss: 13.22477
training loss: 15.72688
training loss: 14.59620
training loss: 15.88855
training loss: 11.87406
training loss: 14.32190
training loss: 15.39674
training loss: 19.27937
training loss: 11.32800
training loss: 12.10679
training loss: 14.27836
training loss: 12.31410
training loss: 13.89726
training loss: 13.26657
training loss: 10.91256
training loss: 12.37400
training loss: 11.63052
training loss: 12.91979
training loss: 13.15413
training loss: 16.54053
training loss: 12.40975
training loss: 12.59992
training loss: 14.30658
training loss: 15.30732
training loss: 11.14626
training loss: 14.18338
training loss: 16.24586
training loss: 12.72764
training loss: 11.42078
training loss: 13.30727
training loss: 12.55625
training loss: 11.08395
training loss: 14.33743
training loss: 12.38232
training loss: nan
training loss: 9.96965
training loss: 15.04883
training loss: 14.99903
training loss: 11.69483
training loss: 17.26101
training loss: 11.17769
training loss: 14.20283
training loss: 15.82303
training loss: 13.86603
training loss: 14.43031
training loss: 15.33620
training loss: 9.71447
training loss: 17.32418
training loss: 13.82689
training loss: 10.10136
training loss: 17.53069
training loss: 17.49915
training loss: 11.59641
training loss: 21.97799
training loss: 27.98441
training loss: 13.44622
training loss: 13.78857
training loss: 11.00687
training loss: 16.35244
training loss: 14.59870
training loss: 15.56619
training loss: 11.42321
training loss: 14.28541
training loss: 14.38292
training loss: 16.60649
training loss: 12.12269
training loss: 12.88198
training loss: 10.73507
training loss: 17.64063
training loss: 14.30504
training loss: 15.21187
training loss: 15.53190
training loss: 15.68593
training loss: 13.74812
training loss: 15.98282
training loss: 16.71063
training loss: 13.71630
training loss: 12.33611
training loss: 17.76958
training loss: 14.77018
training loss: 13.94401
training loss: 11.16430
training loss: 11.63747
training loss: 14.79238
training loss: 14.33554
training loss: 15.98721
training loss: 12.26680
training loss: 11.61073
training loss: 12.74226
training loss: 11.62551
training loss: 12.61721
training loss: 15.62030
training loss: 11.85968
training loss: 17.82456
training loss: 12.10875
training loss: 12.08680
training loss: 12.49103
training loss: 11.24523
training loss: 13.51690
training loss: 15.40037
training loss: 15.44264
training loss: 13.31483
training loss: 11.10841
training loss: 13.43642
training loss: 9.31288
training loss: 12.25893
training loss: 17.55698
training loss: 18.08666
training loss: 10.92374
training loss: 12.44345
training loss: 10.61203
training loss: 9.64238
training loss: 13.74427
training loss: 11.45529
training loss: 11.76485
training loss: 13.55475
training loss: 16.66567
training loss: 16.33026
training loss: 14.95082
training loss: 14.38859
training loss: 10.36033
training loss: 12.07064
training loss: 17.94243
training loss: 15.31862
training loss: 15.00680
training loss: 16.46247
training loss: 12.26793
training loss: 13.04610
training loss: 14.70386
training loss: 12.31434
training loss: 12.91987
training loss: 18.41228
training loss: 15.12614
training loss: 11.78631
training loss: 13.68193
training loss: 16.45761
training loss: 13.53530
training loss: 13.66960
training loss: 14.44383
training loss: nan
training loss: 15.53047
training loss: 12.63873
training loss: 14.15861
training loss: 12.46096
training loss: 14.79402
training loss: 8.06624
training loss: 14.67138
training loss: 13.90345
training loss: 18.21906
training loss: 11.92244
training loss: 13.39539
training loss: 14.41226
training loss: 10.78280
training loss: 16.43888
training loss: 14.96082
training loss: 11.58054
training loss: 13.23231
training loss: 10.27701
training loss: 19.14540
training loss: 13.62946
training loss: 19.55663
training loss: 14.39814
training loss: 14.64268
training loss: 20.13673
training loss: 13.07709
training loss: 11.80623
training loss: 14.55495
training loss: 16.31215
training loss: 16.83111
training loss: 13.65375
training loss: 17.57042
training loss: 18.61649
training loss: 11.84622
training loss: 11.75902
training loss: 16.42905
training loss: 12.35261
training loss: 14.39662
training loss: 11.01596
training loss: 20.07462
training loss: 12.44121
training loss: 12.97338
training loss: 14.97392
training loss: 13.73396
training loss: 14.06882
training loss: 10.71943
training loss: 17.64903
training loss: 7.69891
training loss: 11.86865
training loss: 13.34999
training loss: 11.10517
training loss: 10.05459
training loss: 12.22863
training loss: 10.03376
training loss: 15.59260
training loss: 19.85473
training loss: 11.52245
training loss: 13.73334
training loss: 12.37696
training loss: 13.00247
training loss: 17.64410
training loss: 10.97995
training loss: 12.15303
training loss: 15.26771
training loss: 11.87752
training loss: 16.34253
training loss: 17.03491
training loss: 16.32640
training loss: 18.29247
training loss: 15.79012
training loss: 15.09761
training loss: 12.70162
training loss: 12.71306
training loss: 14.94584
training loss: 17.31841
training loss: 13.88857
training loss: 13.76995
training loss: 17.87072
training loss: 13.30705
training loss: 13.77385
training loss: 13.11377
training loss: 14.23054
training loss: 14.50256
training loss: 12.86724
training loss: 16.11607
training loss: 12.14130
training loss: 12.36316
training loss: 12.94110
training loss: 9.90349
training loss: 16.50712
training loss: 10.93367
training loss: 14.29858
training loss: 14.18623
training loss: 17.44131
training loss: 16.16849
training loss: 11.44685
training loss: 12.31850
training loss: 13.20617
training loss: 14.63010
training loss: 13.15990
training loss: 11.63007
training loss: 11.79219
training loss: 10.47812
training loss: 11.56268
training loss: 12.87923
training loss: 15.29477
training loss: 14.26490
training loss: 17.17576
training loss: 16.84179
training loss: 17.52190
training loss: 17.10260
training loss: 13.32365
training loss: 14.41280
training loss: 17.18987
training loss: 11.80568
training loss: 13.63148
training loss: 16.63338
training loss: 14.41819
training loss: 15.69208
training loss: 14.50239
training loss: 14.77847
training loss: 17.43204
training loss: 10.24727
training loss: 13.44464
training loss: 17.41521
training loss: 14.33329
training loss: 22.23257
training loss: 17.79067
training loss: 14.05807
training loss: 11.15731
training loss: 18.95538
training loss: 9.57953
training loss: 10.13857
training loss: 12.51967
training loss: 14.66854
training loss: 15.96536
training loss: 16.84854
training loss: 11.77429
training loss: 12.43558
training loss: 12.34976
training loss: 12.27910
training loss: 10.04866
training loss: 16.66401
training loss: 14.20681
training loss: 12.54253
training loss: 18.36888
training loss: 14.97260
training loss: 11.97736
training loss: 12.90485
training loss: 17.97732
training loss: 13.31805
training loss: 14.35697
training loss: 13.13038
training loss: 13.88673
training loss: 16.02617
training loss: 15.63525
training loss: 9.88869
training loss: 15.30472
training loss: 15.38801
training loss: 12.84451
training loss: 12.29858
training loss: 20.96473
training loss: 13.94148
training loss: 13.48209
training loss: 12.15651
training loss: 11.24099
training loss: 15.08032
training loss: 12.55549
training loss: 15.12448
training loss: 12.18162
training loss: 12.51354
training loss: 15.54548
training loss: 9.70376
training loss: 18.88843
training loss: 13.36830
training loss: 15.44246
training loss: 15.32961
training loss: 13.26516
training loss: 13.51294
training loss: 12.31242
training loss: 12.67251
training loss: 10.97519
training loss: 18.08300
training loss: 19.94240
training loss: 15.02981
training loss: 16.35003
training loss: 19.64050
training loss: 14.64774
training loss: 12.99072
training loss: 11.87833
training loss: 11.90344
training loss: 15.11808
training loss: 16.68110
training loss: 9.67413
training loss: 12.04838
training loss: 12.89265
training loss: 12.77914
training loss: 10.78086
training loss: 11.29652
training loss: 12.66120
training loss: 13.22592
training loss: 13.28961
training loss: 16.00161
training loss: 10.13471
training loss: 15.03780
training loss: 11.81894
training loss: 13.17029
training loss: 17.40352
training loss: 13.81601
training loss: 13.65298
training loss: 12.35821
training loss: 13.56771
training loss: 13.60526
training loss: 11.98724
training loss: 14.27803
training loss: 10.14461
training loss: 10.88345
training loss: 14.53912
training loss: 13.02091
training loss: 14.85120
training loss: 12.81445
training loss: 13.70517
training loss: 15.48442
training loss: 10.95874
training loss: 16.63839
training loss: 12.10911
training loss: 16.31199
training loss: 16.99449
training loss: 10.32868
training loss: 16.55363
training loss: 11.98481
training loss: 16.10474
training loss: 11.24947
training loss: 10.61781
training loss: 14.94245
training loss: 16.19998
training loss: 11.06222
training loss: 11.83287
training loss: 13.14351
training loss: 10.55765
training loss: 13.45283
training loss: 15.13819
training loss: 15.86115
training loss: 16.54835
training loss: 12.37653
training loss: 12.70414
training loss: 11.43067
training loss: 13.28023
training loss: 12.97854
training loss: 13.46741
training loss: 11.79650
training loss: 12.59787
training loss: 16.95820
training loss: 14.54767
training loss: 12.87932
training loss: 13.82920
training loss: 15.85882
training loss: 17.11265
training loss: 20.52322
training loss: 11.45796
training loss: 15.14479
training loss: 14.27324
training loss: 12.79202
training loss: 12.42896
training loss: 17.42913
training loss: 17.96105
training loss: 12.92806
training loss: 14.48834
training loss: 12.22893
training loss: 14.09427
training loss: 16.34317
training loss: 16.27221
training loss: 9.54720
training loss: 11.34542
training loss: 15.82927
training loss: 9.67996
training loss: 11.80204
training loss: 14.48691
training loss: 12.35747
training loss: 10.82012
training loss: 14.22734
training loss: 17.53151
training loss: 12.92755
training loss: 14.34600
training loss: 12.74973
training loss: 12.22283
training loss: 18.29566
training loss: 13.16917
training loss: 12.86664
training loss: 13.94193
training loss: 14.45998
training loss: 18.77423
training loss: 14.35929
training loss: 15.50554
training loss: 14.97555
training loss: 18.06014
training loss: 11.41177
training loss: 10.49023
training loss: 12.40829
training loss: 13.01828
training loss: 14.16973
training loss: 13.30061
training loss: 10.45719
training loss: 13.66521
training loss: 12.45023
training loss: 15.16469
training loss: 12.21925
training loss: 12.47591
training loss: 11.98957
training loss: 18.71517
training loss: 13.95418
training loss: 13.04828
training loss: 10.33313
training loss: 10.61087
training loss: 12.69630
training loss: 15.55460
training loss: 15.78853
training loss: 10.87685
training loss: 14.71208
training loss: 13.13875
training loss: 13.29764
training loss: 13.61191
training loss: 10.94230
training loss: 19.12503
training loss: 9.24322
training loss: 13.21362
training loss: 14.85296
training loss: 13.33614
training loss: 11.54593
training loss: 15.79490
training loss: 9.76908
training loss: 11.89419
training loss: 13.75842
training loss: 15.95868
training loss: 13.11996
training loss: 12.68965
training loss: 13.85750
training loss: 12.24283
training loss: 11.37303
training loss: 13.10458
training loss: 17.18461
training loss: 11.52582
training loss: 8.38088
training loss: 12.57979
training loss: 12.21841
training loss: 13.12090
training loss: 12.52294
training loss: 11.72209
training loss: 12.47943
training loss: 12.07891
training loss: 11.56241
training loss: 9.17311
training loss: 12.44518
training loss: 18.67669
training loss: 10.91982
training loss: 9.18047
training loss: 13.65809
training loss: 13.41549
training loss: 9.94677
training loss: 15.28762
training loss: 13.40986
training loss: 10.27398
training loss: 16.89823
training loss: 12.03366
training loss: 14.33022
training loss: 15.61146
training loss: 15.84479
training loss: 13.23094
training loss: 18.77559
training loss: 13.57926
training loss: 18.18216
training loss: 13.61876
training loss: 11.70770
training loss: 16.18103
training loss: 12.49678
training loss: 10.60372
training loss: 14.83906
training loss: 18.81491
training loss: 12.53146
training loss: 16.38125
training loss: 15.20915
training loss: 15.81540
training loss: 10.70908
training loss: 16.87820
training loss: 15.20289
training loss: 12.53654
training loss: 9.12364
training loss: 14.88960
training loss: 9.55237
training loss: 14.90285
training loss: 13.79185
training loss: 18.22051
training loss: 7.47119
training loss: 11.92028
training loss: 15.96358
training loss: 15.39040
training loss: 15.42182
training loss: 13.65298
training loss: 12.74335
training loss: 14.35399
training loss: 14.79944
training loss: 15.81328
training loss: 14.05410
training loss: 18.79837
training loss: 11.01986
training loss: 12.53722
training loss: 14.18710
training loss: 16.98287
training loss: 16.12913
training loss: 14.24710
training loss: 14.00219
training loss: 9.85447
training loss: 9.20178
training loss: 16.56780
training loss: 18.20029
training loss: 14.81552
training loss: 8.50568
training loss: 13.57104
training loss: 11.88497
training loss: 13.77374
training loss: 15.48535
training loss: 14.02116
training loss: 11.02063
training loss: 15.80800
training loss: 12.08442
training loss: 13.18750
training loss: 18.32969
training loss: 8.90774
training loss: 15.41024
training loss: 13.04370
training loss: 16.02550
training loss: 13.28344
training loss: 12.19896
training loss: 9.83901
training loss: 11.80759
training loss: 11.40497
training loss: 15.32071
training loss: 16.90065
training loss: 14.40606
training loss: 11.13624
training loss: 13.52791
training loss: 13.86802
training loss: 10.69551
training loss: 14.65915
training loss: 13.35633
training loss: 17.32575
training loss: 9.91021
training loss: 10.79692
training loss: 10.95858
training loss: 14.40596
training loss: 14.26425
training loss: 18.03254
training loss: 15.58472
training loss: 14.58037
training loss: 13.91435
training loss: 12.66426
training loss: 15.11101
training loss: 19.74886
training loss: 14.50485
training loss: 17.18978
training loss: 9.31756
training loss: 11.70124
training loss: 13.57787
training loss: 15.07861
training loss: 17.35194
training loss: 14.76772
training loss: 14.57487
training loss: 19.96612
training loss: 13.01425
training loss: 9.89824
training loss: 15.39819
training loss: 12.87148
training loss: 12.89289
training loss: 13.86521
training loss: 16.55482
training loss: 10.20169
training loss: 14.51340
training loss: 14.74965
training loss: 11.57564
training loss: 14.24576
training loss: 20.54316
training loss: 12.55262
training loss: 12.36711
training loss: 14.65742
training loss: 16.29952
training loss: 9.40629
training loss: 20.12890
training loss: 12.53612
training loss: 21.79845
training loss: 11.27293
training loss: 15.74329
training loss: 16.09122
training loss: 11.17187
training loss: 12.14825
training loss: 15.95470
training loss: 13.57645
training loss: 20.02468
training loss: 11.87708
training loss: 15.28174
training loss: 13.42553
training loss: 15.29971
training loss: 13.48528
training loss: 15.65425
training loss: 11.39166
training loss: 11.32481
training loss: 19.68705
training loss: 16.11093
training loss: 11.96830
training loss: 13.42817
training loss: 13.36578
training loss: 12.75513
training loss: 11.73004
training loss: 15.22460
training loss: 14.65445
training loss: nan
training loss: 16.25210
training loss: 12.64883
training loss: 11.27912
training loss: 16.52637
training loss: 13.84597
training loss: 11.88296
training loss: 11.71571
training loss: 15.33948
training loss: 15.71813
training loss: 12.06442
training loss: 13.21760
training loss: 11.53704
training loss: 14.77015
training loss: 12.34652
training loss: 14.36798
training loss: 15.94330
training loss: 17.48300
training loss: 10.28861
training loss: 13.02605
training loss: 14.81039
training loss: 15.14344
training loss: 15.56826
training loss: 15.74984
training loss: 12.77399
training loss: 14.53741
training loss: 13.70931
training loss: 12.81528
training loss: 15.23306
training loss: 18.62922
training loss: 17.37781
training loss: 14.22491
training loss: 13.36105
training loss: 15.67020
training loss: 15.65612
training loss: 13.23625
training loss: 14.06262
training loss: 13.14423
training loss: 14.05082
training loss: 14.84241
training loss: 12.10133
training loss: 13.00167
training loss: 17.17345
training loss: 11.68427
training loss: 12.83288
training loss: 14.81425
training loss: 10.74752
training loss: 14.99594
training loss: 14.14236
training loss: 15.79689
training loss: 16.24095
training loss: 13.56108
training loss: 13.99834
training loss: 16.57900
training loss: 11.96562
training loss: 13.87091
training loss: 13.38086
training loss: 12.66232
training loss: 12.05909
training loss: 18.59767
training loss: 13.59534
training loss: 13.49528
training loss: 15.56728
training loss: 12.30397
training loss: 13.47742
training loss: 8.44302
training loss: 11.31380
training loss: 14.64816
training loss: 15.40905
training loss: 16.05291
training loss: 14.10628
training loss: 14.12184
training loss: 14.53812
training loss: 17.65976
training loss: 18.54534
training loss: 16.94169
training loss: 15.11296
training loss: 14.22122
training loss: 12.33037
training loss: 15.48742
training loss: 12.37483
training loss: 14.51978
training loss: 11.01606
training loss: 11.44384
training loss: 12.46778
training loss: 14.14913
training loss: 15.54774
training loss: 13.75517
training loss: 14.77578
training loss: 18.73301
training loss: 12.11920
training loss: 20.64746
training loss: 13.94599
training loss: 14.94214
training loss: 13.27041
training loss: 9.10228
training loss: 12.85312
training loss: 18.15404
training loss: 13.12997
training loss: 11.67353
training loss: 15.34659
training loss: 12.07644
training loss: 11.38119
training loss: 9.23762
training loss: 11.63276
training loss: 13.06148
training loss: 8.37494
training loss: 16.12438
training loss: 14.40162
training loss: 13.76573
training loss: 12.79424
training loss: 11.28089
training loss: 15.15134
training loss: 17.34878
training loss: 13.00194
training loss: 10.72656
training loss: 17.09478
training loss: 15.21363
training loss: 12.01927
training loss: 12.28602
training loss: 15.54638
training loss: nan
training loss: 15.66037
training loss: 12.95015
training loss: 11.33474
training loss: 13.04155
training loss: 11.00175
training loss: 15.80261
training loss: 17.07402
training loss: 11.61431
training loss: 13.36832
training loss: 12.60247
training loss: 9.51825
training loss: 19.20613
training loss: 13.21618
training loss: 9.97567
training loss: 8.54632
training loss: 10.93670
training loss: 12.58961
training loss: 12.32542
training loss: 15.46506
training loss: 12.28114
training loss: 15.16133
training loss: 14.73470
training loss: 8.69568
training loss: 15.48411
training loss: 16.84727
training loss: 16.83931
training loss: 14.81388
training loss: 13.02490
training loss: 13.07633
training loss: 18.61900
training loss: 13.98128
training loss: 16.20264
training loss: 13.09923
training loss: 15.76950
training loss: 14.29133
training loss: 12.61162
training loss: 15.54574
training loss: 13.13520
training loss: 13.65207
training loss: 14.02396
training loss: 16.28062
training loss: 10.11955
training loss: 12.77481
training loss: 14.16354
training loss: 13.88221
training loss: 11.75944
training loss: 13.85793
training loss: 15.89820
training loss: 12.48302
training loss: 7.92087
training loss: 12.61907
training loss: 13.45990
training loss: 14.37392
training loss: 16.61707
training loss: 16.43394
training loss: 11.37836
training loss: 13.23250
training loss: 12.30346
training loss: 17.72378
training loss: 13.31683
training loss: 15.70138
training loss: 11.59060
training loss: 14.53280
training loss: 14.80558
training loss: 11.36636
training loss: 11.00909
training loss: 12.86506
training loss: 11.99835
training loss: 9.51934
training loss: 15.49183
training loss: 12.13722
training loss: 10.16362
training loss: 13.36447
training loss: 12.49709
training loss: 24.18179
training loss: 11.34764
training loss: 13.28392
training loss: 15.30020
training loss: 13.45387
training loss: 13.09401
training loss: 11.14813
training loss: 11.60850
training loss: 12.06979
training loss: 15.58813
training loss: 13.68764
training loss: 11.05237
training loss: 14.91083
training loss: 14.93381
training loss: 12.02260
training loss: 12.56446
training loss: 15.76430
training loss: 11.54044
training loss: 12.71297
training loss: 13.37025
training loss: 14.91663
training loss: 16.76729
training loss: 16.18811
training loss: 12.07420
training loss: 14.60132
training loss: 11.89107
training loss: 12.54206
training loss: 11.30250
training loss: 11.27484
training loss: 14.85645
training loss: 17.21995
training loss: 12.94291
training loss: 23.05127
training loss: 15.53466
training loss: 15.59013
training loss: 18.84933
training loss: 14.70060
training loss: 13.45678
training loss: 9.54205
training loss: 13.61172
training loss: 12.42257
training loss: 14.66114
training loss: 14.32008
training loss: 14.37986
training loss: 15.20571
training loss: 15.51015
training loss: 12.01601
training loss: 15.95206
training loss: 15.98597
training loss: 21.58607
training loss: 9.97780
training loss: 13.86677
training loss: 10.98823
training loss: 15.31115
training loss: 13.32332
training loss: 10.52247
training loss: 12.13959
training loss: 10.61489
training loss: 15.96081
training loss: 15.32688
training loss: 14.90075
training loss: 12.61172
training loss: 18.90338
training loss: 13.19007
training loss: 19.70563
training loss: 17.51123
training loss: 11.67826
training loss: 11.21342
training loss: 19.97099
training loss: 12.54788
training loss: 12.84811
training loss: 11.84667
training loss: 14.85758
training loss: 12.27475
training loss: 10.45107
training loss: 12.10497
training loss: 15.56474
training loss: 11.80429
training loss: 15.84106
training loss: 13.87075
training loss: 14.07114
training loss: 12.72906
training loss: 11.26832
training loss: 16.77430
training loss: 13.64033
training loss: 17.22626
training loss: 10.02538
training loss: 14.65169
training loss: 14.48415
training loss: 15.62803
training loss: 17.99484
training loss: 11.70516
training loss: 8.95482
training loss: 18.77071
training loss: 11.84557
training loss: 25.65798
training loss: 13.49970
training loss: nan
training loss: 15.68674
training loss: 13.37394
training loss: 13.32835
training loss: 15.21684
training loss: 12.52875
training loss: 16.85309
training loss: 12.84146
training loss: 11.14355
training loss: 11.42276
training loss: 12.24440
training loss: 11.77334
training loss: 12.35123
training loss: 12.62774
training loss: 14.18393
training loss: 15.94090
training loss: 12.82638
training loss: 10.97711
training loss: 15.34400
training loss: 13.55078
training loss: 10.84899
training loss: 15.34496
training loss: 13.04276
training loss: 14.01927
training loss: 13.64282
training loss: 12.12614
training loss: 13.81434
training loss: 17.01239
training loss: 11.29212
training loss: 10.73515
training loss: 15.12348
training loss: 12.52970
training loss: 13.03804
training loss: 14.76114
training loss: 10.81760
training loss: 15.69866
training loss: 13.08058
training loss: 12.22264
training loss: 13.41780
training loss: 16.40472
training loss: 11.74522
training loss: 13.26661
training loss: 12.51626
training loss: 13.63488
training loss: 13.88893
training loss: 17.42660
training loss: 17.30294
training loss: 8.98730
training loss: 16.38047
training loss: 10.14500
training loss: 15.55716
training loss: 13.18778
training loss: 14.47790
training loss: 15.29942
training loss: 13.59300
training loss: 15.01393
training loss: 13.92356
training loss: 10.24788
training loss: 16.40579
training loss: 14.33562
training loss: 10.82437
training loss: 9.08950
training loss: 18.85412
training loss: 11.35533
training loss: 22.01529
training loss: 12.46696
training loss: 13.34445
training loss: 19.79490
training loss: 11.89998
training loss: 14.33922
training loss: 14.67887
training loss: 16.89018
training loss: 15.74350
training loss: 14.52334
training loss: 12.50000
training loss: 11.84056
training loss: 16.00143
training loss: 13.50286
training loss: 10.65130
training loss: 11.83273
training loss: 15.56691
training loss: 11.36249
training loss: 13.87661
training loss: 15.93561
training loss: 13.38841
training loss: 11.20271
training loss: 14.20765
training loss: 12.33472
training loss: 14.15283
training loss: 14.89123
training loss: 14.34594
training loss: 17.24390
training loss: 14.11668
training loss: 15.61904
training loss: 15.74825
training loss: 14.06450
training loss: 12.39792
training loss: 13.54034
training loss: 16.69453
training loss: 13.89340
training loss: 13.21872
training loss: 11.58724
training loss: 14.34627
training loss: 11.88596
training loss: 12.95851
training loss: 15.85953
training loss: 14.09361
training loss: 15.00722
training loss: 12.53437
training loss: 13.49528
training loss: 15.46954
training loss: 10.95760
training loss: 11.94140
training loss: 13.94158
training loss: 12.78579
training loss: 12.22704
training loss: 16.58233
training loss: 15.56593
training loss: 9.00468
training loss: 13.77167
training loss: 11.17666
training loss: 13.78663
training loss: 13.30552
training loss: 12.01452
training loss: 11.59527
training loss: 13.44663
training loss: 16.68930
training loss: 14.67157
training loss: 11.84324
training loss: 14.27797
training loss: 14.37145
training loss: 9.69016
training loss: 12.25717
training loss: 10.46889
training loss: 14.57238
training loss: 11.48973
training loss: 11.42315
training loss: 14.30138
training loss: 13.98281
training loss: 13.00151
training loss: 18.37612
training loss: 15.60776
training loss: 13.80815
training loss: 13.11243
training loss: 10.19043
training loss: 9.81945
training loss: 9.70731
training loss: 12.07194
training loss: 11.18296
training loss: 16.24056
training loss: 14.75631
training loss: 15.98445
training loss: 15.43913
training loss: 14.72001
training loss: 15.50750
training loss: 14.53638
training loss: 16.55027
training loss: 15.12589
training loss: 16.08607
training loss: 10.72514
training loss: 15.20116
training loss: 12.27099
training loss: 11.98113
training loss: 13.78343
training loss: 13.31538
training loss: 11.81773
training loss: 13.62441
training loss: 13.98263
training loss: 9.98898
training loss: 10.83738
training loss: 12.63382
training loss: 15.35367
training loss: 14.34509
training loss: 13.96530
training loss: 11.79021
training loss: 10.50031
training loss: 13.61653
training loss: 14.40255
training loss: 13.57010
training loss: 15.51784
training loss: 14.91538
training loss: 10.96329
training loss: 13.46161
training loss: 9.69769
training loss: 11.90778
training loss: 15.01709
training loss: 11.20828
training loss: 10.86187
training loss: 13.04012
training loss: 13.07278
training loss: 11.56432
training loss: 15.84114
training loss: 13.22224
training loss: 11.00130
training loss: 12.92483
training loss: 15.94857
training loss: 14.60408
training loss: 17.01848
training loss: 14.07557
training loss: 15.03629
training loss: 13.19727
training loss: 15.57512
training loss: 13.27191
training loss: 12.80905
training loss: 17.22524
training loss: 17.06610
training loss: 15.17260
training loss: 16.53647
training loss: 14.28223
training loss: 12.09469
training loss: 18.36487
training loss: 13.82545
training loss: 11.40205
training loss: 11.87828
training loss: 14.89902
training loss: 12.69933
training loss: 14.06005
training loss: 15.03895
training loss: 14.35124
training loss: 13.64652
training loss: 16.29798
training loss: 15.76433
training loss: 12.12639
training loss: 10.77697
training loss: 14.32860
training loss: 12.44524
training loss: 15.86907
training loss: 11.19567
training loss: 15.05792
training loss: 14.96185
training loss: 12.30057
training loss: 16.04055
training loss: 14.86835
training loss: 12.53960
training loss: 15.66002
training loss: 12.70164
training loss: 13.28458
training loss: 15.77988
training loss: 14.23111
training loss: 13.76762
training loss: 15.85557
training loss: 10.36708
training loss: 12.88274
training loss: 10.58728
training loss: 17.23464
training loss: 15.88981
training loss: 15.60715
training loss: 12.90095
training loss: 11.43962
training loss: 12.68319
training loss: 13.66083
training loss: 16.71775
training loss: 12.72751
training loss: 12.47426
training loss: 14.59892
training loss: 12.47367
training loss: 10.83853
training loss: 14.06534
training loss: 14.53237
training loss: 14.79216
training loss: 17.02297
training loss: 11.99487
training loss: 15.49659
training loss: 12.41405
training loss: 10.95906
training loss: 14.97544
training loss: 14.14261
training loss: 13.28350
training loss: 11.81476
training loss: 14.07492
training loss: 14.08828
training loss: 14.66754
training loss: 12.31935
training loss: 16.22566
training loss: 13.08427
training loss: 15.77842
training loss: 13.95323
training loss: 13.16667
training loss: 14.71470
training loss: 15.92525
training loss: 12.53248
training loss: 19.04355
training loss: 13.62223
training loss: 17.58776
training loss: 15.84221
training loss: 15.68175
training loss: 11.72444
training loss: 14.34312
training loss: 14.41891
training loss: 15.56824
training loss: 14.10677
training loss: 9.95860
training loss: 13.89385
training loss: 14.76166
training loss: 12.04927
training loss: 15.44734
training loss: 11.47125
training loss: 10.61116
training loss: 12.13705
training loss: 13.96253
training loss: 17.24333
training loss: 13.50854
training loss: 11.22765
training loss: 16.20171
training loss: 10.87518
training loss: 11.97249
training loss: 14.51851
training loss: 12.46319
training loss: 13.73966
training loss: 15.43993
training loss: 10.89384
training loss: 16.53051
training loss: 14.04948
training loss: 21.46510
training loss: 16.24294
training loss: 14.30186
training loss: 14.41413
training loss: 13.95651
training loss: 17.63741
training loss: 14.25820
training loss: 13.16693
training loss: 18.90185
training loss: 14.62920
training loss: 14.59377
training loss: 14.71853
training loss: 13.21518
training loss: 16.37678
training loss: 16.28897
training loss: 12.68130
training loss: 12.69386
training loss: 13.94927
training loss: 9.60208
training loss: 10.69919
training loss: 27.47116
training loss: 11.30389
training loss: 11.72916
training loss: 9.19892
training loss: 15.82199
training loss: 5.54810
[1;34mwandb[0m: 
[1;34mwandb[0m:  View run [33mdainty-lion-3[0m at: [34mhttps://wandb.ai/anunay-yadav-epfl/mamba_distill/runs/t5r2yi9x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250312_154837-t5r2yi9x/logs[0m
