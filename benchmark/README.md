## Evaluating base models

Please check [llm_eval](https://github.com/jxiw/MambaInLlama/tree/main/benchmark/llm_eval) to evaluate base models.

## Evaluating chat models

Please check [alpaca_eval](https://github.com/jxiw/MambaInLlama/tree/main/benchmark/alpaca_eval) and [mt_bench](https://github.com/jxiw/MambaInLlama/tree/main/benchmark/mt_bench) to evaluate chat models.

Please check [zero_eval](https://github.com/jxiw/ZeroEval) to evaluate chat models in zero shot.

## Evaluating long context

Please check [Needle In A Haystack](https://github.com/jxiw/MambaInLlama/tree/main/benchmark/needle) to evaluate chat models in zero shot.

## Speed Test

Please check and change `speed.sh`